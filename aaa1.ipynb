{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3smEWR0YeX1K"
   },
   "source": [
    "# Notebook 1: Data Preprocessing & Labeling\n",
    "\n",
    "This notebook handles:\n",
    "1. Data loading and preprocessing\n",
    "2. Feature engineering\n",
    "3. Market cycle labeling (regime detection)\n",
    "4. Saving processed data for subsequent notebooks\n",
    "\n",
    "**Output Files:**\n",
    "- `market_cycle/data/market_cycle_labeled_data.parquet`\n",
    "- `market_cycle/features/market_cycle_train_data.parquet`\n",
    "- `market_cycle/features/sequence_data.npz` (for deep learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAhK5NkseX1N"
   },
   "source": [
    "Market Cycle Labeling for 5-Minute K-Line Data\n",
    "\n",
    "Based on Al Brooks Price Action Theory\n",
    "\n",
    "**Labels:**\n",
    "- `-1`: ä¸‹è·Œè¶‹åŠ¿ (Downtrend)\n",
    "- `0`: éœ‡è¡/äº¤æ˜“åŒºé—´ (Trading Range / Breakout Mode)\n",
    "- `+1`: ä¸Šæ¶¨è¶‹åŠ¿ (Uptrend)\n",
    "\n",
    "**Core Principles:**\n",
    "1. åªå…³å¿ƒæœ¬å‘¨æœŸå±€éƒ¨ç»“æ„ï¼Œåˆ©ç”¨å°‘é‡æœªæ¥ä¿¡æ¯ï¼ˆtriple barrier + æœªæ¥çª—å£ï¼‰æ¥æ ‡æ³¨\n",
    "2. å……åˆ†åˆ©ç”¨ KAMAï¼ˆå«ERæ•ˆç‡å› å­ï¼‰æ¥æµ‹\"è¶‹åŠ¿ vs éœ‡è¡\"\n",
    "3. ç»“åˆ Al Brooks çš„20æ ¹baräº¤æ˜“åŒºé—´ä¸­æ€§åŒ–è§„åˆ™\n",
    "4. ç”¨ triple barrier åš\"æ–¹å‘ç¡®è®¤\"\n",
    "\n",
    "**Pipeline Layers:**\n",
    "1. æ•°æ®é¢„å¤„ç†å±‚\n",
    "2. è¾…åŠ©ç‰¹å¾å±‚ (KAMA, ER, çº¿æ€§å›å½’, éœ‡è¡åº¦)\n",
    "3. Triple Barrier å±‚\n",
    "4. å¸‚åœºå‘¨æœŸæ ‡ç­¾å±‚ + å¹³æ»‘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1192,
     "status": "ok",
     "timestamp": 1765937069050,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "XPSrfI8XfcTb",
    "outputId": "95037c38-dd2c-44f0-dd46-ac1ff9d1c2db"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1765937070837,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "3ftrT8Atfija",
    "outputId": "c7b98937-14c0-49a8-d83d-906dc7917191"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Colab Notebooks/SeeM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj67TNJ9hodh"
   },
   "source": [
    "## Cell 1: ç¯å¢ƒé…ç½® & åº“å¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9107,
     "status": "ok",
     "timestamp": 1765937082322,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "XLGvfp0teX1O",
    "outputId": "ccf46af1-551a-4c9f-dd0c-bcc1e07ab95f"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 1: ç¯å¢ƒé…ç½® & åº“å¯¼å…¥ ==========\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from scipy import stats\n",
    "\n",
    "# ========== Matplotlib ä¸­æ–‡å­—ä½“é…ç½® ==========\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "\n",
    "# å¼ºåˆ¶æ¸…é™¤å­—ä½“ç¼“å­˜å¹¶é‡æ–°é…ç½®\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "\n",
    "# Windows ç³»ç»Ÿå¸¸è§ä¸­æ–‡å­—ä½“ - ä½¿ç”¨å¤šç§æ–¹å¼å°è¯•\n",
    "def setup_chinese_font():\n",
    "    \"\"\"è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨å¤šç§æ–¹æ³•ç¡®ä¿ç”Ÿæ•ˆ\"\"\"\n",
    "\n",
    "    # æ–¹æ³•1: ç›´æ¥æŸ¥æ‰¾å­—ä½“æ–‡ä»¶è·¯å¾„\n",
    "    import os\n",
    "    windows_font_paths = [\n",
    "        r\"C:\\Windows\\Fonts\\msyh.ttc\",      # å¾®è½¯é›…é»‘\n",
    "        r\"C:\\Windows\\Fonts\\msyhbd.ttc\",    # å¾®è½¯é›…é»‘ç²—ä½“\n",
    "        r\"C:\\Windows\\Fonts\\simhei.ttf\",    # é»‘ä½“\n",
    "        r\"C:\\Windows\\Fonts\\simsun.ttc\",    # å®‹ä½“\n",
    "        r\"Deng.ttf\"\n",
    "    ]\n",
    "\n",
    "    font_path = None\n",
    "    for path in windows_font_paths:\n",
    "        if os.path.exists(path):\n",
    "            font_path = path\n",
    "            break\n",
    "\n",
    "    if font_path:\n",
    "        # ç›´æ¥ä»æ–‡ä»¶åŠ è½½å­—ä½“\n",
    "        fm.fontManager.addfont(font_path)\n",
    "        font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "        plt.rcParams['font.sans-serif'] = [font_name] + plt.rcParams['font.sans-serif']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(f\"âœ… å·²ä»æ–‡ä»¶åŠ è½½ä¸­æ–‡å­—ä½“: {font_path}\")\n",
    "        print(f\"   å­—ä½“åç§°: {font_name}\")\n",
    "        return font_name\n",
    "\n",
    "    # æ–¹æ³•2: é€šè¿‡å­—ä½“åç§°æŸ¥æ‰¾\n",
    "    chinese_fonts = ['Microsoft YaHei', 'SimHei', 'SimSun', 'KaiTi']\n",
    "    available_fonts = set([f.name for f in fm.fontManager.ttflist])\n",
    "\n",
    "    for font in chinese_fonts:\n",
    "        if font in available_fonts:\n",
    "            plt.rcParams['font.sans-serif'] = [font] + plt.rcParams['font.sans-serif']\n",
    "            plt.rcParams['axes.unicode_minus'] = False\n",
    "            print(f\"âœ… å·²è®¾ç½®ä¸­æ–‡å­—ä½“: {font}\")\n",
    "            return font\n",
    "\n",
    "    print(\"âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“\")\n",
    "    return None\n",
    "\n",
    "chinese_font = setup_chinese_font()\n",
    "\n",
    "# å¼ºåˆ¶åˆ·æ–°å­—ä½“ç¼“å­˜\n",
    "import matplotlib as mpl\n",
    "mpl.font_manager._load_fontmanager(try_read_cache=False)\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ========== Bokeh é…ç½® ==========\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file\n",
    "from bokeh.models import ColumnDataSource, BoxAnnotation, HoverTool, Range1d, Span, Label\n",
    "from bokeh.layouts import column\n",
    "from bokeh.io import save\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "# ========== è·¯å¾„é…ç½® ==========\n",
    "DATA_DIR_FUTURE = Path(\"data/Future/rth\")\n",
    "\n",
    "# ========== è¾“å‡ºç›®å½•é…ç½® ==========\n",
    "OUTPUT_DIR = Path(\"market_cycle\")\n",
    "OUTPUT_DIR_DATA = OUTPUT_DIR / \"data\"       # æ ‡æ³¨æ•°æ®ã€è®­ç»ƒæ•°æ®\n",
    "OUTPUT_DIR_CHARTS = OUTPUT_DIR / \"charts\"   # Bokeh å›¾è¡¨\n",
    "OUTPUT_DIR_FEATURES = OUTPUT_DIR / \"features\"  # ç‰¹å¾çŸ©é˜µ\n",
    "\n",
    "# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "for d in [OUTPUT_DIR_DATA, OUTPUT_DIR_CHARTS, OUTPUT_DIR_FEATURES]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nDATA_DIR_FUTURE: {DATA_DIR_FUTURE.resolve()}\")\n",
    "print(f\"Kçº¿æ•°æ®ç›®å½•å­˜åœ¨: {DATA_DIR_FUTURE.exists()}\")\n",
    "print(f\"\\nè¾“å‡ºç›®å½•:\")\n",
    "print(f\"  æ•°æ®: {OUTPUT_DIR_DATA.resolve()}\")\n",
    "print(f\"  å›¾è¡¨: {OUTPUT_DIR_CHARTS.resolve()}\")\n",
    "print(f\"  ç‰¹å¾: {OUTPUT_DIR_FEATURES.resolve()}\")\n",
    "\n",
    "print(\"\\nCell 1 å®Œæˆ: åº“å¯¼å…¥ & å­—ä½“é…ç½® âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1765937084884,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "k-COV5iFeX1Q",
    "outputId": "6ea26c17-37fa-43bc-c417-1a1a1b4f7258"
   },
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "font_manager.fontManager.addfont(r\"Deng.ttf\")\n",
    "\n",
    "# å¼ºåˆ¶æŒ‡å®šå­—ä½“ï¼ˆå…³é”®ï¼ï¼‰\n",
    "plt.rcParams['font.sans-serif'] = ['DengXian']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title(\"æµ‹è¯•æ ‡é¢˜ï¼šä¸­æ–‡æ˜¯å¦æ­£å¸¸æ˜¾ç¤ºï¼Ÿ\")\n",
    "plt.xlabel(\"æ¨ªè½´ï¼šæ•°é‡\")\n",
    "plt.ylabel(\"çºµè½´ï¼šæŒ‡æ ‡\")\n",
    "plt.plot([1,2,3])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oHQW25Lhsgd"
   },
   "source": [
    "## Cell 2: å…¨å±€è¶…å‚æ•°é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1765937086863,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "HiLObPPMeX1R",
    "outputId": "ae8aec57-c107-40b4-d834-1f644d12c7b4"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 2: å…¨å±€è¶…å‚æ•°é…ç½® ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ å‚æ•°è°ƒä¼˜æŒ‡å—:\n",
    "   - æƒ³è¦æ£€æµ‹åˆ°æ›´å¤šè¶‹åŠ¿ â†’ é™ä½ THR_ER_LOW, THR_CHOP_HIGH, æé«˜ THR_ER_HIGH\n",
    "   - æƒ³è¦æ›´ä¸¥æ ¼çš„è¶‹åŠ¿åˆ¤å®š â†’ æé«˜ THR_ER_HIGH, é™ä½ THR_CHOP_LOW\n",
    "   - Al Brooks 80/20 è§„åˆ™: çº¦80%æ—¶é—´åœ¨éœ‡è¡åŒºé—´ï¼Œ20%æ—¶é—´åœ¨è¶‹åŠ¿ä¸­\n",
    "\n",
    "âš¡ å¿«é€Ÿè°ƒå‚: åªä¿®æ”¹è¿™ä¸ª Cellï¼Œç„¶åé‡æ–°è¿è¡Œåç»­æ‰€æœ‰ Cell å³å¯\n",
    "\"\"\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“Š åŸºç¡€è®¡ç®—å‚æ•°\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "N_ATR = 20          # ATR è®¡ç®—å‘¨æœŸ (5min Kçº¿, 20æ ¹â‰ˆ100åˆ†é’Ÿ)\n",
    "                    #   â†“ å‡å°: ATR æ›´æ•æ„Ÿï¼Œæ³¢åŠ¨ä¼°è®¡æ›´åŠæ—¶ä½†æ›´noisy\n",
    "                    #   â†‘ å¢å¤§: ATR æ›´ç¨³å®šï¼Œä½†å¯¹çªå‘æ³¢åŠ¨ååº”æ…¢\n",
    "\n",
    "N_ER = 20           # ER æ•ˆç‡å› å­çª—å£ (ä¸ Brooks 20-bar è§„åˆ™ä¸€è‡´)\n",
    "                    #   â†“ å‡å°: æ›´å¿«æ£€æµ‹åˆ°è¶‹åŠ¿å¼€å§‹ï¼Œä½†å¯èƒ½äº§ç”Ÿæ›´å¤šå‡ä¿¡å·\n",
    "                    #   â†‘ å¢å¤§: è¶‹åŠ¿åˆ¤æ–­æ›´å¯é ï¼Œä½†ä¼šé”™è¿‡è¶‹åŠ¿åˆæœŸ\n",
    "\n",
    "L_BACK = 20         # å›çœ‹çª—å£ (ç”¨äºçº¿æ€§å›å½’ã€éœ‡è¡åº¦ç­‰)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“ˆ KAMA (Kaufman Adaptive Moving Average) å‚æ•°\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "KAMA_N_ER = 10      # KAMA å†…éƒ¨çš„ ER è®¡ç®—çª—å£\n",
    "                    #   â†“ å‡å°: KAMA å¯¹è¶‹åŠ¿å˜åŒ–æ›´æ•æ„Ÿ\n",
    "                    #   â†‘ å¢å¤§: KAMA æ›´å¹³æ»‘\n",
    "\n",
    "KAMA_FAST = 2       # å¿«é€Ÿ EMA å‘¨æœŸ (è¶‹åŠ¿å¼ºæ—¶ä½¿ç”¨)\n",
    "KAMA_SLOW = 30      # æ…¢é€Ÿ EMA å‘¨æœŸ (éœ‡è¡æ—¶ä½¿ç”¨)\n",
    "KAMA_SLOPE_LAG = 5  # KAMA æ–œç‡è®¡ç®—æ»å (ç”¨å‡ æ ¹barè®¡ç®—æ–œç‡)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ Triple Barrier å‚æ•° (æ–¹å‘ç¡®è®¤)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "T_VERT = 12         # å‚ç›´æ—¶é—´éšœç¢ (12æ ¹5minâ‰ˆ1å°æ—¶)\n",
    "                    #   â†“ å‡å°: åªçœ‹çŸ­æœŸæ–¹å‘ï¼Œæ›´é€‚åˆçŸ­çº¿\n",
    "                    #   â†‘ å¢å¤§: çœ‹æ›´é•¿æœŸæ–¹å‘ï¼Œè¶‹åŠ¿åˆ¤æ–­æ›´ç¨³å¥\n",
    "\n",
    "PT_MULT = 1.5       # æ­¢ç›ˆå€æ•° (ç›¸å¯¹ATR)\n",
    "                    #   â†“ å‡å°: æ›´å®¹æ˜“è§¦å‘æ–¹å‘æ ‡ç­¾ï¼Œæ£€æµ‹åˆ°æ›´å¤šè¶‹åŠ¿\n",
    "                    #   â†‘ å¢å¤§: åªæœ‰å¼ºåŠ¿è¡Œæƒ…æ‰ç»™æ–¹å‘æ ‡ç­¾\n",
    "\n",
    "SL_MULT = 1.5       # æ­¢æŸå€æ•° (ç›¸å¯¹ATR)ï¼Œé€šå¸¸ä¸ PT_MULT ç›¸åŒ\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”´ éœ‡è¡åŒºé—´åˆ¤å®šå‚æ•° (ä¸¥æ ¼æ¡ä»¶ï¼Œéœ€åŒæ—¶æ»¡è¶³å¤šä¸ª)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "L_RANGE = 10        # åŒºé—´çª—å£ (å‰åå„å¤šå°‘æ ¹bar)\n",
    "L_RANGE_FWD = 10    # æœªæ¥çª—å£ (ç”¨äºåˆ¤æ–­æ˜¯å¦ä»åœ¨åŒºé—´)\n",
    "\n",
    "THR_ER_LOW = 0.25   # ã€å…³é”®ã€‘ER < æ­¤å€¼è§†ä¸ºéœ‡è¡\n",
    "                    #   â†“ å‡å°(å¦‚0.2): æ›´ä¸¥æ ¼ï¼Œåªæœ‰æåº¦éœ‡è¡æ‰æ ‡ä¸ºåŒºé—´ â†’ è¶‹åŠ¿æ¯”ä¾‹â†‘\n",
    "                    #   â†‘ å¢å¤§(å¦‚0.4): æ›´å®½æ¾ï¼Œæ›´å¤šbaræ ‡ä¸ºéœ‡è¡åŒºé—´ â†’ éœ‡è¡æ¯”ä¾‹â†‘\n",
    "\n",
    "THR_CHOP_HIGH = 0.75  # ã€å…³é”®ã€‘chop > æ­¤å€¼è§†ä¸ºéœ‡è¡\n",
    "                    #   â†“ å‡å°(å¦‚0.6): æ›´ä¸¥æ ¼ â†’ è¶‹åŠ¿æ¯”ä¾‹â†‘\n",
    "                    #   â†‘ å¢å¤§(å¦‚0.85): æ›´å®½æ¾ â†’ éœ‡è¡æ¯”ä¾‹â†‘\n",
    "\n",
    "THR_RANGE_ATR = 3.5 # range/ATR < æ­¤å€¼è§†ä¸ºçª„åŒºé—´\n",
    "                    #   â†“ å‡å°: éœ€è¦æ›´çª„çš„åŒºé—´æ‰ç®—éœ‡è¡\n",
    "                    #   â†‘ å¢å¤§: æ›´å®½çš„åŒºé—´ä¹Ÿå¯ä»¥ç®—éœ‡è¡\n",
    "\n",
    "THR_R2_LOW = 0.25   # RÂ² < æ­¤å€¼è§†ä¸ºæ— æ˜æ˜¾çº¿æ€§è¶‹åŠ¿\n",
    "                    #   â†“ å‡å°: æ›´å®½æ¾ï¼Œå…è®¸ç¨æœ‰è¶‹åŠ¿æ€§çš„åŒºé—´\n",
    "                    #   â†‘ å¢å¤§: æ›´ä¸¥æ ¼\n",
    "\n",
    "THR_FUTURE_MOVE = 1.2  # æœªæ¥ç§»åŠ¨ < æ­¤å€¼*ATR è§†ä¸ºä»åœ¨åŒºé—´\n",
    "                    #   â†“ å‡å°: æ›´ä¸¥æ ¼ï¼Œéœ€è¦ä»·æ ¼å‡ ä¹ä¸åŠ¨\n",
    "                    #   â†‘ å¢å¤§: å…è®¸æ›´å¤§çš„æœªæ¥ç§»åŠ¨ä»ç®—åŒºé—´\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸŸ¢ è¶‹åŠ¿åˆ¤å®šå‚æ•° (å¯¹ééœ‡è¡åŒºé—´çš„barè¿›è¡Œè¶‹åŠ¿åˆ¤å®š)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "THR_ER_HIGH = 0.35  # ã€å…³é”®ã€‘ER > æ­¤å€¼å¼€å§‹è€ƒè™‘è¶‹åŠ¿\n",
    "                    #   â†“ å‡å°(å¦‚0.3): æ›´å®¹æ˜“è¢«åˆ¤å®šä¸ºè¶‹åŠ¿ â†’ è¶‹åŠ¿æ¯”ä¾‹â†‘\n",
    "                    #   â†‘ å¢å¤§(å¦‚0.5): éœ€è¦æ›´å¼ºçš„æ•ˆç‡æ‰ç»™è¶‹åŠ¿æ ‡ç­¾ â†’ è¶‹åŠ¿æ¯”ä¾‹â†“\n",
    "\n",
    "THR_CHOP_LOW = 0.55 # ã€å…³é”®ã€‘chop < æ­¤å€¼å¼€å§‹è€ƒè™‘è¶‹åŠ¿\n",
    "                    #   â†“ å‡å°(å¦‚0.4): éœ€è¦å¾ˆä½çš„éœ‡è¡åº¦æ‰ç»™è¶‹åŠ¿\n",
    "                    #   â†‘ å¢å¤§(å¦‚0.6): ä¸­ç­‰éœ‡è¡åº¦ä¹Ÿå¯ä»¥ç»™è¶‹åŠ¿ â†’ è¶‹åŠ¿æ¯”ä¾‹â†‘\n",
    "\n",
    "THR_SLOPE_NORM = 0.015  # KAMAæ–œç‡æ ‡å‡†åŒ–é˜ˆå€¼ (æ¯barç§»åŠ¨å¤šå°‘ATR)\n",
    "                    #   â†“ å‡å°: æ›´å®¹æ˜“æ»¡è¶³æ–œç‡æ¡ä»¶ â†’ è¶‹åŠ¿æ¯”ä¾‹â†‘\n",
    "                    #   â†‘ å¢å¤§: éœ€è¦æ›´é™¡çš„æ–œç‡æ‰ç®—è¶‹åŠ¿\n",
    "\n",
    "THR_DIST_NORM = 0.4 # ä»·æ ¼åç¦»KAMAçš„æ ‡å‡†åŒ–é˜ˆå€¼\n",
    "                    #   â†“ å‡å°: æ›´å®¹æ˜“æ»¡è¶³åç¦»æ¡ä»¶ â†’ è¶‹åŠ¿æ¯”ä¾‹â†‘\n",
    "                    #   â†‘ å¢å¤§: éœ€è¦æ›´å¤§çš„åç¦»æ‰ç®—è¶‹åŠ¿\n",
    "\n",
    "L_FWD = 12          # è¶‹åŠ¿ç¡®è®¤çš„æœªæ¥çª—å£ (çº¦1å°æ—¶)\n",
    "                    #   ç”¨äºéªŒè¯å½“å‰æ–œç‡æ–¹å‘ä¸æœªæ¥èµ°åŠ¿æ˜¯å¦ä¸€è‡´\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”§ æ ‡ç­¾å¹³æ»‘å‚æ•°\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "MIN_TREND_LEN = 4   # æœ€å°è¶‹åŠ¿æ®µé•¿åº¦ (å¤ªçŸ­çš„è¶‹åŠ¿æ®µæ ‡ä¸º0)\n",
    "                    #   â†“ å‡å°: ä¿ç•™æ›´çŸ­çš„è¶‹åŠ¿æ®µ â†’ è¶‹åŠ¿æ¯”ä¾‹â†‘\n",
    "                    #   â†‘ å¢å¤§: è¿‡æ»¤æ‰çŸ­è¶‹åŠ¿ â†’ éœ‡è¡æ¯”ä¾‹â†‘\n",
    "\n",
    "MIN_RANGE_LEN = 15  # æœ€å°éœ‡è¡åŒºé—´é•¿åº¦ (BrooksåŸå§‹ä¸º20)\n",
    "                    #   â†“ å‡å°: æ›´çŸ­çš„éœ‡è¡ä¹Ÿä¿ç•™ â†’ éœ‡è¡æ¯”ä¾‹â†‘\n",
    "                    #   â†‘ å¢å¤§: åªä¿ç•™é•¿éœ‡è¡ â†’ è¶‹åŠ¿æ¯”ä¾‹â†‘\n",
    "\n",
    "SMOOTH_WINDOW = 5   # å¹³æ»‘çª—å£ (å¤šæ•°æŠ•ç¥¨)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“‹ æ‰“å°å½“å‰é…ç½®\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“Š å½“å‰å‚æ•°é…ç½®\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nã€åŸºç¡€å‚æ•°ã€‘\")\n",
    "print(f\"  ATRå‘¨æœŸ: {N_ATR}, ERçª—å£: {N_ER}, å›çœ‹çª—å£: {L_BACK}\")\n",
    "print(f\"\\nã€KAMAå‚æ•°ã€‘\")\n",
    "print(f\"  n_er={KAMA_N_ER}, fast={KAMA_FAST}, slow={KAMA_SLOW}, slope_lag={KAMA_SLOPE_LAG}\")\n",
    "print(f\"\\nã€Triple Barrierã€‘\")\n",
    "print(f\"  T_vert={T_VERT} (~{T_VERT*5}åˆ†é’Ÿ), pt_mult={PT_MULT}, sl_mult={SL_MULT}\")\n",
    "print(f\"\\nã€éœ‡è¡åŒºé—´åˆ¤å®šã€‘ (éœ€åŒæ—¶æ»¡è¶³)\")\n",
    "print(f\"  ER < {THR_ER_LOW}, chop > {THR_CHOP_HIGH}, range_atr < {THR_RANGE_ATR}\")\n",
    "print(f\"  RÂ² < {THR_R2_LOW}, future_move < {THR_FUTURE_MOVE}*ATR\")\n",
    "print(f\"\\nã€è¶‹åŠ¿åˆ¤å®šã€‘ (æ»¡è¶³éƒ¨åˆ†æ¡ä»¶)\")\n",
    "print(f\"  ER > {THR_ER_HIGH} æˆ– chop < {THR_CHOP_LOW}\")\n",
    "print(f\"  slope_norm > {THR_SLOPE_NORM}, dist_norm > {THR_DIST_NORM}\")\n",
    "print(f\"\\nã€æ ‡ç­¾å¹³æ»‘ã€‘\")\n",
    "print(f\"  æœ€å°è¶‹åŠ¿é•¿åº¦: {MIN_TREND_LEN}, æœ€å°éœ‡è¡é•¿åº¦: {MIN_RANGE_LEN}, å¹³æ»‘çª—å£: {SMOOTH_WINDOW}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nâœ… Cell 2 å®Œæˆ: å‚æ•°é…ç½® (ä¿®æ”¹åé‡æ–°è¿è¡Œåç»­Cellå³å¯)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxVbBy6gnY_P"
   },
   "source": [
    "## Cell 3: åŠ è½½å¹¶åˆå¹¶ 5min Kçº¿æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "executionInfo": {
     "elapsed": 18722,
     "status": "ok",
     "timestamp": 1765937109599,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "bB45AgCleX1R",
    "outputId": "f82f9e15-90ee-4d92-ad90-5a5bac29833a"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 3: åŠ è½½å¹¶åˆå¹¶ 5min Kçº¿æ•°æ® ==========\n",
    "\n",
    "# è·å–æ‰€æœ‰ ES 5min Kçº¿æ–‡ä»¶\n",
    "five_min_files = sorted(DATA_DIR_FUTURE.glob(\"ES_5min_rth_*.csv\"))\n",
    "print(f\"æ‰¾åˆ°çš„ 5min Kçº¿æ–‡ä»¶æ•°é‡: {len(five_min_files)}\")\n",
    "\n",
    "if not five_min_files:\n",
    "    raise FileNotFoundError(f\"åœ¨ç›®å½• {DATA_DIR_FUTURE} ä¸‹æœªæ‰¾åˆ° ES_5min_rth_*.csv æ–‡ä»¶\")\n",
    "\n",
    "dfs = []\n",
    "for f in five_min_files:\n",
    "    print(f\"è¯»å–: {f.name}\")\n",
    "    df_year = pd.read_csv(f)\n",
    "\n",
    "    # æ£€æŸ¥å¿…è¦åˆ—\n",
    "    required_cols = {\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"}\n",
    "    missing_cols = required_cols - set(df_year.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"æ–‡ä»¶ {f.name} ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}\")\n",
    "\n",
    "    # è½¬æ¢æ—¶é—´æˆ³\n",
    "    df_year[\"timestamp\"] = pd.to_datetime(df_year[\"timestamp\"], errors=\"coerce\")\n",
    "    df_year = df_year.sort_values(\"timestamp\")\n",
    "    dfs.append(df_year)\n",
    "\n",
    "# åˆå¹¶æ‰€æœ‰å¹´ä»½\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "df = df.set_index(\"timestamp\")\n",
    "\n",
    "# ç¡®ä¿æ•°å€¼åˆ—ç±»å‹æ­£ç¡®\n",
    "for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "print(f\"\\n=== df åŸºæœ¬ä¿¡æ¯ ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"æ—¶é—´èŒƒå›´: {df.index.min()} ~ {df.index.max()}\")\n",
    "print(f\"é‡å¤æ—¶é—´æˆ³æ•°é‡: {df.index.duplicated().sum()}\")\n",
    "\n",
    "# æ£€æŸ¥ç¼ºå¤±å€¼\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(f\"\\nå­˜åœ¨ç¼ºå¤±å€¼:\\n{missing[missing > 0]}\")\n",
    "else:\n",
    "    print(\"\\næ— ç¼ºå¤±å€¼\")\n",
    "\n",
    "display(df.head())\n",
    "print(\"\\nCell 3 å®Œæˆ: æ•°æ®åŠ è½½å®Œæ¯• âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MCojB88nbaG"
   },
   "source": [
    "## Cell 4: æ•°æ®é¢„å¤„ç† - åŸºç¡€åºåˆ—è®¡ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1765937109699,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "t18LwxmAeX1S",
    "outputId": "c020a846-1640-425f-d45a-d72ebfaa5de0"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 4: æ•°æ®é¢„å¤„ç† - åŸºç¡€åºåˆ—è®¡ç®— ==========\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "# 1. å¯¹æ•°æ”¶ç›Š (log return)\n",
    "# r_t = ln(C_t) - ln(C_{t-1})\n",
    "df[\"log_close\"] = np.log(df[\"close\"])\n",
    "df[\"log_return\"] = df[\"log_close\"].diff()\n",
    "\n",
    "# 2. çœŸå®æ³¢åŠ¨èŒƒå›´ (True Range) å’Œ ATR\n",
    "# TR_t = max(H_t - L_t, |H_t - C_{t-1}|, |L_t - C_{t-1}|)\n",
    "prev_close = df[\"close\"].shift(1)\n",
    "tr1 = df[\"high\"] - df[\"low\"]\n",
    "tr2 = np.abs(df[\"high\"] - prev_close)\n",
    "tr3 = np.abs(df[\"low\"] - prev_close)\n",
    "df[\"tr\"] = np.maximum(np.maximum(tr1, tr2), tr3)\n",
    "\n",
    "# ATR ä½¿ç”¨ EMA\n",
    "df[\"atr\"] = df[\"tr\"].ewm(span=N_ATR, adjust=False).mean()\n",
    "\n",
    "# 3. æ»šåŠ¨é«˜ä½ä»·åŒºé—´\n",
    "df[\"roll_max\"] = df[\"close\"].rolling(window=L_BACK).max()\n",
    "df[\"roll_min\"] = df[\"close\"].rolling(window=L_BACK).min()\n",
    "df[\"roll_range\"] = df[\"roll_max\"] - df[\"roll_min\"]\n",
    "\n",
    "# 4. ç›¸å¯¹åŒºé—´ (range / ATR)\n",
    "df[\"range_atr\"] = df[\"roll_range\"] / df[\"atr\"].replace(0, np.nan)\n",
    "\n",
    "print(\"=== åŸºç¡€åºåˆ—è®¡ç®—å®Œæˆ ===\")\n",
    "print(f\"log_return: mean={df['log_return'].mean():.6f}, std={df['log_return'].std():.6f}\")\n",
    "print(f\"ATR: mean={df['atr'].mean():.4f}, std={df['atr'].std():.4f}\")\n",
    "print(f\"range_atr: mean={df['range_atr'].mean():.4f}, std={df['range_atr'].std():.4f}\")\n",
    "\n",
    "display(df[[\"open\", \"high\", \"low\", \"close\", \"log_return\", \"tr\", \"atr\", \"range_atr\"]].tail(10))\n",
    "print(\"\\nCell 4 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkXtXC8Qndm4"
   },
   "source": [
    "## Cell 5: KAMA ä¸ ER (æ•ˆç‡å› å­) è®¡ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "executionInfo": {
     "elapsed": 1499,
     "status": "ok",
     "timestamp": 1765492486131,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "UbbZPZ_QeX1S",
    "outputId": "89e2bcb9-ed3b-42c3-fe4e-3816b32bd933"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 5: KAMA ä¸ ER (æ•ˆç‡å› å­) è®¡ç®— ==========\n",
    "\n",
    "def calc_efficiency_ratio(close: pd.Series, n: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ•ˆç‡å› å­ ER (Efficiency Ratio)\n",
    "\n",
    "    ER_t = |C_t - C_{t-n}| / sum(|C_i - C_{i-1}|, i=t-n+1 to t)\n",
    "\n",
    "    ER â†’ 1: ä»·æ ¼å‡ ä¹\"èµ°ç›´çº¿\"ï¼Œè¶‹åŠ¿å¹²å‡€\n",
    "    ER â†’ 0: å¤§é‡æ¥å›éœ‡è¡ï¼Œå…¸å‹äº¤æ˜“åŒºé—´\n",
    "    \"\"\"\n",
    "    change = (close - close.shift(n)).abs()\n",
    "    volatility = close.diff().abs().rolling(window=n).sum()\n",
    "    er = change / volatility.replace(0, np.nan)\n",
    "    return er.clip(0, 1)\n",
    "\n",
    "\n",
    "def calc_kama(close: pd.Series, n_er: int, fast: int, slow: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    è®¡ç®— KAMA (Kaufman Adaptive Moving Average)\n",
    "\n",
    "    SC (Smoothing Constant) = [ER * (fast_sc - slow_sc) + slow_sc]^2\n",
    "    KAMA_t = KAMA_{t-1} + SC * (Close_t - KAMA_{t-1})\n",
    "    \"\"\"\n",
    "    # è®¡ç®— ER\n",
    "    er = calc_efficiency_ratio(close, n_er)\n",
    "\n",
    "    # å¹³æ»‘å¸¸æ•°\n",
    "    fast_sc = 2 / (fast + 1)\n",
    "    slow_sc = 2 / (slow + 1)\n",
    "    sc = (er * (fast_sc - slow_sc) + slow_sc) ** 2\n",
    "\n",
    "    # åˆå§‹åŒ– KAMA\n",
    "    kama = np.zeros(len(close))\n",
    "    kama[:] = np.nan\n",
    "\n",
    "    # æ‰¾ç¬¬ä¸€ä¸ªé NaN çš„ SC ä½ç½®\n",
    "    first_valid = sc.first_valid_index()\n",
    "    if first_valid is None:\n",
    "        return pd.Series(kama, index=close.index)\n",
    "\n",
    "    first_idx = close.index.get_loc(first_valid)\n",
    "\n",
    "    # ç”¨ SMA åˆå§‹åŒ–\n",
    "    kama[first_idx] = close.iloc[:first_idx + 1].mean()\n",
    "\n",
    "    # é€’å½’è®¡ç®—\n",
    "    close_arr = close.values\n",
    "    sc_arr = sc.values\n",
    "    for i in range(first_idx + 1, len(close)):\n",
    "        if np.isnan(sc_arr[i]):\n",
    "            kama[i] = kama[i - 1]\n",
    "        else:\n",
    "            kama[i] = kama[i - 1] + sc_arr[i] * (close_arr[i] - kama[i - 1])\n",
    "\n",
    "    return pd.Series(kama, index=close.index)\n",
    "\n",
    "\n",
    "# è®¡ç®— ER (ä½¿ç”¨å…¨å±€ N_ER å‚æ•°)\n",
    "df[\"er\"] = calc_efficiency_ratio(df[\"close\"], N_ER)\n",
    "\n",
    "# è®¡ç®— KAMA\n",
    "df[\"kama\"] = calc_kama(df[\"close\"], KAMA_N_ER, KAMA_FAST, KAMA_SLOW)\n",
    "\n",
    "# è®¡ç®— KAMA æ–œç‡ (ä½¿ç”¨ KAMA_SLOPE_LAG)\n",
    "df[\"kama_slope\"] = (df[\"kama\"] - df[\"kama\"].shift(KAMA_SLOPE_LAG)) / KAMA_SLOPE_LAG\n",
    "\n",
    "# æ–œç‡æ ‡å‡†åŒ– (ç›¸å¯¹ ATR)\n",
    "# slope_norm_t = slope_t / ATR_t\n",
    "df[\"slope_norm\"] = df[\"kama_slope\"] / df[\"atr\"].replace(0, np.nan)\n",
    "\n",
    "# ä»·æ ¼åç¦»åº¦ (ç›¸å¯¹ ATR)\n",
    "# dist_norm_t = (C_t - KAMA_t) / ATR_t\n",
    "df[\"dist_norm\"] = (df[\"close\"] - df[\"kama\"]) / df[\"atr\"].replace(0, np.nan)\n",
    "\n",
    "print(\"=== KAMA & ER è®¡ç®—å®Œæˆ ===\")\n",
    "print(f\"ER: mean={df['er'].mean():.4f}, median={df['er'].median():.4f}\")\n",
    "print(f\"KAMAæ–œç‡æ ‡å‡†åŒ–: mean={df['slope_norm'].mean():.4f}, std={df['slope_norm'].std():.4f}\")\n",
    "print(f\"ä»·æ ¼åç¦»åº¦: mean={df['dist_norm'].mean():.4f}, std={df['dist_norm'].std():.4f}\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['DengXian']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ER åˆ†å¸ƒç›´æ–¹å›¾\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(df[\"er\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].axvline(x=THR_ER_LOW, color=\"red\", linestyle=\"--\", label=f\"éœ‡è¡é˜ˆå€¼: {THR_ER_LOW}\")\n",
    "axes[0].axvline(x=THR_ER_HIGH, color=\"green\", linestyle=\"--\", label=f\"è¶‹åŠ¿é˜ˆå€¼: {THR_ER_HIGH}\")\n",
    "axes[0].set_xlabel(\"ER (æ•ˆç‡å› å­)\")\n",
    "axes[0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0].set_title(\"ER æ•ˆç‡å› å­åˆ†å¸ƒ\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(df[\"slope_norm\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[1].axvline(x=THR_SLOPE_NORM, color=\"green\", linestyle=\"--\", label=f\"+é˜ˆå€¼: {THR_SLOPE_NORM}\")\n",
    "axes[1].axvline(x=-THR_SLOPE_NORM, color=\"red\", linestyle=\"--\", label=f\"-é˜ˆå€¼: -{THR_SLOPE_NORM}\")\n",
    "axes[1].set_xlabel(\"KAMA æ–œç‡ (æ ‡å‡†åŒ–)\")\n",
    "axes[1].set_ylabel(\"æ•°é‡\")\n",
    "axes[1].set_title(\"KAMA æ–œç‡æ ‡å‡†åŒ–åˆ†å¸ƒ\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].hist(df[\"dist_norm\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[2].axvline(x=THR_DIST_NORM, color=\"green\", linestyle=\"--\", label=f\"+é˜ˆå€¼: {THR_DIST_NORM}\")\n",
    "axes[2].axvline(x=-THR_DIST_NORM, color=\"red\", linestyle=\"--\", label=f\"-é˜ˆå€¼: -{THR_DIST_NORM}\")\n",
    "axes[2].set_xlabel(\"ä»·æ ¼åç¦»åº¦ (æ ‡å‡†åŒ–)\")\n",
    "axes[2].set_ylabel(\"æ•°é‡\")\n",
    "axes[2].set_title(\"ä»·æ ¼åç¦»åº¦åˆ†å¸ƒ\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 5 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf-wPbJmniOM"
   },
   "source": [
    "##  Cell 6: æœ¬åœ°ç»“æ„/éœ‡è¡åº¦ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "executionInfo": {
     "elapsed": 9821,
     "status": "ok",
     "timestamp": 1765492495954,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "6PWzvzpaeX1T",
    "outputId": "043d3d69-a0b4-444d-e5bf-c5d644618e8b"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 6: æœ¬åœ°ç»“æ„/éœ‡è¡åº¦ç‰¹å¾ ==========\n",
    "\n",
    "def rolling_linreg(y: np.ndarray, window: int) -> tuple:\n",
    "    \"\"\"\n",
    "    å¯¹ y åºåˆ—åšæ»šåŠ¨çº¿æ€§å›å½’ï¼Œè¿”å› (æ–œç‡, RÂ²)\n",
    "    ä½¿ç”¨ç®€å•çš„æœ€å°äºŒä¹˜æ³•: y = beta * x + alpha\n",
    "    x = [0, 1, 2, ..., window-1]\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    beta = np.full(n, np.nan)\n",
    "    r2 = np.full(n, np.nan)\n",
    "\n",
    "    x = np.arange(window)\n",
    "    x_mean = x.mean()\n",
    "    ss_x = ((x - x_mean) ** 2).sum()\n",
    "\n",
    "    for i in range(window - 1, n):\n",
    "        y_win = y[i - window + 1:i + 1]\n",
    "        if np.any(np.isnan(y_win)):\n",
    "            continue\n",
    "\n",
    "        y_mean = y_win.mean()\n",
    "\n",
    "        # æ–œç‡\n",
    "        ss_xy = ((x - x_mean) * (y_win - y_mean)).sum()\n",
    "        b = ss_xy / ss_x if ss_x > 0 else 0\n",
    "\n",
    "        # RÂ²\n",
    "        y_pred = b * (x - x_mean) + y_mean\n",
    "        ss_res = ((y_win - y_pred) ** 2).sum()\n",
    "        ss_tot = ((y_win - y_mean) ** 2).sum()\n",
    "        r2_val = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n",
    "\n",
    "        beta[i] = b\n",
    "        r2[i] = max(0, min(1, r2_val))  # clip to [0, 1]\n",
    "\n",
    "    return beta, r2\n",
    "\n",
    "\n",
    "# 1. æ»šåŠ¨çº¿æ€§å›å½’ (å¯¹ log_close)\n",
    "print(\"è®¡ç®—æ»šåŠ¨çº¿æ€§å›å½’...\")\n",
    "log_close_arr = df[\"log_close\"].values\n",
    "beta_arr, r2_arr = rolling_linreg(log_close_arr, L_BACK)\n",
    "\n",
    "df[\"beta\"] = beta_arr           # æ–œç‡\n",
    "df[\"r2\"] = r2_arr               # RÂ² (æ‹Ÿåˆç¨‹åº¦)\n",
    "\n",
    "# 2. éœ‡è¡åº¦ (Choppiness Index - åŸºäºATRçš„æ ‡å‡†å®šä¹‰)\n",
    "# Choppiness Index = 100 * log10(sum(ATR_n) / (highest - lowest)) / log10(n)\n",
    "# è¿™ä¸ªå®šä¹‰ä¸ ER åœ¨æ•°å­¦ä¸Šä¸å®Œå…¨ç­‰ä»·ï¼Œå› ä¸ºå®ƒä½¿ç”¨ ATR è€Œéæ”¶ç›˜ä»·å˜åŠ¨\n",
    "print(\"è®¡ç®—éœ‡è¡åº¦ (Choppiness Index)...\")\n",
    "\n",
    "# ä½¿ç”¨ä¸åŒçš„çª—å£æ¥é¿å…ä¸ ER å®Œç¾ç›¸å…³\n",
    "CHOP_WINDOW = 14  # æ ‡å‡† Choppiness Index ä½¿ç”¨ 14 å‘¨æœŸ\n",
    "\n",
    "# è®¡ç®— ATR çš„æ»šåŠ¨å’Œ\n",
    "atr_sum = df[\"tr\"].rolling(window=CHOP_WINDOW).sum()\n",
    "\n",
    "# è®¡ç®—çª—å£å†…çš„é«˜ä½ç‚¹å·®\n",
    "high_max = df[\"high\"].rolling(window=CHOP_WINDOW).max()\n",
    "low_min = df[\"low\"].rolling(window=CHOP_WINDOW).min()\n",
    "hl_range = high_max - low_min\n",
    "\n",
    "# Choppiness Index (æ ‡å‡†åŒ–åˆ° 0-1)\n",
    "# åŸå§‹å…¬å¼: 100 * log10(atr_sum / hl_range) / log10(n)\n",
    "# ç®€åŒ–: chop = log10(atr_sum / hl_range) / log10(n)\n",
    "# å€¼è¶Šé«˜ = è¶Šéœ‡è¡, å€¼è¶Šä½ = è¶Šè¶‹åŠ¿\n",
    "import math\n",
    "df[\"chop\"] = np.log10(atr_sum / hl_range.replace(0, np.nan)) / math.log10(CHOP_WINDOW)\n",
    "df[\"chop\"] = df[\"chop\"].clip(0, 1)\n",
    "\n",
    "# è¡¥å……: æ·»åŠ ä¸€ä¸ªåŸºäº bar é‡å åº¦çš„éœ‡è¡æŒ‡æ ‡ (ä¸ ER ä¸åŒ)\n",
    "# è®¡ç®—ç›¸é‚» bar çš„é‡å ç¨‹åº¦\n",
    "prev_high = df[\"high\"].shift(1)\n",
    "prev_low = df[\"low\"].shift(1)\n",
    "overlap = np.minimum(df[\"high\"], prev_high) - np.maximum(df[\"low\"], prev_low)\n",
    "overlap = overlap.clip(lower=0)\n",
    "bar_range = (df[\"high\"] - df[\"low\"] + prev_high - prev_low) / 2\n",
    "df[\"overlap_ratio\"] = (overlap / bar_range.replace(0, np.nan)).rolling(window=L_BACK).mean()\n",
    "df[\"overlap_ratio\"] = df[\"overlap_ratio\"].clip(0, 1)\n",
    "\n",
    "# 3. éªŒè¯: ER ä¸ chop çš„å…³ç³»\n",
    "# æ³¨æ„: ä½¿ç”¨æ ‡å‡† Choppiness Index å®šä¹‰åï¼ŒER ä¸ chop ä¸å†å®Œç¾è´Ÿç›¸å…³\n",
    "# é«˜ ER -> ä½ chop (è¶‹åŠ¿)\n",
    "# ä½ ER -> é«˜ chop (éœ‡è¡)\n",
    "\n",
    "print(\"\\n=== æœ¬åœ°ç»“æ„ç‰¹å¾è®¡ç®—å®Œæˆ ===\")\n",
    "print(f\"Beta (æ–œç‡): mean={df['beta'].mean():.6f}, std={df['beta'].std():.6f}\")\n",
    "print(f\"RÂ² (æ‹Ÿåˆåº¦): mean={df['r2'].mean():.4f}, median={df['r2'].median():.4f}\")\n",
    "print(f\"Chop (Choppiness Index): mean={df['chop'].mean():.4f}, median={df['chop'].median():.4f}\")\n",
    "print(f\"Overlap Ratio (é‡å åº¦): mean={df['overlap_ratio'].mean():.4f}, median={df['overlap_ratio'].median():.4f}\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['DengXian']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ER vs Chop æ•£ç‚¹å›¾\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# RÂ² åˆ†å¸ƒ\n",
    "axes[0].hist(df[\"r2\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].axvline(x=THR_R2_LOW, color=\"red\", linestyle=\"--\", label=f\"ä½è¶‹åŠ¿é˜ˆå€¼: {THR_R2_LOW}\")\n",
    "axes[0].set_xlabel(\"RÂ² (æ‹Ÿåˆåº¦)\")\n",
    "axes[0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0].set_title(\"RÂ² æ‹Ÿåˆåº¦åˆ†å¸ƒ\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Chop åˆ†å¸ƒ\n",
    "axes[1].hist(df[\"chop\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[1].axvline(x=THR_CHOP_HIGH, color=\"red\", linestyle=\"--\", label=f\"éœ‡è¡é˜ˆå€¼: {THR_CHOP_HIGH}\")\n",
    "axes[1].axvline(x=THR_CHOP_LOW, color=\"green\", linestyle=\"--\", label=f\"è¶‹åŠ¿é˜ˆå€¼: {THR_CHOP_LOW}\")\n",
    "axes[1].set_xlabel(\"Chop (éœ‡è¡åº¦)\")\n",
    "axes[1].set_ylabel(\"æ•°é‡\")\n",
    "axes[1].set_title(\"éœ‡è¡åº¦ (Chop) åˆ†å¸ƒ\")\n",
    "axes[1].legend()\n",
    "\n",
    "# ER vs Chop æ•£ç‚¹å›¾ (é‡‡æ ·ä»¥åŠ é€Ÿ)\n",
    "sample_idx = np.random.choice(len(df.dropna()), size=min(5000, len(df.dropna())), replace=False)\n",
    "df_sample = df.dropna().iloc[sample_idx]\n",
    "axes[2].scatter(df_sample[\"er\"], df_sample[\"chop\"], alpha=0.3, s=5)\n",
    "axes[2].set_xlabel(\"ER (æ•ˆç‡å› å­)\")\n",
    "axes[2].set_ylabel(\"Chop (Choppiness Index)\")\n",
    "axes[2].set_title(\"ER vs Chop ç›¸å…³æ€§\")\n",
    "axes[2].axvline(x=THR_ER_LOW, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "axes[2].axhline(y=THR_CHOP_HIGH, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# è®¡ç®—ç›¸å…³ç³»æ•°\n",
    "corr_er_chop = df[[\"er\", \"chop\"]].dropna().corr().iloc[0, 1]\n",
    "corr_er_overlap = df[[\"er\", \"overlap_ratio\"]].dropna().corr().iloc[0, 1]\n",
    "print(f\"\\nER vs Chop ç›¸å…³ç³»æ•°: {corr_er_chop:.4f} (åº”è¯¥ä¸å†æ˜¯ -1.0)\")\n",
    "print(f\"ER vs Overlap Ratio ç›¸å…³ç³»æ•°: {corr_er_overlap:.4f}\")\n",
    "\n",
    "print(\"\\nCell 6 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwFXH8aMnkkB"
   },
   "source": [
    "## Cell 7: Triple Barrier æ–¹å‘æ ‡ç­¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "executionInfo": {
     "elapsed": 1656,
     "status": "ok",
     "timestamp": 1765937118980,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "osWTxBZ2eX1U",
    "outputId": "25a0644d-55b6-4476-815e-94557ffc7e84"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 7: Triple Barrier æ–¹å‘æ ‡ç­¾ ==========\n",
    "\n",
    "@njit\n",
    "def triple_barrier_labels(close: np.ndarray, atr: np.ndarray,\n",
    "                          t_vert: int, pt_mult: float, sl_mult: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    ä¸ºæ¯ä¸ª bar è®¡ç®— triple barrier æ ‡ç­¾\n",
    "\n",
    "    å‚æ•°:\n",
    "        close: æ”¶ç›˜ä»·æ•°ç»„\n",
    "        atr: ATR æ•°ç»„\n",
    "        t_vert: å‚ç›´æ—¶é—´éšœç¢ (æœ€å¤§æŒæœ‰æ—¶é—´)\n",
    "        pt_mult: æ­¢ç›ˆå€æ•° (ç›¸å¯¹ ATR)\n",
    "        sl_mult: æ­¢æŸå€æ•° (ç›¸å¯¹ ATR)\n",
    "\n",
    "    è¿”å›:\n",
    "        d: æ–¹å‘æ ‡ç­¾æ•°ç»„ (-1, 0, 1)\n",
    "           +1: å…ˆè§¦åŠä¸Šè½¨ (æ­¢ç›ˆ)\n",
    "           -1: å…ˆè§¦åŠä¸‹è½¨ (æ­¢æŸ)\n",
    "            0: æœªè§¦åŠä»»ä½•è½¨é“ (æ—¶é—´æˆªæ­¢)\n",
    "    \"\"\"\n",
    "    n = len(close)\n",
    "    d = np.zeros(n, dtype=np.int32)\n",
    "\n",
    "    for t in range(n):\n",
    "        if np.isnan(atr[t]) or atr[t] <= 0:\n",
    "            d[t] = 0\n",
    "            continue\n",
    "\n",
    "        c_t = close[t]\n",
    "        upper = c_t + pt_mult * atr[t]  # æ­¢ç›ˆä¸Šè½¨\n",
    "        lower = c_t - sl_mult * atr[t]  # æ­¢æŸä¸‹è½¨\n",
    "\n",
    "        # éå†æœªæ¥è·¯å¾„\n",
    "        hit_up = False\n",
    "        hit_down = False\n",
    "        first_hit_up = n + 1\n",
    "        first_hit_down = n + 1\n",
    "\n",
    "        for j in range(1, min(t_vert + 1, n - t)):\n",
    "            future_close = close[t + j]\n",
    "\n",
    "            if future_close >= upper and not hit_up:\n",
    "                hit_up = True\n",
    "                first_hit_up = j\n",
    "\n",
    "            if future_close <= lower and not hit_down:\n",
    "                hit_down = True\n",
    "                first_hit_down = j\n",
    "\n",
    "            if hit_up and hit_down:\n",
    "                break\n",
    "\n",
    "        # åˆ¤æ–­å“ªä¸ªå…ˆè§¦åŠ\n",
    "        if hit_up and hit_down:\n",
    "            if first_hit_up < first_hit_down:\n",
    "                d[t] = 1\n",
    "            elif first_hit_down < first_hit_up:\n",
    "                d[t] = -1\n",
    "            else:\n",
    "                d[t] = 0  # åŒæ—¶è§¦åŠï¼Œæ ‡ä¸ºä¸­æ€§\n",
    "        elif hit_up:\n",
    "            d[t] = 1\n",
    "        elif hit_down:\n",
    "            d[t] = -1\n",
    "        else:\n",
    "            # æœªè§¦åŠä»»ä½•è½¨é“ï¼Œç”¨æœ€ç»ˆæ–¹å‘\n",
    "            end_idx = min(t + t_vert, n - 1)\n",
    "            if end_idx > t:\n",
    "                final_move = close[end_idx] - c_t\n",
    "                if final_move > 0:\n",
    "                    d[t] = 1\n",
    "                elif final_move < 0:\n",
    "                    d[t] = -1\n",
    "                else:\n",
    "                    d[t] = 0\n",
    "            else:\n",
    "                d[t] = 0\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "# è®¡ç®— Triple Barrier æ ‡ç­¾\n",
    "print(\"è®¡ç®— Triple Barrier æ–¹å‘æ ‡ç­¾...\")\n",
    "print(f\"å‚æ•°: T_vert={T_VERT}, pt_mult={PT_MULT}, sl_mult={SL_MULT}\")\n",
    "\n",
    "close_arr = df[\"close\"].values.astype(np.float64)\n",
    "atr_arr = df[\"atr\"].values.astype(np.float64)\n",
    "\n",
    "df[\"d_barrier\"] = triple_barrier_labels(close_arr, atr_arr, T_VERT, PT_MULT, SL_MULT)\n",
    "\n",
    "# ç»Ÿè®¡åˆ†å¸ƒ\n",
    "barrier_counts = df[\"d_barrier\"].value_counts().sort_index()\n",
    "print(\"\\n=== Triple Barrier æ ‡ç­¾åˆ†å¸ƒ ===\")\n",
    "for k, v in barrier_counts.items():\n",
    "    label_name = {-1: \"DOWN\", 0: \"NEUTRAL\", 1: \"UP\"}.get(k, str(k))\n",
    "    print(f\"  {label_name} ({k}): {v} ({v / len(df):.2%})\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['DengXian']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "barrier_counts.plot(kind=\"bar\", ax=ax, color=[\"#ef5350\", \"#ffeb3b\", \"#26a69a\"], edgecolor=\"black\")\n",
    "ax.set_xlabel(\"Triple Barrier æ ‡ç­¾\")\n",
    "ax.set_ylabel(\"æ•°é‡\")\n",
    "ax.set_title(\"Triple Barrier æ–¹å‘æ ‡ç­¾åˆ†å¸ƒ\")\n",
    "ax.set_xticklabels([\"ä¸‹è·Œ (-1)\", \"ä¸­æ€§ (0)\", \"ä¸Šæ¶¨ (+1)\"], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 7 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtbX2-CNCecB"
   },
   "source": [
    "## Cell 7.5 Tripple Barrier Version2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "executionInfo": {
     "elapsed": 1433,
     "status": "ok",
     "timestamp": 1765937451015,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "uRjvVDIcCipk",
    "outputId": "486b9e4b-3a72-4ba7-8cce-85e9506e96cc"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 7.5: Triple Barrier æ–¹å‘æ ‡ç­¾ï¼ˆR-barrier ç‰ˆï¼‰ ==========\n",
    "\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TICK_SIZE = 0.01\n",
    "LOOKBACK_N = 5\n",
    "\n",
    "@njit\n",
    "def triple_barrier_labels_R(\n",
    "    high: np.ndarray,\n",
    "    low: np.ndarray,\n",
    "    close: np.ndarray,\n",
    "    t_vert: int,\n",
    "    pt_mult: float,\n",
    "    sl_mult: float,\n",
    "    tick_size: float,\n",
    "    lookback: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    ä¸ºæ¯ä¸ª bar è®¡ç®— triple barrier æ ‡ç­¾ï¼ˆä¸ç”¨ ATRï¼Œç”¨ç»“æ„ Rï¼‰\n",
    "\n",
    "    ç»“æ„æ­¢æŸçº¿ï¼ˆå¤šå¤´ï¼‰ï¼š\n",
    "      - è‹¥å½“å‰baræ„æˆä¸Šæ¶¨å¾®é€šé“ï¼ˆHigher Lows: L[t-2] < L[t-1] < L[t]ï¼‰\n",
    "        SL_long = min(L[t-2], L[t-1], L[t]) - tick\n",
    "      - å¦åˆ™ fallback:\n",
    "        SL_long = rolling_min(low, lookback) - tick\n",
    "\n",
    "    ç»“æ„æ­¢æŸçº¿ï¼ˆç©ºå¤´ï¼‰ï¼š\n",
    "      SL_short = rolling_max(high, lookback) + tick\n",
    "      ï¼ˆå¦‚æœä½ åç»­ä¹Ÿè¦â€œä¸‹è·Œå¾®é€šé“â€ï¼Œå¯ä»¥å¯¹ç§°åŠ è¿›å»ï¼‰\n",
    "\n",
    "    é£é™©å•ä½ï¼š\n",
    "      R_long  = close[t] - SL_long\n",
    "      R_short = SL_short - close[t]\n",
    "\n",
    "    Barrierï¼š\n",
    "      upper = close[t] + pt_mult * R_long     # ä¾‹å¦‚ pt_mult=0.5 -> 0.5R\n",
    "      lower = close[t] - sl_mult * R_short    # ä¾‹å¦‚ sl_mult=1.0 -> 1R æ­¢æŸ\n",
    "\n",
    "    è§¦çº¿åˆ¤å®šï¼ˆæ›´è´´åˆâ€œçº¿â€ï¼‰ï¼š\n",
    "      hit_up   ç”¨ future_high >= upper\n",
    "      hit_down ç”¨ future_low  <= lower\n",
    "\n",
    "    è¿”å›:\n",
    "      d[t] âˆˆ {-1,0,1}\n",
    "        +1: å…ˆè§¦åŠ upper\n",
    "        -1: å…ˆè§¦åŠ lower\n",
    "         0: æ—¶é—´æˆªæ­¢ä»æœªè§¦åŠï¼ˆç”¨æœ€ç»ˆæ–¹å‘å…œåº•ï¼‰\n",
    "    \"\"\"\n",
    "    n = len(close)\n",
    "    d = np.zeros(n, dtype=np.int32)\n",
    "\n",
    "    for t in range(n):\n",
    "        c_t = close[t]\n",
    "\n",
    "        # ---------- 1) å¤šå¤´ç»“æ„æ­¢æŸçº¿ï¼šå¾®é€šé“ä¼˜å…ˆï¼Œå¦åˆ™ fallback ----------\n",
    "        # fallbackï¼šè¿‡å» lookback æ ¹ï¼ˆå«å½“å‰ï¼‰æœ€ä½ç‚¹\n",
    "        start = t - lookback + 1\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        mn_low = low[start]\n",
    "        mx_high = high[start]\n",
    "        for i in range(start + 1, t + 1):\n",
    "            if low[i] < mn_low:\n",
    "                mn_low = low[i]\n",
    "            if high[i] > mx_high:\n",
    "                mx_high = high[i]\n",
    "\n",
    "        sl_long = mn_low - tick_size\n",
    "\n",
    "        # å¾®é€šé“ï¼ˆä¸Šæ¶¨ï¼‰ï¼šL[t-2] < L[t-1] < L[t]ï¼Œä¸” t>=2\n",
    "        if t >= 2:\n",
    "            l1 = low[t - 2]\n",
    "            l2 = low[t - 1]\n",
    "            l3 = low[t]\n",
    "            if (l1 < l2) and (l2 < l3):\n",
    "                # é€šé“ä¸‹æ²¿ = ä¸‰æ ¹é‡Œæœ€ä½ low\n",
    "                mc_low = l1\n",
    "                if l2 < mc_low:\n",
    "                    mc_low = l2\n",
    "                if l3 < mc_low:\n",
    "                    mc_low = l3\n",
    "                sl_long = mc_low - tick_size\n",
    "\n",
    "        # ---------- 2) ç©ºå¤´ç»“æ„æ­¢æŸçº¿ï¼šç”¨ç»“æ„é«˜ç‚¹ï¼ˆrolling maxï¼‰ ----------\n",
    "        sl_short = mx_high + tick_size\n",
    "\n",
    "        # ---------- 3) è®¡ç®— R ----------\n",
    "        R_long = c_t - sl_long\n",
    "        R_short = sl_short - c_t\n",
    "\n",
    "        # é˜²å¾¡ï¼šæç«¯æƒ…å†µä¸‹ R<=0 ç›´æ¥ä¸­æ€§\n",
    "        if (R_long <= 0.0) or (R_short <= 0.0):\n",
    "            d[t] = 0\n",
    "            continue\n",
    "\n",
    "        # ---------- 4) barrier ----------\n",
    "        upper = c_t + pt_mult * R_long\n",
    "        lower = c_t - sl_mult * R_short\n",
    "\n",
    "        # ---------- 5) å‘å‰çœ‹ t_vertï¼Œåˆ¤æ–­è°å…ˆè§¦çº¿ ----------\n",
    "        hit_up = False\n",
    "        hit_down = False\n",
    "        first_up = n + 1\n",
    "        first_dn = n + 1\n",
    "\n",
    "        max_j = t_vert\n",
    "        if t + max_j >= n:\n",
    "            max_j = n - 1 - t\n",
    "\n",
    "        for j in range(1, max_j + 1):\n",
    "            fh = high[t + j]\n",
    "            fl = low[t + j]\n",
    "\n",
    "            if (not hit_up) and (fh >= upper):\n",
    "                hit_up = True\n",
    "                first_up = j\n",
    "            if (not hit_down) and (fl <= lower):\n",
    "                hit_down = True\n",
    "                first_dn = j\n",
    "\n",
    "            if hit_up and hit_down:\n",
    "                break\n",
    "\n",
    "        if hit_up and hit_down:\n",
    "            if first_up < first_dn:\n",
    "                d[t] = 1\n",
    "            elif first_dn < first_up:\n",
    "                d[t] = -1\n",
    "            else:\n",
    "                d[t] = 0\n",
    "        elif hit_up:\n",
    "            d[t] = 1\n",
    "        elif hit_down:\n",
    "            d[t] = -1\n",
    "        else:\n",
    "            # æ—¶é—´åˆ°ï¼šç”¨æœ€ç»ˆæ–¹å‘å…œåº•\n",
    "            end_idx = t + max_j\n",
    "            final_move = close[end_idx] - c_t\n",
    "            if final_move > 0:\n",
    "                d[t] = 1\n",
    "            elif final_move < 0:\n",
    "                d[t] = -1\n",
    "            else:\n",
    "                d[t] = 0\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "# ====== è®¡ç®— Triple Barrier æ ‡ç­¾ï¼ˆR-barrierï¼‰ ======\n",
    "print(\"è®¡ç®— Triple Barrier æ–¹å‘æ ‡ç­¾ï¼ˆR-barrierï¼‰...\")\n",
    "print(f\"å‚æ•°: T_vert={T_VERT}, pt_mult={PT_MULT} (e.g., 0.5R), sl_mult={SL_MULT} (e.g., 1R), \"\n",
    "      f\"tick={TICK_SIZE}, lookback={LOOKBACK_N}\")\n",
    "\n",
    "high_arr  = df[\"high\"].values.astype(np.float64)\n",
    "low_arr   = df[\"low\"].values.astype(np.float64)\n",
    "close_arr = df[\"close\"].values.astype(np.float64)\n",
    "\n",
    "df[\"d_barrier\"] = triple_barrier_labels_R(\n",
    "    high_arr, low_arr, close_arr,\n",
    "    T_VERT, PT_MULT, SL_MULT,\n",
    "    TICK_SIZE, LOOKBACK_N\n",
    ")\n",
    "\n",
    "# ç»Ÿè®¡åˆ†å¸ƒ\n",
    "barrier_counts = df[\"d_barrier\"].value_counts().sort_index()\n",
    "print(\"\\n=== Triple Barrier æ ‡ç­¾åˆ†å¸ƒ ===\")\n",
    "for k, v in barrier_counts.items():\n",
    "    label_name = {-1: \"DOWN\", 0: \"NEUTRAL\", 1: \"UP\"}.get(k, str(k))\n",
    "    print(f\"  {label_name} ({k}): {v} ({v / len(df):.2%})\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['DengXian']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "barrier_counts.plot(kind=\"bar\", ax=ax, color=[\"#ef5350\", \"#ffeb3b\", \"#26a69a\"], edgecolor=\"black\")\n",
    "ax.set_xlabel(\"Triple Barrier æ ‡ç­¾\")\n",
    "ax.set_ylabel(\"æ•°é‡\")\n",
    "ax.set_title(\"Triple Barrier æ–¹å‘æ ‡ç­¾åˆ†å¸ƒï¼ˆR-barrierï¼‰\")\n",
    "ax.set_xticklabels([\"ä¸‹è·Œ (-1)\", \"ä¸­æ€§ (0)\", \"ä¸Šæ¶¨ (+1)\"], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 7.5 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFUwt0t3iNGM"
   },
   "source": [
    "## Cell 8: å¸‚åœºå‘¨æœŸæ ‡ç­¾ - Step 1: è¯†åˆ«éœ‡è¡åŒºé—´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2188,
     "status": "ok",
     "timestamp": 1765492499863,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "9GCA2tvSeX1U",
    "outputId": "964b9ccb-1168-463d-99f9-30f5620db649"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 8: å¸‚åœºå‘¨æœŸæ ‡ç­¾ - Step 1: è¯†åˆ«éœ‡è¡åŒºé—´ ==========\n",
    "\n",
    "def identify_trading_range(df: pd.DataFrame,\n",
    "                           thr_er_low: float,\n",
    "                           thr_chop_high: float,\n",
    "                           thr_range_atr: float,\n",
    "                           thr_r2_low: float,\n",
    "                           thr_future_move: float,\n",
    "                           l_range_fwd: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    è¯†åˆ«éœ‡è¡/äº¤æ˜“åŒºé—´\n",
    "\n",
    "    åˆ¤å®šæ¡ä»¶ (æ»¡è¶³æ‰€æœ‰æ¡ä»¶):\n",
    "    1. ER < thr_er_low (æ•ˆç‡ä½, æ¥å›éœ‡è¡)\n",
    "    2. chop > thr_chop_high (éœ‡è¡åº¦é«˜)\n",
    "    3. range_atr < thr_range_atr (åŒºé—´ç›¸å¯¹çª„)\n",
    "    4. RÂ² < thr_r2_low (æ— æ˜æ˜¾çº¿æ€§è¶‹åŠ¿)\n",
    "    5. æœªæ¥ç§»åŠ¨ < thr_future_move * ATR (ä»åœ¨åŒºé—´å†…)\n",
    "\n",
    "    è¿”å›:\n",
    "        is_range: bool æ•°ç»„, True è¡¨ç¤ºè¯¥ bar å¤„äºäº¤æ˜“åŒºé—´\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    is_range = np.zeros(n, dtype=bool)\n",
    "\n",
    "    er = df[\"er\"].values\n",
    "    chop = df[\"chop\"].values\n",
    "    range_atr = df[\"range_atr\"].values\n",
    "    r2 = df[\"r2\"].values\n",
    "    close = df[\"close\"].values\n",
    "    atr = df[\"atr\"].values\n",
    "\n",
    "    for t in range(n):\n",
    "        # æ£€æŸ¥åŸºæœ¬æ¡ä»¶\n",
    "        if np.isnan(er[t]) or np.isnan(chop[t]) or np.isnan(range_atr[t]) or np.isnan(r2[t]):\n",
    "            continue\n",
    "        if np.isnan(atr[t]) or atr[t] <= 0:\n",
    "            continue\n",
    "\n",
    "        cond_er = er[t] < thr_er_low\n",
    "        cond_chop = chop[t] > thr_chop_high\n",
    "        cond_range = range_atr[t] < thr_range_atr\n",
    "        cond_r2 = r2[t] < thr_r2_low\n",
    "\n",
    "        # æ£€æŸ¥æœªæ¥ç§»åŠ¨ (åˆ©ç”¨å°‘é‡æœªæ¥ä¿¡æ¯)\n",
    "        future_idx = min(t + l_range_fwd, n - 1)\n",
    "        if future_idx > t:\n",
    "            future_move = abs(close[future_idx] - close[t])\n",
    "            cond_future = future_move < thr_future_move * atr[t]\n",
    "        else:\n",
    "            cond_future = True\n",
    "\n",
    "        # éœ‡è¡åŒºé—´åˆ¤å®š: æ»¡è¶³ ER + chop æ¡ä»¶ AND (range æˆ– RÂ² æˆ– future move)\n",
    "        if cond_er and cond_chop and (cond_range or cond_r2 or cond_future):\n",
    "            is_range[t] = True\n",
    "\n",
    "    return is_range\n",
    "\n",
    "\n",
    "# è®¡ç®—åˆæ­¥çš„éœ‡è¡åŒºé—´æ ‡è®°\n",
    "print(\"è¯†åˆ«éœ‡è¡/äº¤æ˜“åŒºé—´...\")\n",
    "is_range = identify_trading_range(\n",
    "    df,\n",
    "    thr_er_low=THR_ER_LOW,\n",
    "    thr_chop_high=THR_CHOP_HIGH,\n",
    "    thr_range_atr=THR_RANGE_ATR,\n",
    "    thr_r2_low=THR_R2_LOW,\n",
    "    thr_future_move=THR_FUTURE_MOVE,\n",
    "    l_range_fwd=L_RANGE_FWD\n",
    ")\n",
    "\n",
    "df[\"is_range_raw\"] = is_range\n",
    "\n",
    "# ç»Ÿè®¡\n",
    "range_count = is_range.sum()\n",
    "print(f\"\\nåˆæ­¥éœ‡è¡åŒºé—´ bar æ•°é‡: {range_count} ({range_count / len(df):.2%})\")\n",
    "\n",
    "# åº”ç”¨æœ€å°é•¿åº¦çº¦æŸ (Brooks 20-bar rule)\n",
    "# åªæœ‰è¿ç»­ >= MIN_RANGE_LEN ä¸ª bar éƒ½æ˜¯éœ‡è¡åŒºé—´ï¼Œæ‰ç¡®è®¤ä¸ºéœ‡è¡\n",
    "def apply_min_length_constraint(arr: np.ndarray, min_len: int, value: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    å¯¹è¿ç»­æ®µåº”ç”¨æœ€å°é•¿åº¦çº¦æŸ\n",
    "    \"\"\"\n",
    "    result = arr.copy()\n",
    "    n = len(arr)\n",
    "    i = 0\n",
    "\n",
    "    while i < n:\n",
    "        if arr[i] == value:\n",
    "            # æ‰¾è¿ç»­æ®µçš„ç»“æŸ\n",
    "            j = i + 1\n",
    "            while j < n and arr[j] == value:\n",
    "                j += 1\n",
    "\n",
    "            seg_len = j - i\n",
    "            if seg_len < min_len:\n",
    "                # å¤ªçŸ­ï¼Œå–æ¶ˆæ ‡è®°\n",
    "                result[i:j] = not value\n",
    "\n",
    "            i = j\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# åº”ç”¨æœ€å°é•¿åº¦çº¦æŸ\n",
    "is_range_filtered = apply_min_length_constraint(is_range, MIN_RANGE_LEN, True)\n",
    "df[\"is_range\"] = is_range_filtered\n",
    "\n",
    "range_count_filtered = is_range_filtered.sum()\n",
    "print(f\"è¿‡æ»¤åéœ‡è¡åŒºé—´ bar æ•°é‡ (min_len={MIN_RANGE_LEN}): {range_count_filtered} ({range_count_filtered / len(df):.2%})\")\n",
    "\n",
    "# æ‰©å±•è¾¹ç¼˜ (å‰åå„ 2-3 bar)\n",
    "EDGE_EXTEND = 2\n",
    "\n",
    "def extend_range_edges(arr: np.ndarray, extend: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    å¯¹éœ‡è¡åŒºé—´çš„è¾¹ç¼˜è¿›è¡Œæ‰©å±•\n",
    "    \"\"\"\n",
    "    result = arr.copy()\n",
    "    n = len(arr)\n",
    "\n",
    "    for i in range(n):\n",
    "        if arr[i]:\n",
    "            # å‘å‰æ‰©å±•\n",
    "            for k in range(1, extend + 1):\n",
    "                if i - k >= 0:\n",
    "                    result[i - k] = True\n",
    "            # å‘åæ‰©å±•\n",
    "            for k in range(1, extend + 1):\n",
    "                if i + k < n:\n",
    "                    result[i + k] = True\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "is_range_extended = extend_range_edges(is_range_filtered, EDGE_EXTEND)\n",
    "df[\"is_range_extended\"] = is_range_extended\n",
    "\n",
    "range_count_extended = is_range_extended.sum()\n",
    "print(f\"æ‰©å±•è¾¹ç¼˜åéœ‡è¡åŒºé—´ bar æ•°é‡ (extend={EDGE_EXTEND}): {range_count_extended} ({range_count_extended / len(df):.2%})\")\n",
    "\n",
    "print(\"\\nCell 8 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7c4Rja5iTt_"
   },
   "source": [
    "## Cell 9: å¸‚åœºå‘¨æœŸæ ‡ç­¾ - Step 2: è¯†åˆ«è¶‹åŠ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2199,
     "status": "ok",
     "timestamp": 1765492502065,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "G3gDyBnieX1V",
    "outputId": "8f0f0cc4-cd0f-42d5-8e69-da5cd26a52d6"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 9: å¸‚åœºå‘¨æœŸæ ‡ç­¾ - Step 2: è¯†åˆ«è¶‹åŠ¿ ==========\n",
    "\n",
    "def identify_trend(df: pd.DataFrame,\n",
    "                   is_range: np.ndarray,\n",
    "                   thr_er_high: float,\n",
    "                   thr_chop_low: float,\n",
    "                   thr_slope_norm: float,\n",
    "                   thr_dist_norm: float,\n",
    "                   l_fwd: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    è¯†åˆ«è¶‹åŠ¿ (å¯¹ééœ‡è¡åŒºé—´çš„ bar)\n",
    "\n",
    "    è¶‹åŠ¿åˆ¤å®šæ¡ä»¶:\n",
    "    1. æ–¹å‘ä¸€è‡´æ€§: sign(slope_norm) == sign(æœªæ¥æ”¶ç›Š)\n",
    "    2. æ–œç‡å¼ºåº¦: |slope_norm| > thr_slope_norm\n",
    "    3. æ•ˆç‡/è¶‹åŠ¿æ€§: ER > thr_er_high æˆ– chop < thr_chop_low\n",
    "    4. ä»·æ ¼åç¦»: |dist_norm| > thr_dist_norm (å¯é€‰)\n",
    "    5. Triple barrier æ–¹å‘ç¡®è®¤\n",
    "\n",
    "    è¿”å›:\n",
    "        regime: æ ‡ç­¾æ•°ç»„ (-1, 0, 1)\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    regime = np.zeros(n, dtype=np.int32)\n",
    "\n",
    "    close = df[\"close\"].values\n",
    "    er = df[\"er\"].values\n",
    "    chop = df[\"chop\"].values\n",
    "    slope_norm = df[\"slope_norm\"].values\n",
    "    dist_norm = df[\"dist_norm\"].values\n",
    "    d_barrier = df[\"d_barrier\"].values\n",
    "\n",
    "    for t in range(n):\n",
    "        # å¦‚æœå·²è¢«æ ‡è®°ä¸ºéœ‡è¡åŒºé—´ï¼Œç›´æ¥è®¾ä¸º 0\n",
    "        if is_range[t]:\n",
    "            regime[t] = 0\n",
    "            continue\n",
    "\n",
    "        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦æœ‰æ•ˆ\n",
    "        if (np.isnan(er[t]) or np.isnan(chop[t]) or\n",
    "            np.isnan(slope_norm[t]) or np.isnan(dist_norm[t])):\n",
    "            regime[t] = 0\n",
    "            continue\n",
    "\n",
    "        # æ£€æŸ¥æœªæ¥æ”¶ç›Šæ–¹å‘\n",
    "        future_idx = min(t + l_fwd, n - 1)\n",
    "        if future_idx > t:\n",
    "            future_return = close[future_idx] - close[t]\n",
    "            future_direction = np.sign(future_return)\n",
    "        else:\n",
    "            future_direction = 0\n",
    "\n",
    "        # è¶‹åŠ¿å€™é€‰æ¡ä»¶\n",
    "        slope_direction = np.sign(slope_norm[t])\n",
    "\n",
    "        # æ¡ä»¶1: æ–¹å‘ä¸€è‡´æ€§\n",
    "        direction_consistent = (slope_direction == future_direction) and (slope_direction != 0)\n",
    "\n",
    "        # æ¡ä»¶2: æ–œç‡å¼ºåº¦\n",
    "        slope_strong = abs(slope_norm[t]) > thr_slope_norm\n",
    "\n",
    "        # æ¡ä»¶3: æ•ˆç‡/è¶‹åŠ¿æ€§ (æ»¡è¶³å…¶ä¸€å³å¯)\n",
    "        trend_quality = (er[t] > thr_er_high) or (chop[t] < thr_chop_low)\n",
    "\n",
    "        # æ¡ä»¶4: ä»·æ ¼åç¦» (å¯é€‰åŠ å¼ºæ¡ä»¶)\n",
    "        price_deviated = abs(dist_norm[t]) > thr_dist_norm\n",
    "\n",
    "        # ç»¼åˆåˆ¤å®š\n",
    "        # å¿…é¡»æ»¡è¶³: æ–¹å‘ä¸€è‡´ + æ–œç‡å¼ºåº¦ + (è¶‹åŠ¿è´¨é‡ æˆ– ä»·æ ¼åç¦»)\n",
    "        is_trend = direction_consistent and slope_strong and (trend_quality or price_deviated)\n",
    "\n",
    "        if is_trend:\n",
    "            # å†ç”¨ triple barrier ç¡®è®¤æ–¹å‘\n",
    "            if d_barrier[t] == slope_direction:\n",
    "                regime[t] = int(slope_direction)\n",
    "            elif d_barrier[t] == 0:\n",
    "                # barrier æ— æ–¹å‘ï¼Œä½†ç»“æ„æ˜¾ç¤ºè¶‹åŠ¿ï¼Œä»ç»™è¶‹åŠ¿æ ‡ç­¾\n",
    "                regime[t] = int(slope_direction)\n",
    "            else:\n",
    "                # barrier æ–¹å‘ä¸ç»“æ„ä¸ä¸€è‡´ï¼Œæ ‡ä¸ºæ¨¡ç³Š (0)\n",
    "                regime[t] = 0\n",
    "        else:\n",
    "            regime[t] = 0\n",
    "\n",
    "    return regime\n",
    "\n",
    "\n",
    "# è¯†åˆ«è¶‹åŠ¿\n",
    "print(\"è¯†åˆ«è¶‹åŠ¿...\")\n",
    "regime_raw = identify_trend(\n",
    "    df,\n",
    "    is_range=df[\"is_range_extended\"].values,\n",
    "    thr_er_high=THR_ER_HIGH,\n",
    "    thr_chop_low=THR_CHOP_LOW,\n",
    "    thr_slope_norm=THR_SLOPE_NORM,\n",
    "    thr_dist_norm=THR_DIST_NORM,\n",
    "    l_fwd=L_FWD\n",
    ")\n",
    "\n",
    "df[\"regime_raw\"] = regime_raw\n",
    "\n",
    "# ç»Ÿè®¡\n",
    "regime_counts_raw = pd.Series(regime_raw).value_counts().sort_index()\n",
    "print(\"\\n=== åŸå§‹ Regime æ ‡ç­¾åˆ†å¸ƒ ===\")\n",
    "for k, v in regime_counts_raw.items():\n",
    "    label_name = {-1: \"DOWN (-1)\", 0: \"RANGE (0)\", 1: \"UP (+1)\"}.get(k, str(k))\n",
    "    print(f\"  {label_name}: {v} ({v / len(df):.2%})\")\n",
    "\n",
    "print(\"\\nCell 9 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3BGrvuDiXnK"
   },
   "source": [
    "## Cell 10: å¸‚åœºå‘¨æœŸæ ‡ç­¾ - Step 3: æ ‡ç­¾å¹³æ»‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "executionInfo": {
     "elapsed": 1234,
     "status": "ok",
     "timestamp": 1765492503323,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "pofwS0lGeX1V",
    "outputId": "1d216335-892f-4d6e-ce15-c73b2da50c77"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 10: å¸‚åœºå‘¨æœŸæ ‡ç­¾ - Step 3: æ ‡ç­¾å¹³æ»‘ ==========\n",
    "\n",
    "def smooth_regime_labels(regime: np.ndarray,\n",
    "                         min_trend_len: int,\n",
    "                         smooth_window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    å¯¹æ ‡ç­¾åºåˆ—è¿›è¡Œå¹³æ»‘å¤„ç†\n",
    "\n",
    "    æ­¥éª¤:\n",
    "    1. åˆ é™¤å¤ªçŸ­çš„è¶‹åŠ¿æ®µ (é•¿åº¦ < min_trend_len çš„ Â±1 æ®µæ”¹ä¸º 0)\n",
    "    2. å¤šæ•°æŠ•ç¥¨å¹³æ»‘\n",
    "\n",
    "    å‚æ•°:\n",
    "        regime: åŸå§‹æ ‡ç­¾æ•°ç»„ (-1, 0, 1)\n",
    "        min_trend_len: æœ€å°è¶‹åŠ¿æ®µé•¿åº¦\n",
    "        smooth_window: å¹³æ»‘çª—å£å¤§å°\n",
    "\n",
    "    è¿”å›:\n",
    "        smoothed: å¹³æ»‘åçš„æ ‡ç­¾æ•°ç»„\n",
    "    \"\"\"\n",
    "    n = len(regime)\n",
    "    result = regime.copy()\n",
    "\n",
    "    # Step 1: åˆ é™¤å¤ªçŸ­çš„è¶‹åŠ¿æ®µ\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if result[i] != 0:  # è¶‹åŠ¿æ®µ\n",
    "            # æ‰¾è¿ç»­æ®µçš„ç»“æŸ\n",
    "            j = i + 1\n",
    "            while j < n and result[j] == result[i]:\n",
    "                j += 1\n",
    "\n",
    "            seg_len = j - i\n",
    "            if seg_len < min_trend_len:\n",
    "                # å¤ªçŸ­ï¼Œæ”¹ä¸º 0 (éœ‡è¡)\n",
    "                result[i:j] = 0\n",
    "\n",
    "            i = j\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # Step 2: å¤šæ•°æŠ•ç¥¨å¹³æ»‘ (ä¸­å€¼æ»¤æ³¢çš„å˜ä½“)\n",
    "    half_win = smooth_window // 2\n",
    "    smoothed = result.copy()\n",
    "\n",
    "    for i in range(n):\n",
    "        start = max(0, i - half_win)\n",
    "        end = min(n, i + half_win + 1)\n",
    "        window = result[start:end]\n",
    "\n",
    "        # ç»Ÿè®¡æ¯ä¸ªæ ‡ç­¾çš„å‡ºç°æ¬¡æ•°\n",
    "        counts = {-1: 0, 0: 0, 1: 0}\n",
    "        for v in window:\n",
    "            counts[v] = counts.get(v, 0) + 1\n",
    "\n",
    "        # æ‰¾å‡ºæœ€å¤šçš„æ ‡ç­¾\n",
    "        max_count = max(counts.values())\n",
    "        candidates = [k for k, v in counts.items() if v == max_count]\n",
    "\n",
    "        # å¦‚æœæœ‰å¤šä¸ªå€™é€‰ï¼Œä¼˜å…ˆä¿æŒåŸå€¼æˆ–å– 0\n",
    "        if len(candidates) == 1:\n",
    "            smoothed[i] = candidates[0]\n",
    "        elif result[i] in candidates:\n",
    "            smoothed[i] = result[i]\n",
    "        else:\n",
    "            smoothed[i] = 0\n",
    "\n",
    "    return smoothed\n",
    "\n",
    "\n",
    "# åº”ç”¨å¹³æ»‘\n",
    "print(f\"æ ‡ç­¾å¹³æ»‘ (min_trend_len={MIN_TREND_LEN}, smooth_window={SMOOTH_WINDOW})...\")\n",
    "regime_smoothed = smooth_regime_labels(\n",
    "    df[\"regime_raw\"].values,\n",
    "    min_trend_len=MIN_TREND_LEN,\n",
    "    smooth_window=SMOOTH_WINDOW\n",
    ")\n",
    "\n",
    "df[\"regime\"] = regime_smoothed\n",
    "\n",
    "# æœ€ç»ˆç»Ÿè®¡\n",
    "regime_counts_final = pd.Series(regime_smoothed).value_counts().sort_index()\n",
    "print(\"\\n=== æœ€ç»ˆ Market Cycle æ ‡ç­¾åˆ†å¸ƒ ===\")\n",
    "total = len(df)\n",
    "for k, v in regime_counts_final.items():\n",
    "    label_name = {-1: \"DOWN (-1)\", 0: \"RANGE (0)\", 1: \"UP (+1)\"}.get(k, str(k))\n",
    "    print(f\"  {label_name}: {v:,} ({v / total:.2%})\")\n",
    "\n",
    "# ä¸ Al Brooks 80/20 è§„åˆ™å¯¹æ¯”\n",
    "range_pct = regime_counts_final.get(0, 0) / total\n",
    "trend_pct = (regime_counts_final.get(-1, 0) + regime_counts_final.get(1, 0)) / total\n",
    "print(f\"\\néœ‡è¡åŒºé—´æ¯”ä¾‹: {range_pct:.2%} (Al Brooks: ~80%)\")\n",
    "print(f\"è¶‹åŠ¿åŒºé—´æ¯”ä¾‹: {trend_pct:.2%} (Al Brooks: ~20%)\")\n",
    "\n",
    "# å¯è§†åŒ–å¯¹æ¯”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# åŸå§‹ vs å¹³æ»‘åçš„åˆ†å¸ƒ\n",
    "regime_counts_raw_series = pd.Series(df[\"regime_raw\"].values).value_counts().sort_index()\n",
    "\n",
    "width = 0.35\n",
    "x = np.arange(3)\n",
    "labels = [\"ä¸‹è·Œ (-1)\", \"éœ‡è¡ (0)\", \"ä¸Šæ¶¨ (+1)\"]\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['DengXian']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "axes[0].bar(x - width/2, [regime_counts_raw_series.get(k, 0) for k in [-1, 0, 1]],\n",
    "            width, label=\"åŸå§‹\", alpha=0.8)\n",
    "axes[0].bar(x + width/2, [regime_counts_final.get(k, 0) for k in [-1, 0, 1]],\n",
    "            width, label=\"å¹³æ»‘å\", alpha=0.8)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(labels)\n",
    "axes[0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0].set_title(\"å¸‚åœºå‘¨æœŸæ ‡ç­¾åˆ†å¸ƒå¯¹æ¯” (å¹³æ»‘å‰å)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# é¥¼å›¾\n",
    "colors = [\"#ef5350\", \"#ffeb3b\", \"#26a69a\"]\n",
    "sizes = [regime_counts_final.get(k, 0) for k in [-1, 0, 1]]\n",
    "axes[1].pie(sizes, labels=labels, colors=colors, autopct=\"%1.1f%%\", startangle=90)\n",
    "axes[1].set_title(\"æœ€ç»ˆå¸‚åœºå‘¨æœŸåˆ†å¸ƒ\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 10 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWz45EV1iald"
   },
   "source": [
    "## Cell 11: Bokeh Kçº¿å›¾å¯è§†åŒ–å‡½æ•°å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1765492503359,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "040TttXMeX1V",
    "outputId": "497cd1ad-a5b0-4bf2-df81-6e26d3c877f0"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 11: Bokeh Kçº¿å›¾å¯è§†åŒ–å‡½æ•°å®šä¹‰ ==========\n",
    "\n",
    "def plot_kline_with_regime(df_day: pd.DataFrame, title: str = \"K-line with Market Regime\") -> figure:\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶å•æ—¥ K çº¿å›¾ï¼Œå¹¶åœ¨èƒŒæ™¯ä¸Šå¡«å…… market regime é¢œè‰²\n",
    "\n",
    "    é¢œè‰²æ˜ å°„:\n",
    "    - DOWN (-1): æµ…çº¢è‰²\n",
    "    - RANGE (0): æµ…é»„è‰²\n",
    "    - UP (+1): æµ…ç»¿è‰²\n",
    "\n",
    "    Args:\n",
    "        df_day: å•æ—¥çš„ K çº¿æ•°æ® DataFrameï¼Œéœ€åŒ…å«:\n",
    "                timestamp_dt, open, high, low, close, regime\n",
    "        title: å›¾è¡¨æ ‡é¢˜\n",
    "\n",
    "    Returns:\n",
    "        Bokeh figure å¯¹è±¡\n",
    "    \"\"\"\n",
    "    df_day = df_day.copy().reset_index(drop=True)\n",
    "\n",
    "    # è®¡ç®— K çº¿çš„æ¶¨è·Œé¢œè‰²\n",
    "    df_day[\"color\"] = df_day.apply(\n",
    "        lambda row: \"#26a69a\" if row[\"close\"] >= row[\"open\"] else \"#ef5350\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # K çº¿å®½åº¦ï¼ˆæ¯«ç§’ï¼Œ5 åˆ†é’Ÿ K çº¿ç”¨ 4 åˆ†é’Ÿå®½åº¦ï¼‰\n",
    "    w = 4 * 60 * 1000  # 4 minutes in milliseconds\n",
    "\n",
    "    # åˆ›å»º ColumnDataSource\n",
    "    source = ColumnDataSource(data={\n",
    "        \"timestamp\": df_day[\"timestamp_dt\"],\n",
    "        \"open\": df_day[\"open\"],\n",
    "        \"high\": df_day[\"high\"],\n",
    "        \"low\": df_day[\"low\"],\n",
    "        \"close\": df_day[\"close\"],\n",
    "        \"color\": df_day[\"color\"],\n",
    "        \"regime\": df_day[\"regime\"].fillna(0).astype(int),\n",
    "    })\n",
    "\n",
    "    # è®¡ç®— Y è½´èŒƒå›´\n",
    "    y_min = df_day[\"low\"].min() * 0.9995\n",
    "    y_max = df_day[\"high\"].max() * 1.0005\n",
    "\n",
    "    # åˆ›å»º figure\n",
    "    p = figure(\n",
    "        title=title,\n",
    "        x_axis_type=\"datetime\",\n",
    "        width=1200,\n",
    "        height=500,\n",
    "        y_range=Range1d(y_min, y_max),\n",
    "        tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
    "        background_fill_color=\"#fafafa\",\n",
    "    )\n",
    "\n",
    "    # ---- æ·»åŠ  regime èƒŒæ™¯è‰²å— ----\n",
    "    regime_colors = {\n",
    "        -1: \"#ffcccc\",  # DOWN - æµ…çº¢è‰²\n",
    "        0: \"#ffffcc\",   # RANGE - æµ…é»„è‰²\n",
    "        1: \"#ccffcc\",   # UP - æµ…ç»¿è‰²\n",
    "    }\n",
    "\n",
    "    # æ‰¾å‡ºè¿ç»­ç›¸åŒ regime çš„åŒºé—´\n",
    "    df_day[\"regime_filled\"] = df_day[\"regime\"].fillna(0).astype(int)\n",
    "    df_day[\"regime_change\"] = (df_day[\"regime_filled\"] != df_day[\"regime_filled\"].shift()).cumsum()\n",
    "\n",
    "    regime_groups = df_day.groupby(\"regime_change\").agg({\n",
    "        \"timestamp_dt\": [\"first\", \"last\"],\n",
    "        \"regime_filled\": \"first\"\n",
    "    })\n",
    "    regime_groups.columns = [\"start_time\", \"end_time\", \"regime\"]\n",
    "\n",
    "    # ä¸ºæ¯ä¸ª regime åŒºé—´æ·»åŠ èƒŒæ™¯\n",
    "    for _, row in regime_groups.iterrows():\n",
    "        regime = int(row[\"regime\"])\n",
    "        if regime in regime_colors:\n",
    "            start = row[\"start_time\"]\n",
    "            end = row[\"end_time\"] + pd.Timedelta(minutes=5)\n",
    "\n",
    "            box = BoxAnnotation(\n",
    "                left=start,\n",
    "                right=end,\n",
    "                fill_color=regime_colors[regime],\n",
    "                fill_alpha=0.4,\n",
    "                level=\"underlay\",\n",
    "            )\n",
    "            p.add_layout(box)\n",
    "\n",
    "    # ---- ç»˜åˆ¶ K çº¿ ----\n",
    "    # å½±çº¿\n",
    "    p.segment(\n",
    "        x0=\"timestamp\", y0=\"high\",\n",
    "        x1=\"timestamp\", y1=\"low\",\n",
    "        source=source,\n",
    "        color=\"black\",\n",
    "        line_width=1,\n",
    "    )\n",
    "\n",
    "    # K çº¿å®ä½“\n",
    "    p.vbar(\n",
    "        x=\"timestamp\",\n",
    "        width=w,\n",
    "        top=\"open\",\n",
    "        bottom=\"close\",\n",
    "        source=source,\n",
    "        fill_color=\"color\",\n",
    "        line_color=\"black\",\n",
    "        line_width=0.5,\n",
    "    )\n",
    "\n",
    "    # ---- æ·»åŠ  HoverTool ----\n",
    "    hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"æ—¶é—´\", \"@timestamp{%Y-%m-%d %H:%M}\"),\n",
    "            (\"å¼€\", \"@open{0.2f}\"),\n",
    "            (\"é«˜\", \"@high{0.2f}\"),\n",
    "            (\"ä½\", \"@low{0.2f}\"),\n",
    "            (\"æ”¶\", \"@close{0.2f}\"),\n",
    "            (\"Regime\", \"@regime (-1=DOWN, 0=RANGE, 1=UP)\"),\n",
    "        ],\n",
    "        formatters={\"@timestamp\": \"datetime\"},\n",
    "        mode=\"vline\",\n",
    "    )\n",
    "    p.add_tools(hover)\n",
    "\n",
    "    # è®¾ç½®è½´æ ‡ç­¾\n",
    "    p.xaxis.axis_label = \"Time\"\n",
    "    p.yaxis.axis_label = \"Price\"\n",
    "    p.xaxis.major_label_orientation = 0.8\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def plot_multiday_kline(df_multi: pd.DataFrame, title: str = \"Multi-Day K-line\",\n",
    "                        width: int = 2400, height: int = 600) -> figure:\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶è¿ç»­å¤šæ—¥ K çº¿å›¾ï¼Œç§»é™¤ä¼‘ç›˜æ—¶é—´çš„ç©ºéš™\n",
    "    ä½¿ç”¨ index-based x è½´\n",
    "    \"\"\"\n",
    "    df = df_multi.copy().reset_index(drop=True)\n",
    "    df[\"idx\"] = df.index\n",
    "\n",
    "    # K çº¿æ¶¨è·Œé¢œè‰²\n",
    "    df[\"color\"] = df.apply(\n",
    "        lambda row: \"#26a69a\" if row[\"close\"] >= row[\"open\"] else \"#ef5350\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # æ ¼å¼åŒ–æ—¶é—´æ ‡ç­¾\n",
    "    df[\"time_label\"] = df[\"timestamp_dt\"].dt.strftime(\"%m-%d %H:%M\")\n",
    "    df[\"date_str\"] = df[\"date\"].astype(str)\n",
    "\n",
    "    bar_width = 0.6\n",
    "\n",
    "    # ColumnDataSource\n",
    "    source = ColumnDataSource(data={\n",
    "        \"idx\": df[\"idx\"],\n",
    "        \"timestamp\": df[\"timestamp_dt\"],\n",
    "        \"open\": df[\"open\"],\n",
    "        \"high\": df[\"high\"],\n",
    "        \"low\": df[\"low\"],\n",
    "        \"close\": df[\"close\"],\n",
    "        \"color\": df[\"color\"],\n",
    "        \"regime\": df[\"regime\"].fillna(0).astype(int),\n",
    "        \"date_str\": df[\"date_str\"],\n",
    "        \"time_label\": df[\"time_label\"],\n",
    "    })\n",
    "\n",
    "    # Y è½´èŒƒå›´\n",
    "    y_min = df[\"low\"].min() * 0.998\n",
    "    y_max = df[\"high\"].max() * 1.002\n",
    "\n",
    "    # åˆ›å»º figure\n",
    "    p = figure(\n",
    "        title=title,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        y_range=Range1d(y_min, y_max),\n",
    "        tools=\"pan,wheel_zoom,box_zoom,reset,save,crosshair\",\n",
    "        background_fill_color=\"#fafafa\",\n",
    "    )\n",
    "\n",
    "    p.x_range.range_padding = 0.01\n",
    "\n",
    "    # ---- æ·»åŠ  regime èƒŒæ™¯è‰²å— ----\n",
    "    regime_colors = {\n",
    "        -1: \"#ffcccc\",  # DOWN\n",
    "        0: \"#ffffcc\",   # RANGE\n",
    "        1: \"#ccffcc\",   # UP\n",
    "    }\n",
    "\n",
    "    df[\"regime_filled\"] = df[\"regime\"].fillna(0).astype(int)\n",
    "    df[\"regime_change\"] = (df[\"regime_filled\"] != df[\"regime_filled\"].shift()).cumsum()\n",
    "\n",
    "    regime_groups = df.groupby(\"regime_change\").agg({\n",
    "        \"idx\": [\"first\", \"last\"],\n",
    "        \"regime_filled\": \"first\"\n",
    "    })\n",
    "    regime_groups.columns = [\"start_idx\", \"end_idx\", \"regime\"]\n",
    "\n",
    "    for _, row in regime_groups.iterrows():\n",
    "        regime = int(row[\"regime\"])\n",
    "        if regime in regime_colors:\n",
    "            start = row[\"start_idx\"] - 0.5\n",
    "            end = row[\"end_idx\"] + 0.5\n",
    "\n",
    "            box = BoxAnnotation(\n",
    "                left=start,\n",
    "                right=end,\n",
    "                fill_color=regime_colors[regime],\n",
    "                fill_alpha=0.4,\n",
    "                level=\"underlay\",\n",
    "            )\n",
    "            p.add_layout(box)\n",
    "\n",
    "    # ---- æ·»åŠ æ—¥æœŸåˆ†å‰²çº¿ ----\n",
    "    unique_dates = df[\"date\"].unique()\n",
    "    for i, date in enumerate(unique_dates):\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        first_bar_idx = df[df[\"date\"] == date][\"idx\"].min()\n",
    "\n",
    "        vline = Span(\n",
    "            location=first_bar_idx - 0.5,\n",
    "            dimension=\"height\",\n",
    "            line_color=\"gray\",\n",
    "            line_dash=\"dashed\",\n",
    "            line_width=1.5,\n",
    "            line_alpha=0.7,\n",
    "        )\n",
    "        p.add_layout(vline)\n",
    "\n",
    "        label = Label(\n",
    "            x=first_bar_idx + 5,\n",
    "            y=y_max * 0.999,\n",
    "            text=str(date),\n",
    "            text_font_size=\"10pt\",\n",
    "            text_color=\"gray\",\n",
    "            text_align=\"left\",\n",
    "        )\n",
    "        p.add_layout(label)\n",
    "\n",
    "    # ---- ç»˜åˆ¶ K çº¿ ----\n",
    "    p.segment(\n",
    "        x0=\"idx\", y0=\"high\",\n",
    "        x1=\"idx\", y1=\"low\",\n",
    "        source=source,\n",
    "        color=\"black\",\n",
    "        line_width=1,\n",
    "    )\n",
    "\n",
    "    p.vbar(\n",
    "        x=\"idx\",\n",
    "        width=bar_width,\n",
    "        top=\"open\",\n",
    "        bottom=\"close\",\n",
    "        source=source,\n",
    "        fill_color=\"color\",\n",
    "        line_color=\"black\",\n",
    "        line_width=0.5,\n",
    "    )\n",
    "\n",
    "    # ---- X è½´æ ‡ç­¾ ----\n",
    "    tick_interval = 12  # çº¦ 1 å°æ—¶\n",
    "    tick_indices = list(range(0, len(df), tick_interval))\n",
    "\n",
    "    p.xaxis.ticker = tick_indices\n",
    "    p.xaxis.major_label_overrides = {\n",
    "        i: df.loc[i, \"time_label\"] for i in tick_indices if i < len(df)\n",
    "    }\n",
    "    p.xaxis.major_label_orientation = 0.8\n",
    "\n",
    "    # ---- HoverTool ----\n",
    "    hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"æ—¥æœŸ\", \"@date_str\"),\n",
    "            (\"æ—¶é—´\", \"@time_label\"),\n",
    "            (\"å¼€\", \"@open{0.2f}\"),\n",
    "            (\"é«˜\", \"@high{0.2f}\"),\n",
    "            (\"ä½\", \"@low{0.2f}\"),\n",
    "            (\"æ”¶\", \"@close{0.2f}\"),\n",
    "            (\"Regime\", \"@regime (-1=DOWN, 0=RANGE, 1=UP)\"),\n",
    "        ],\n",
    "        mode=\"vline\",\n",
    "    )\n",
    "    p.add_tools(hover)\n",
    "\n",
    "    p.xaxis.axis_label = \"Time\"\n",
    "    p.yaxis.axis_label = \"Price\"\n",
    "    p.title.text_font_size = \"14pt\"\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "print(\"Bokeh ç»‘å®šå‡½æ•°å·²å®šä¹‰:\")\n",
    "print(\"  - plot_kline_with_regime(df_day, title)\")\n",
    "print(\"  - plot_multiday_kline(df_multi, title, width, height)\")\n",
    "print(\"\\nCell 11 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oboJQ2p2hYu8"
   },
   "source": [
    "## Cell 12: éšæœºé€‰å–å•æ—¥ Kçº¿å›¾å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3385,
     "status": "ok",
     "timestamp": 1765492506746,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "KZMJn0ZheX1W",
    "outputId": "00955e58-6c32-456a-b742-2613f8fe68b2"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 12: éšæœºé€‰å–å•æ—¥ Kçº¿å›¾å¯è§†åŒ– ==========\n",
    "import random\n",
    "\n",
    "# å‡†å¤‡ç»˜å›¾æ•°æ®\n",
    "df_plot = df.copy().reset_index()\n",
    "df_plot[\"timestamp_dt\"] = pd.to_datetime(df_plot[\"timestamp\"].astype(str).str.slice(0, 19))\n",
    "df_plot[\"date\"] = df_plot[\"timestamp_dt\"].dt.date\n",
    "\n",
    "# è·å–æ‰€æœ‰æœ‰æ•ˆçš„äº¤æ˜“æ—¥ (æœ‰ regime æ ‡ç­¾)\n",
    "valid_dates = df_plot[df_plot[\"regime\"].notna()][\"date\"].unique()\n",
    "print(f\"æœ‰æ•ˆäº¤æ˜“æ—¥æ€»æ•°: {len(valid_dates)}\")\n",
    "\n",
    "# éšæœºé€‰å– 10 ä¸ªäº¤æ˜“æ—¥\n",
    "NUM_DAYS = 10\n",
    "# random.seed(42)\n",
    "selected_dates = sorted(random.sample(list(valid_dates), min(NUM_DAYS, len(valid_dates))))\n",
    "\n",
    "print(f\"\\né€‰å–çš„ {len(selected_dates)} ä¸ªäº¤æ˜“æ—¥:\")\n",
    "for d in selected_dates:\n",
    "    print(f\"  - {d}\")\n",
    "\n",
    "\n",
    "# ç»˜åˆ¶æ¯å¤©çš„å›¾è¡¨\n",
    "plots = []\n",
    "for date in selected_dates:\n",
    "    df_day = df_plot[df_plot[\"date\"] == date].copy()\n",
    "\n",
    "    if len(df_day) == 0:\n",
    "        print(f\"  [è·³è¿‡] {date}: æ— æ•°æ®\")\n",
    "        continue\n",
    "\n",
    "    # ç»Ÿè®¡å½“å¤©çš„ regime åˆ†å¸ƒ\n",
    "    regime_counts = df_day[\"regime\"].value_counts()\n",
    "    regime_str = \", \".join([f\"{k}:{v}\" for k, v in sorted(regime_counts.items())])\n",
    "\n",
    "    title = f\"ES 5min - {date} | Regimeåˆ†å¸ƒ: {regime_str} | DOWN=æµ…çº¢, RANGE=æµ…é»„, UP=æµ…ç»¿\"\n",
    "    p = plot_kline_with_regime(df_day, title=title)\n",
    "    plots.append(p)\n",
    "    print(f\"  [å®Œæˆ] {date}: {len(df_day)} æ ¹ K çº¿\")\n",
    "\n",
    "# æ˜¾ç¤ºå›¾è¡¨\n",
    "if plots:\n",
    "    layout = column(*plots)\n",
    "    show(layout)\n",
    "\n",
    "    # ä¿å­˜ HTML åˆ° charts ç›®å½•\n",
    "    chart_path = OUTPUT_DIR_CHARTS / \"market_cycle_random_days.html\"\n",
    "    output_file(str(chart_path))\n",
    "    save(layout, filename=str(chart_path), title=\"Market Cycle - Random Days\")\n",
    "    print(f\"\\nå›¾è¡¨å·²ä¿å­˜åˆ°: {chart_path}\")\n",
    "\n",
    "print(\"\\nCell 12 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 947
    },
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1765492508316,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "KZnPEYpZeX1W",
    "outputId": "b8c243fe-3f0f-46d8-c278-b2a8d751753f"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 13: è¿ç»­å¤šæ—¥ Kçº¿å›¾å¯è§†åŒ– ==========\n",
    "\n",
    "# é…ç½®\n",
    "NUM_CONSECUTIVE_DAYS = 10\n",
    "CHART_WIDTH = 2400\n",
    "CHART_HEIGHT = 600\n",
    "\n",
    "# å¯ä»¥æŒ‡å®šèµ·å§‹æ—¥æœŸï¼Œæˆ–éšæœºé€‰æ‹©\n",
    "START_MODE = \"random\"  # \"random\" æˆ– \"specific\"\n",
    "SPECIFIC_START_DATE = \"2023-10-01\"\n",
    "\n",
    "# è·å–æœ‰æ•ˆäº¤æ˜“æ—¥åˆ—è¡¨\n",
    "valid_dates_sorted = sorted(df_plot[df_plot[\"regime\"].notna()][\"date\"].unique())\n",
    "print(f\"æœ‰æ•ˆäº¤æ˜“æ—¥æ€»æ•°: {len(valid_dates_sorted)}\")\n",
    "\n",
    "# é€‰æ‹©è¿ç»­çš„äº¤æ˜“æ—¥\n",
    "if START_MODE == \"specific\":\n",
    "    from datetime import datetime\n",
    "    target_start = datetime.strptime(SPECIFIC_START_DATE, \"%Y-%m-%d\").date()\n",
    "    if target_start in valid_dates_sorted:\n",
    "        start_idx = valid_dates_sorted.index(target_start)\n",
    "    else:\n",
    "        later_dates = [d for d in valid_dates_sorted if d >= target_start]\n",
    "        start_idx = valid_dates_sorted.index(later_dates[0]) if later_dates else 0\n",
    "    print(f\"æŒ‡å®šèµ·å§‹æ—¥æœŸ: {SPECIFIC_START_DATE}\")\n",
    "else:\n",
    "    random.seed(123)\n",
    "    max_start_idx = len(valid_dates_sorted) - NUM_CONSECUTIVE_DAYS\n",
    "    start_idx = random.randint(0, max(0, max_start_idx))\n",
    "    print(f\"éšæœºé€‰æ‹©èµ·å§‹ç´¢å¼•: {start_idx}\")\n",
    "\n",
    "end_idx = min(start_idx + NUM_CONSECUTIVE_DAYS, len(valid_dates_sorted))\n",
    "consecutive_dates = valid_dates_sorted[start_idx:end_idx]\n",
    "\n",
    "print(f\"\\né€‰å–çš„ {len(consecutive_dates)} ä¸ªè¿ç»­äº¤æ˜“æ—¥:\")\n",
    "print(f\"  èµ·å§‹: {consecutive_dates[0]}\")\n",
    "print(f\"  ç»“æŸ: {consecutive_dates[-1]}\")\n",
    "\n",
    "# ç­›é€‰æ•°æ®\n",
    "df_multi = df_plot[df_plot[\"date\"].isin(consecutive_dates)].copy()\n",
    "df_multi = df_multi.sort_values(\"timestamp_dt\").reset_index(drop=True)\n",
    "print(f\"\\næ€» K çº¿æ•°: {len(df_multi)}\")\n",
    "\n",
    "# ç»Ÿè®¡ regime åˆ†å¸ƒ\n",
    "regime_multi_counts = df_multi[\"regime\"].value_counts().sort_index()\n",
    "print(\"\\nè¿ç»­å¤šæ—¥ Regime åˆ†å¸ƒ:\")\n",
    "for k, v in regime_multi_counts.items():\n",
    "    label_name = {-1: \"DOWN (-1)\", 0: \"RANGE (0)\", 1: \"UP (+1)\"}.get(k, str(k))\n",
    "    print(f\"  {label_name}: {v} ({v / len(df_multi):.2%})\")\n",
    "\n",
    "# ç»˜åˆ¶å¤šæ—¥è¿ç»­å›¾\n",
    "title = f\"ES 5min ({consecutive_dates[0]} ~ {consecutive_dates[-1]}) | DOWN=æµ…çº¢, RANGE=æµ…é»„, UP=æµ…ç»¿\"\n",
    "p_multi = plot_multiday_kline(df_multi, title=title, width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "\n",
    "show(p_multi)\n",
    "\n",
    "# ä¿å­˜ HTML åˆ° charts ç›®å½•\n",
    "chart_path = OUTPUT_DIR_CHARTS / \"market_cycle_multiday.html\"\n",
    "output_file(str(chart_path))\n",
    "save(p_multi, filename=str(chart_path), title=\"Market Cycle - Multi-Day\")\n",
    "print(f\"\\nè¿ç»­å¤šæ—¥å›¾è¡¨å·²ä¿å­˜åˆ°: {chart_path}\")\n",
    "\n",
    "print(\"\\nCell 13 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2223,
     "status": "ok",
     "timestamp": 1765492510557,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "clJjp144eX1W",
    "outputId": "dee068d9-8988-45d2-ef76-9825021c5fee"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 14: è‡ªå®šä¹‰æ—¥æœŸ Kçº¿å›¾å¯è§†åŒ– ==========\n",
    "# ä¿®æ”¹ custom_dates åˆ—è¡¨æ¥æŸ¥çœ‹ç‰¹å®šæ—¥æœŸ\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "custom_dates = [\n",
    "    \"2023-03-10\",\n",
    "    \"2023-06-15\",\n",
    "    \"2024-01-08\",\n",
    "    \"2024-11-05\",\n",
    "    \"2025-01-15\",\n",
    "]\n",
    "\n",
    "# è½¬æ¢ä¸º date ç±»å‹\n",
    "custom_dates_parsed = [datetime.strptime(d, \"%Y-%m-%d\").date() for d in custom_dates]\n",
    "\n",
    "# è¿‡æ»¤æœ‰æ•ˆæ—¥æœŸ\n",
    "valid_custom_dates = [d for d in custom_dates_parsed if d in set(valid_dates_sorted)]\n",
    "invalid_dates = [d for d in custom_dates_parsed if d not in set(valid_dates_sorted)]\n",
    "\n",
    "if invalid_dates:\n",
    "    print(f\"[è­¦å‘Š] ä»¥ä¸‹æ—¥æœŸæ— æœ‰æ•ˆæ•°æ®ï¼Œå°†è¢«è·³è¿‡: {invalid_dates}\")\n",
    "\n",
    "if not valid_custom_dates:\n",
    "    print(\"[é”™è¯¯] æ²¡æœ‰æœ‰æ•ˆçš„è‡ªå®šä¹‰æ—¥æœŸå¯ç»˜åˆ¶ã€‚\")\n",
    "else:\n",
    "    print(f\"å°†ç»˜åˆ¶ä»¥ä¸‹ {len(valid_custom_dates)} ä¸ªè‡ªå®šä¹‰æ—¥æœŸ:\")\n",
    "    for d in valid_custom_dates:\n",
    "        print(f\"  - {d}\")\n",
    "\n",
    "    # ç»˜åˆ¶å›¾è¡¨\n",
    "    custom_plots = []\n",
    "    for date in valid_custom_dates:\n",
    "        df_day = df_plot[df_plot[\"date\"] == date].copy()\n",
    "\n",
    "        if len(df_day) == 0:\n",
    "            print(f\"  [è·³è¿‡] {date}: æ— æ•°æ®\")\n",
    "            continue\n",
    "\n",
    "        # ç»Ÿè®¡å½“å¤©çš„ regime åˆ†å¸ƒ\n",
    "        regime_counts = df_day[\"regime\"].value_counts()\n",
    "        regime_str = \", \".join([f\"{k}:{v}\" for k, v in sorted(regime_counts.items())])\n",
    "\n",
    "        title = f\"ES 5min - {date} | Regimeåˆ†å¸ƒ: {regime_str} | DOWN=æµ…çº¢, RANGE=æµ…é»„, UP=æµ…ç»¿\"\n",
    "        p = plot_kline_with_regime(df_day, title=title)\n",
    "        custom_plots.append(p)\n",
    "        print(f\"  [å®Œæˆ] {date}: {len(df_day)} æ ¹ K çº¿\")\n",
    "\n",
    "    if custom_plots:\n",
    "        custom_layout = column(*custom_plots)\n",
    "        show(custom_layout)\n",
    "\n",
    "        # ä¿å­˜ HTML åˆ° charts ç›®å½•\n",
    "        chart_path = OUTPUT_DIR_CHARTS / \"market_cycle_custom_dates.html\"\n",
    "        output_file(str(chart_path))\n",
    "        save(custom_layout, filename=str(chart_path), title=\"Market Cycle - Custom Dates\")\n",
    "        print(f\"\\nè‡ªå®šä¹‰æ—¥æœŸå›¾è¡¨å·²ä¿å­˜åˆ°: {chart_path}\")\n",
    "\n",
    "print(\"\\nCell 14 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 18254,
     "status": "ok",
     "timestamp": 1765492528816,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "35xJmbrAeX1W",
    "outputId": "4b3a8a14-20f7-45b2-d1e2-1e924d50b1f9"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 15: å¯¼å‡ºæ ‡æ³¨æ•°æ®ä¸ç‰¹å¾çŸ©é˜µ ==========\n",
    "\n",
    "# é€‰æ‹©è¦å¯¼å‡ºçš„ç‰¹å¾åˆ—\n",
    "feature_cols = [\n",
    "    \"log_return\",       # å¯¹æ•°æ”¶ç›Š\n",
    "    \"atr\",              # ATR\n",
    "    \"range_atr\",        # ç›¸å¯¹åŒºé—´\n",
    "    \"er\",               # æ•ˆç‡å› å­\n",
    "    \"kama\",             # KAMA\n",
    "    \"slope_norm\",       # KAMA æ–œç‡æ ‡å‡†åŒ–\n",
    "    \"dist_norm\",        # ä»·æ ¼åç¦»åº¦æ ‡å‡†åŒ–\n",
    "    \"beta\",             # å›å½’æ–œç‡\n",
    "    \"r2\",               # RÂ²\n",
    "    \"chop\",             # Choppiness Index (åŸºäºATR)\n",
    "    \"overlap_ratio\",    # Bar é‡å åº¦\n",
    "    \"d_barrier\",        # Triple Barrier æ–¹å‘æ ‡ç­¾\n",
    "]\n",
    "\n",
    "# é¢å¤–çš„ä»·æ ¼å’Œæ—¶é—´ç‰¹å¾\n",
    "extra_cols = [\n",
    "    \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "]\n",
    "\n",
    "# æ ‡ç­¾åˆ—\n",
    "label_cols = [\n",
    "    \"regime\",           # æœ€ç»ˆå¸‚åœºå‘¨æœŸæ ‡ç­¾\n",
    "    \"regime_raw\",       # åŸå§‹æ ‡ç­¾ (æœªå¹³æ»‘)\n",
    "    \"is_range\",         # æ˜¯å¦ä¸ºéœ‡è¡åŒºé—´ (å¸ƒå°”)\n",
    "    \"is_range_extended\", # æ‰©å±•åçš„éœ‡è¡åŒºé—´\n",
    "]\n",
    "\n",
    "# æ„å»ºå¯¼å‡º DataFrame\n",
    "df_export = df[extra_cols + feature_cols + label_cols].copy()\n",
    "df_export = df_export.reset_index()\n",
    "\n",
    "# æ·»åŠ å¹´ä»½å’Œæ—¥æœŸåˆ—\n",
    "df_export[\"timestamp_dt\"] = pd.to_datetime(df_export[\"timestamp\"].astype(str).str.slice(0, 19))\n",
    "df_export[\"year\"] = df_export[\"timestamp_dt\"].dt.year\n",
    "df_export[\"date\"] = df_export[\"timestamp_dt\"].dt.date\n",
    "\n",
    "# è¿‡æ»¤æ‰ NaN æ ·æœ¬ (warm-up æœŸ)\n",
    "df_valid = df_export.dropna(subset=[\"regime\"])\n",
    "print(f\"æœ‰æ•ˆæ ·æœ¬æ•°: {len(df_valid)} / {len(df_export)} ({len(df_valid) / len(df_export):.2%})\")\n",
    "\n",
    "# ç»Ÿè®¡æœ€ç»ˆæ ‡ç­¾åˆ†å¸ƒ\n",
    "final_counts = df_valid[\"regime\"].value_counts().sort_index()\n",
    "print(\"\\n=== æœ€ç»ˆå¯¼å‡ºæ•°æ®çš„ Regime åˆ†å¸ƒ ===\")\n",
    "for k, v in final_counts.items():\n",
    "    label_name = {-1: \"DOWN (-1)\", 0: \"RANGE (0)\", 1: \"UP (+1)\"}.get(k, str(k))\n",
    "    print(f\"  {label_name}: {v:,} ({v / len(df_valid):.2%})\")\n",
    "\n",
    "# æŒ‰å¹´ä»½ç»Ÿè®¡\n",
    "print(\"\\n=== æŒ‰å¹´ä»½ç»Ÿè®¡ ===\")\n",
    "year_stats = df_valid.groupby(\"year\")[\"regime\"].value_counts().unstack(fill_value=0)\n",
    "year_stats[\"total\"] = year_stats.sum(axis=1)\n",
    "display(year_stats)\n",
    "\n",
    "# ä¿å­˜ä¸º CSV å’Œ Parquet åˆ° data ç›®å½•\n",
    "OUTPUT_CSV = OUTPUT_DIR_DATA / \"market_cycle_labeled_data.csv\"\n",
    "OUTPUT_PARQUET = OUTPUT_DIR_DATA / \"market_cycle_labeled_data.parquet\"\n",
    "\n",
    "df_valid.to_csv(OUTPUT_CSV, index=False)\n",
    "df_valid.to_parquet(OUTPUT_PARQUET, index=False)\n",
    "\n",
    "print(f\"\\næ•°æ®å·²å¯¼å‡º:\")\n",
    "print(f\"  - CSV: {OUTPUT_CSV}\")\n",
    "print(f\"  - Parquet: {OUTPUT_PARQUET}\")\n",
    "\n",
    "# æ„å»ºç”¨äºæ¨¡å‹è®­ç»ƒçš„ç‰¹å¾çŸ©é˜µ X å’Œæ ‡ç­¾ y\n",
    "X = df_valid[feature_cols].copy()\n",
    "y = df_valid[\"regime\"].astype(int).copy()\n",
    "\n",
    "print(f\"\\n=== æ¨¡å‹è®­ç»ƒæ•°æ® ===\")\n",
    "print(f\"ç‰¹å¾çŸ©é˜µ X shape: {X.shape}\")\n",
    "print(f\"æ ‡ç­¾ y shape: {y.shape}\")\n",
    "print(f\"ç‰¹å¾åˆ—: {feature_cols}\")\n",
    "\n",
    "# æ£€æŸ¥ç‰¹å¾çš„åŸºæœ¬ç»Ÿè®¡\n",
    "print(\"\\nç‰¹å¾ç»Ÿè®¡:\")\n",
    "display(X.describe())\n",
    "\n",
    "print(\"\\nCell 15 å®Œæˆ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1765492528995,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "9k79FgQYeX1X",
    "outputId": "f24488d4-0017-4dd7-9dfb-0d5b77b37f06"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 16: ç‰¹å¾å½’ä¸€åŒ– (Rolling Z-Score Normalization) ==========\n",
    "'''\n",
    "ğŸ“Œ å½’ä¸€åŒ–ç­–ç•¥:\n",
    "   1. å¯¹ç»å¯¹é‡çº²ç‰¹å¾ (atr, tr, bar_range, volume) è¿›è¡Œæ»šåŠ¨ Z-score å½’ä¸€åŒ–\n",
    "   2. å·²ç»æ˜¯æ¯”ä¾‹/æœ‰ç•Œçš„ç‰¹å¾ (er, chop, body_ratio ç­‰) ä¸éœ€è¦é¢å¤–å¤„ç†\n",
    "   3. åˆ é™¤åŸå§‹å°ºåº¦ç‰¹å¾ï¼Œåªä¿ç•™å½’ä¸€åŒ–ç‰ˆæœ¬\n",
    "\n",
    "ğŸ“Œ è®¾è®¡åŸåˆ™:\n",
    "   - æ¯ä¸ª t åªä½¿ç”¨è¿‡å» W æ ¹ bar çš„ç»Ÿè®¡é‡ï¼Œä¸çœ‹æœªæ¥\n",
    "   - Ïƒ å¾ˆå°æ—¶ (< eps) ç½®ä¸º 0ï¼Œé¿å…æ•°å€¼çˆ†ç‚¸\n",
    "   - å‰ W-1 æ ¹ bar çš„å½’ä¸€åŒ–å€¼è®¾ä¸º NaNï¼Œåç»­è¿‡æ»¤æ‰\n",
    "'''\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”§ ç‰¹å¾å½’ä¸€åŒ–å¤„ç†\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# æ»šåŠ¨å½’ä¸€åŒ–å‚æ•°\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "NORM_WINDOW = 100  # æ»šåŠ¨çª—å£å¤§å° (~8å°æ—¶ RTH)\n",
    "EPS = 1e-8         # é¿å…é™¤é›¶\n",
    "\n",
    "# ========== 1. å®šä¹‰éœ€è¦å½’ä¸€åŒ–çš„ç‰¹å¾ ==========\n",
    "RAW_SCALE_FEATURES = [\"atr\", \"tr\", \"bar_range\", \"volume\"]\n",
    "\n",
    "# ========== 2. æ»šåŠ¨ Z-Score å½’ä¸€åŒ–å‡½æ•° ==========\n",
    "def rolling_zscore(series: pd.Series, window: int, eps: float = 1e-8) -> pd.Series:\n",
    "    '''\n",
    "    æ»šåŠ¨ Z-Score å½’ä¸€åŒ–\n",
    "    z_t = (x_t - Î¼_t) / Ïƒ_t\n",
    "    å…¶ä¸­ Î¼_t, Ïƒ_t æ˜¯è¿‡å» window æ ¹ bar çš„å‡å€¼å’Œæ ‡å‡†å·®\n",
    "    '''\n",
    "    roll_mean = series.rolling(window=window, min_periods=window).mean()\n",
    "    roll_std = series.rolling(window=window, min_periods=window).std()\n",
    "    roll_std = roll_std.replace(0, np.nan).clip(lower=eps)\n",
    "    zscore = (series - roll_mean) / roll_std\n",
    "    return zscore\n",
    "\n",
    "# ========== 3. å¯¹ç»å¯¹é‡çº²ç‰¹å¾è¿›è¡Œæ»šåŠ¨å½’ä¸€åŒ– ==========\n",
    "print(\"\\nå¯¹ç»å¯¹é‡çº²ç‰¹å¾è¿›è¡Œæ»šåŠ¨ Z-Score å½’ä¸€åŒ–...\")\n",
    "\n",
    "for feat in RAW_SCALE_FEATURES:\n",
    "    if feat in df.columns:\n",
    "        norm_col = f\"{feat}_z\"\n",
    "        df[norm_col] = rolling_zscore(df[feat], NORM_WINDOW, EPS)\n",
    "        valid_count = df[norm_col].notna().sum()\n",
    "        print(f\"  {feat} â†’ {norm_col}: mean={df[norm_col].mean():.4f}, std={df[norm_col].std():.4f}, valid={valid_count:,}\")\n",
    "\n",
    "# ========== 4. KAMA ç‰¹æ®Šå¤„ç† ==========\n",
    "if \"kama\" in df.columns:\n",
    "    df[\"kama_z\"] = rolling_zscore(df[\"kama\"], NORM_WINDOW, EPS)\n",
    "    print(f\"  kama â†’ kama_z: mean={df['kama_z'].mean():.4f}, std={df['kama_z'].std():.4f}\")\n",
    "\n",
    "# ========== 5. Volume ç‰¹æ®Šå¤„ç† ==========\n",
    "if \"volume\" in df.columns:\n",
    "    df[\"log_volume\"] = np.log1p(df[\"volume\"])\n",
    "    df[\"log_volume_z\"] = rolling_zscore(df[\"log_volume\"], NORM_WINDOW, EPS)\n",
    "    print(f\"  volume â†’ log_volume_z: mean={df['log_volume_z'].mean():.4f}, std={df['log_volume_z'].std():.4f}\")\n",
    "\n",
    "# ========== 6. ç»Ÿè®¡å½’ä¸€åŒ–åçš„ç‰¹å¾åˆ†å¸ƒ ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ“Š å½’ä¸€åŒ–ç‰¹å¾ç»Ÿè®¡\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "new_norm_features = [c for c in df.columns if c.endswith(\"_z\") and c not in [\"range_z\", \"range_z_ma5\"]]\n",
    "print(f\"\\næ–°å¢å½’ä¸€åŒ–ç‰¹å¾: {len(new_norm_features)}\")\n",
    "for col in new_norm_features[:10]:\n",
    "    stats = df[col].describe()\n",
    "    print(f\"  {col}: min={stats['min']:.2f}, max={stats['max']:.2f}, mean={stats['mean']:.4f}\")\n",
    "\n",
    "# ========== 7. å®šä¹‰è¦ä»è®­ç»ƒä¸­æ’é™¤çš„åŸå§‹å°ºåº¦ç‰¹å¾ ==========\n",
    "FEATURES_TO_EXCLUDE_FROM_TRAINING = [\n",
    "    \"kama\",       # åŸå§‹ä»·æ ¼å°ºåº¦ â†’ ä½¿ç”¨ dist_norm æˆ– kama_z\n",
    "    \"atr\",        # åŸå§‹æ³¢åŠ¨å¹…åº¦ â†’ ä½¿ç”¨ range_atr æˆ– atr_z\n",
    "    \"tr\",         # åŸå§‹ True Range â†’ ä½¿ç”¨ atr_z\n",
    "    \"bar_range\",  # åŸå§‹ bar é«˜ä½ä»·å·® â†’ ä½¿ç”¨ range_z\n",
    "    \"d_barrier\",  # æ³„éœ²æœªæ¥ä¿¡æ¯\n",
    "    \"regime_raw\",\n",
    "    \"is_range\",\n",
    "    \"is_range_extended\",\n",
    "    \"is_range_in_trend\",\n",
    "]\n",
    "\n",
    "print(f\"\\nâš ï¸ ä»¥ä¸‹ç‰¹å¾å°†ä»è®­ç»ƒé›†ä¸­æ’é™¤:\")\n",
    "for f in FEATURES_TO_EXCLUDE_FROM_TRAINING:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(\"\\nCell 16 å®Œæˆ: ç‰¹å¾å½’ä¸€åŒ– âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 38330,
     "status": "ok",
     "timestamp": 1765492567327,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "zYywEOBPeX1X",
    "outputId": "6b36421c-8063-4643-82a3-167d219e0196"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 17: å¤šå°ºåº¦è¶‹åŠ¿ç‰¹å¾ (Multi-Scale Trend Features) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ 1.1(a) å¤šå°ºåº¦è¶‹åŠ¿å¼ºåº¦ / \"è¶‹åŠ¿èƒ½é‡\"\n",
    "   - ä¸åŒçª—å£çš„ log_close æ–œç‡: slope_short (10), slope_mid (30), slope_long (60)\n",
    "   - å¤šå°ºåº¦ä¸€è‡´æ€§æŒ‡æ ‡: trend_alignment = sign(slope_10) + sign(slope_30) + sign(slope_60)\n",
    "     - æ¥è¿‘ +3/-3: å¤šå°ºåº¦è¶‹åŠ¿åŒå‘\n",
    "     - æ¥è¿‘ 0: åˆ†æ­§å¤šï¼Œç»“æ„ä¸æ¸…æ™°ï¼ˆæ›´åƒ trading range è¾¹ç¼˜ï¼‰\n",
    "\"\"\"\n",
    "print(\"è®¡ç®—å¤šå°ºåº¦è¶‹åŠ¿ç‰¹å¾...\")\n",
    "\n",
    "# å¤šå°ºåº¦æ–œç‡çª—å£å®šä¹‰\n",
    "SLOPE_WINDOWS = [10, 30, 60]\n",
    "\n",
    "def calc_rolling_slope(log_close: pd.Series, window: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ»šåŠ¨çº¿æ€§å›å½’æ–œç‡ (å¯¹ log_close)\n",
    "    ä½¿ç”¨ç®€åŒ–çš„æœ€å°äºŒä¹˜æ³•\n",
    "    \"\"\"\n",
    "    def linreg_slope(y):\n",
    "        if len(y) < window or np.any(np.isnan(y)):\n",
    "            return np.nan\n",
    "        x = np.arange(len(y))\n",
    "        x_mean = x.mean()\n",
    "        y_mean = y.mean()\n",
    "        ss_xy = ((x - x_mean) * (y - y_mean)).sum()\n",
    "        ss_x = ((x - x_mean) ** 2).sum()\n",
    "        return ss_xy / ss_x if ss_x > 0 else 0\n",
    "\n",
    "    return log_close.rolling(window=window).apply(linreg_slope, raw=True)\n",
    "\n",
    "\n",
    "# è®¡ç®—ä¸åŒçª—å£çš„æ–œç‡\n",
    "for w in SLOPE_WINDOWS:\n",
    "    col_name = f\"slope_{w}\"\n",
    "    df[col_name] = calc_rolling_slope(df[\"log_close\"], w)\n",
    "    # æ ‡å‡†åŒ– (ç›¸å¯¹ ATR)\n",
    "    df[f\"{col_name}_norm\"] = df[col_name] / df[\"atr\"].replace(0, np.nan) * 100  # æ”¾å¤§æ˜¾ç¤º\n",
    "\n",
    "# å¤šå°ºåº¦ä¸€è‡´æ€§æŒ‡æ ‡\n",
    "df[\"trend_alignment\"] = (\n",
    "    np.sign(df[\"slope_10\"]) +\n",
    "    np.sign(df[\"slope_30\"]) +\n",
    "    np.sign(df[\"slope_60\"])\n",
    ")\n",
    "\n",
    "# ç»Ÿè®¡\n",
    "print(\"\\n=== å¤šå°ºåº¦è¶‹åŠ¿ç‰¹å¾ç»Ÿè®¡ ===\")\n",
    "for w in SLOPE_WINDOWS:\n",
    "    col = f\"slope_{w}_norm\"\n",
    "    print(f\"slope_{w}_norm: mean={df[col].mean():.4f}, std={df[col].std():.4f}\")\n",
    "\n",
    "alignment_counts = df[\"trend_alignment\"].value_counts().sort_index()\n",
    "print(f\"\\ntrend_alignment åˆ†å¸ƒ:\")\n",
    "for k, v in alignment_counts.items():\n",
    "    pct = v / len(df) * 100\n",
    "    label = {-3: \"å¼ºä¸‹è·Œ\", -2: \"å¼±ä¸‹è·Œ\", -1: \"åˆ†æ­§\", 0: \"æ— æ–¹å‘\",\n",
    "             1: \"åˆ†æ­§\", 2: \"å¼±ä¸Šæ¶¨\", 3: \"å¼ºä¸Šæ¶¨\"}.get(int(k), str(k))\n",
    "    print(f\"  {int(k):+d} ({label}): {v:,} ({pct:.1f}%)\")\n",
    "\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# å¤šå°ºåº¦æ–œç‡åˆ†å¸ƒ\n",
    "for i, w in enumerate(SLOPE_WINDOWS):\n",
    "    axes[0].hist(df[f\"slope_{w}_norm\"].dropna(), bins=50, alpha=0.5, label=f\"slope_{w}\")\n",
    "axes[0].set_xlabel(\"æ–œç‡ (æ ‡å‡†åŒ–)\")\n",
    "axes[0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0].set_title(\"å¤šå°ºåº¦æ–œç‡åˆ†å¸ƒ\")\n",
    "axes[0].legend()\n",
    "axes[0].set_xlim(-0.5, 0.5)\n",
    "\n",
    "# trend_alignment åˆ†å¸ƒ\n",
    "alignment_counts.plot(kind=\"bar\", ax=axes[1], color=\"steelblue\", edgecolor=\"black\")\n",
    "axes[1].set_xlabel(\"Trend Alignment\")\n",
    "axes[1].set_ylabel(\"æ•°é‡\")\n",
    "axes[1].set_title(\"å¤šå°ºåº¦ä¸€è‡´æ€§åˆ†å¸ƒ (Â±3=å¼ºè¶‹åŠ¿, 0=åˆ†æ­§)\")\n",
    "axes[1].set_xticklabels([f\"{int(x)}\" for x in alignment_counts.index], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 17 å®Œæˆ: å¤šå°ºåº¦è¶‹åŠ¿ç‰¹å¾ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1127,
     "status": "ok",
     "timestamp": 1765492568458,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "OHvSCGqveX1X",
    "outputId": "17f0d39b-68e3-4acd-da79-5de8764ae59a"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 18: æ–¹å‘æ€§æ³¢åŠ¨ & Range Expansion (Directional Volatility) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ 1.1(b) \"æ–¹å‘æ€§æ³¢åŠ¨\" vs \"æ— æ–¹å‘æ³¢åŠ¨\"\n",
    "   åŒºåˆ†\"é¡ºåŠ¿æ³¢åŠ¨\"å’Œ\"ä¹±æŠ–åŠ¨\"ï¼š\n",
    "   - vol_up = sum(r_i^2 for r_i > 0)\n",
    "   - vol_down = sum(r_i^2 for r_i < 0)\n",
    "   - dir_vol_ratio = |vol_up - vol_down| / vol_tot  âˆˆ [0,1]\n",
    "     - è¶Šæ¥è¿‘ 1: å•è¾¹ä¸»å¯¼ï¼ˆè¶‹åŠ¿æ›´æ˜æ˜¾ï¼‰\n",
    "     - è¶Šæ¥è¿‘ 0: ä¸Šä¸‹ä¹±æŠ–ï¼ˆå…¸å‹ rangeï¼‰\n",
    "\n",
    "ğŸ“Œ 1.1(c) Range Expansion / Compression\n",
    "   - range_z = (current_range - avg_range_N) / std_range_N\n",
    "   - å…¸å‹çš„ regime å˜åŒ–å¾€å¾€ä¼´éš range_z çš„ spike\n",
    "\"\"\"\n",
    "print(\"è®¡ç®—æ–¹å‘æ€§æ³¢åŠ¨ & Range Expansion ç‰¹å¾...\")\n",
    "\n",
    "DIR_VOL_WINDOW = 20\n",
    "RANGE_Z_WINDOW = 20\n",
    "\n",
    "# ========== 1.1(b) æ–¹å‘æ€§æ³¢åŠ¨ ==========\n",
    "def calc_directional_volatility(returns: pd.Series, window: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ–¹å‘æ€§æ³¢åŠ¨æŒ‡æ ‡\n",
    "    \"\"\"\n",
    "    # ä¸Šæ¶¨æ³¢åŠ¨ (r > 0 æ—¶çš„ r^2)\n",
    "    returns_sq = returns ** 2\n",
    "    vol_up = returns_sq.where(returns > 0, 0).rolling(window).sum()\n",
    "    vol_down = returns_sq.where(returns < 0, 0).rolling(window).sum()\n",
    "    vol_tot = vol_up + vol_down\n",
    "\n",
    "    # æ–¹å‘æ€§æ³¢åŠ¨æ¯”ç‡\n",
    "    dir_vol_ratio = (vol_up - vol_down).abs() / vol_tot.replace(0, np.nan)\n",
    "    dir_vol_ratio = dir_vol_ratio.clip(0, 1)\n",
    "\n",
    "    # ä¸Šæ¶¨æ³¢åŠ¨å æ¯” (åˆ¤æ–­æ–¹å‘)\n",
    "    vol_up_ratio = vol_up / vol_tot.replace(0, np.nan)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"vol_up\": vol_up,\n",
    "        \"vol_down\": vol_down,\n",
    "        \"vol_tot\": vol_tot,\n",
    "        \"dir_vol_ratio\": dir_vol_ratio,\n",
    "        \"vol_up_ratio\": vol_up_ratio,\n",
    "    })\n",
    "\n",
    "\n",
    "dir_vol_df = calc_directional_volatility(df[\"log_return\"], DIR_VOL_WINDOW)\n",
    "df[\"dir_vol_ratio\"] = dir_vol_df[\"dir_vol_ratio\"]\n",
    "df[\"vol_up_ratio\"] = dir_vol_df[\"vol_up_ratio\"]\n",
    "\n",
    "# ========== 1.1(c) Range Expansion / Compression ==========\n",
    "df[\"bar_range\"] = df[\"high\"] - df[\"low\"]\n",
    "df[\"avg_range\"] = df[\"bar_range\"].rolling(RANGE_Z_WINDOW).mean()\n",
    "df[\"std_range\"] = df[\"bar_range\"].rolling(RANGE_Z_WINDOW).std()\n",
    "df[\"range_z\"] = (df[\"bar_range\"] - df[\"avg_range\"]) / df[\"std_range\"].replace(0, np.nan)\n",
    "\n",
    "# Range z-score çš„æ»šåŠ¨å‡å€¼ (ç”¨äºæ£€æµ‹æŒç»­å‹ç¼©/æ‰©å¼ )\n",
    "df[\"range_z_ma5\"] = df[\"range_z\"].rolling(5).mean()\n",
    "\n",
    "# ç»Ÿè®¡\n",
    "print(\"\\n=== æ–¹å‘æ€§æ³¢åŠ¨ç‰¹å¾ç»Ÿè®¡ ===\")\n",
    "print(f\"dir_vol_ratio: mean={df['dir_vol_ratio'].mean():.4f}, median={df['dir_vol_ratio'].median():.4f}\")\n",
    "print(f\"vol_up_ratio: mean={df['vol_up_ratio'].mean():.4f} (0.5=å¹³è¡¡, >0.5=ä¸Šæ¶¨ä¸»å¯¼)\")\n",
    "\n",
    "print(f\"\\n=== Range Expansion ç‰¹å¾ç»Ÿè®¡ ===\")\n",
    "print(f\"range_z: mean={df['range_z'].mean():.4f}, std={df['range_z'].std():.4f}\")\n",
    "print(f\"range_z_ma5: mean={df['range_z_ma5'].mean():.4f}\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# dir_vol_ratio åˆ†å¸ƒ\n",
    "axes[0].hist(df[\"dir_vol_ratio\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].axvline(x=0.5, color=\"red\", linestyle=\"--\", label=\"ä¸­æ€§çº¿ 0.5\")\n",
    "axes[0].set_xlabel(\"dir_vol_ratio\")\n",
    "axes[0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0].set_title(\"æ–¹å‘æ€§æ³¢åŠ¨æ¯”ç‡åˆ†å¸ƒ\\n(é«˜=å•è¾¹, ä½=éœ‡è¡)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# vol_up_ratio åˆ†å¸ƒ\n",
    "axes[1].hist(df[\"vol_up_ratio\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7, color=\"green\")\n",
    "axes[1].axvline(x=0.5, color=\"red\", linestyle=\"--\", label=\"å¹³è¡¡çº¿ 0.5\")\n",
    "axes[1].set_xlabel(\"vol_up_ratio\")\n",
    "axes[1].set_ylabel(\"æ•°é‡\")\n",
    "axes[1].set_title(\"ä¸Šæ¶¨æ³¢åŠ¨å æ¯”\\n(>0.5=ä¸Šæ¶¨ä¸»å¯¼)\")\n",
    "axes[1].legend()\n",
    "\n",
    "# range_z åˆ†å¸ƒ\n",
    "axes[2].hist(df[\"range_z\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7, color=\"orange\")\n",
    "axes[2].axvline(x=0, color=\"red\", linestyle=\"--\", label=\"å¹³å‡æ°´å¹³\")\n",
    "axes[2].axvline(x=2, color=\"green\", linestyle=\"--\", label=\"+2Ïƒ (æ‰©å¼ )\")\n",
    "axes[2].axvline(x=-1, color=\"blue\", linestyle=\"--\", label=\"-1Ïƒ (å‹ç¼©)\")\n",
    "axes[2].set_xlabel(\"range_z\")\n",
    "axes[2].set_ylabel(\"æ•°é‡\")\n",
    "axes[2].set_title(\"Range Z-Score åˆ†å¸ƒ\\n(æ­£=æ‰©å¼ , è´Ÿ=å‹ç¼©)\")\n",
    "axes[2].legend()\n",
    "axes[2].set_xlim(-3, 5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 18 å®Œæˆ: æ–¹å‘æ€§æ³¢åŠ¨ & Range Expansion âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1293,
     "status": "ok",
     "timestamp": 1765492569756,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "7_KkdcEkeX1X",
    "outputId": "415ca504-8d79-4424-e0eb-ba1403a6fca2"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 19: å¤šç©º Bar ç»“æ„ & è¿ç»­æ€§ (Bull/Bear Bar Structure) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ 1.2(a) Brooks å¾ˆçœ‹\"è¿ç»­å‡ æ ¹ bull/bear bar\"\n",
    "   - bull_ratio_N: çª—å£å†…é˜³çº¿æ¯”ä¾‹\n",
    "   - bear_ratio_N: çª—å£å†…é˜´çº¿æ¯”ä¾‹\n",
    "   - consec_bull: å½“å‰å‘å‰è¿ç»­çš„é˜³çº¿æ•°é‡\n",
    "   - consec_bear: å½“å‰å‘å‰è¿ç»­çš„é˜´çº¿æ•°é‡\n",
    "\n",
    "   è¶‹åŠ¿æ®µä¸­å¸¸è§: bull_ratio æé«˜ä¸” consec_bull > 3\n",
    "   éœ‡è¡æ®µä¸­å¤šä¸º: 1-1ã€2-1 äº’æ¢ã€bull/bear æ··æ‚\n",
    "\"\"\"\n",
    "print(\"è®¡ç®—å¤šç©º Bar ç»“æ„ç‰¹å¾...\")\n",
    "\n",
    "BAR_STRUCTURE_WINDOW = 10\n",
    "\n",
    "# ========== Bull/Bear åˆ¤å®š ==========\n",
    "# é˜³çº¿: close > open, é˜´çº¿: close < open\n",
    "df[\"is_bull\"] = (df[\"close\"] > df[\"open\"]).astype(int)\n",
    "df[\"is_bear\"] = (df[\"close\"] < df[\"open\"]).astype(int)\n",
    "df[\"is_doji\"] = (df[\"close\"] == df[\"open\"]).astype(int)  # åå­—æ˜Ÿ\n",
    "\n",
    "# ========== çª—å£å†…æ¯”ä¾‹ ==========\n",
    "df[\"bull_ratio\"] = df[\"is_bull\"].rolling(BAR_STRUCTURE_WINDOW).mean()\n",
    "df[\"bear_ratio\"] = df[\"is_bear\"].rolling(BAR_STRUCTURE_WINDOW).mean()\n",
    "\n",
    "# Bull - Bear å·®å¼‚ (æ­£=å¤šå¤´ä¸»å¯¼, è´Ÿ=ç©ºå¤´ä¸»å¯¼)\n",
    "df[\"bull_bear_diff\"] = df[\"bull_ratio\"] - df[\"bear_ratio\"]\n",
    "\n",
    "# ========== è¿ç»­æ€§è®¡ç®— ==========\n",
    "@njit\n",
    "def calc_consecutive_bars(is_bull: np.ndarray, is_bear: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    è®¡ç®—è¿ç»­é˜³çº¿/é˜´çº¿æ•°é‡\n",
    "    \"\"\"\n",
    "    n = len(is_bull)\n",
    "    consec_bull = np.zeros(n, dtype=np.int32)\n",
    "    consec_bear = np.zeros(n, dtype=np.int32)\n",
    "\n",
    "    for i in range(n):\n",
    "        # è¿ç»­é˜³çº¿\n",
    "        if is_bull[i]:\n",
    "            if i == 0:\n",
    "                consec_bull[i] = 1\n",
    "            else:\n",
    "                consec_bull[i] = consec_bull[i-1] + 1 if is_bull[i-1] else 1\n",
    "        else:\n",
    "            consec_bull[i] = 0\n",
    "\n",
    "        # è¿ç»­é˜´çº¿\n",
    "        if is_bear[i]:\n",
    "            if i == 0:\n",
    "                consec_bear[i] = 1\n",
    "            else:\n",
    "                consec_bear[i] = consec_bear[i-1] + 1 if is_bear[i-1] else 1\n",
    "        else:\n",
    "            consec_bear[i] = 0\n",
    "\n",
    "    return consec_bull, consec_bear\n",
    "\n",
    "\n",
    "consec_bull, consec_bear = calc_consecutive_bars(\n",
    "    df[\"is_bull\"].values.astype(np.int32),\n",
    "    df[\"is_bear\"].values.astype(np.int32)\n",
    ")\n",
    "df[\"consec_bull\"] = consec_bull\n",
    "df[\"consec_bear\"] = consec_bear\n",
    "\n",
    "# æœ€è¿‘ N æ ¹å†…æœ€å¤§è¿ç»­æ®µ\n",
    "df[\"max_consec_bull_10\"] = df[\"consec_bull\"].rolling(10).max()\n",
    "df[\"max_consec_bear_10\"] = df[\"consec_bear\"].rolling(10).max()\n",
    "\n",
    "# ========== ç»Ÿè®¡ ==========\n",
    "print(\"\\n=== Bull/Bear æ¯”ä¾‹ç»Ÿè®¡ ===\")\n",
    "print(f\"bull_ratio: mean={df['bull_ratio'].mean():.4f}\")\n",
    "print(f\"bear_ratio: mean={df['bear_ratio'].mean():.4f}\")\n",
    "print(f\"bull_bear_diff: mean={df['bull_bear_diff'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\n=== è¿ç»­æ€§ç»Ÿè®¡ ===\")\n",
    "print(f\"consec_bull: max={df['consec_bull'].max()}, mean={df['consec_bull'].mean():.2f}\")\n",
    "print(f\"consec_bear: max={df['consec_bear'].max()}, mean={df['consec_bear'].mean():.2f}\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# bull/bear ratio åˆ†å¸ƒ\n",
    "axes[0].hist(df[\"bull_ratio\"].dropna(), bins=30, alpha=0.6, label=\"bull_ratio\", color=\"green\")\n",
    "axes[0].hist(df[\"bear_ratio\"].dropna(), bins=30, alpha=0.6, label=\"bear_ratio\", color=\"red\")\n",
    "axes[0].axvline(x=0.5, color=\"black\", linestyle=\"--\", label=\"å¹³è¡¡çº¿\")\n",
    "axes[0].set_xlabel(\"æ¯”ä¾‹\")\n",
    "axes[0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0].set_title(f\"Bull/Bear æ¯”ä¾‹åˆ†å¸ƒ (çª—å£={BAR_STRUCTURE_WINDOW})\")\n",
    "axes[0].legend()\n",
    "\n",
    "# bull_bear_diff åˆ†å¸ƒ\n",
    "axes[1].hist(df[\"bull_bear_diff\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[1].axvline(x=0, color=\"red\", linestyle=\"--\", label=\"å¹³è¡¡\")\n",
    "axes[1].set_xlabel(\"bull_ratio - bear_ratio\")\n",
    "axes[1].set_ylabel(\"æ•°é‡\")\n",
    "axes[1].set_title(\"å¤šç©ºå·®å¼‚åˆ†å¸ƒ\\n(æ­£=å¤šå¤´ä¸»å¯¼)\")\n",
    "axes[1].legend()\n",
    "\n",
    "# è¿ç»­æ€§åˆ†å¸ƒ\n",
    "consec_bull_counts = pd.Series(consec_bull).value_counts().sort_index()\n",
    "consec_bear_counts = pd.Series(consec_bear).value_counts().sort_index()\n",
    "x_range = range(0, min(15, max(consec_bull_counts.index.max(), consec_bear_counts.index.max()) + 1))\n",
    "axes[2].bar([x - 0.2 for x in x_range],\n",
    "            [consec_bull_counts.get(x, 0) for x in x_range],\n",
    "            width=0.4, label=\"è¿ç»­é˜³çº¿\", color=\"green\", alpha=0.7)\n",
    "axes[2].bar([x + 0.2 for x in x_range],\n",
    "            [consec_bear_counts.get(x, 0) for x in x_range],\n",
    "            width=0.4, label=\"è¿ç»­é˜´çº¿\", color=\"red\", alpha=0.7)\n",
    "axes[2].set_xlabel(\"è¿ç»­ Bar æ•°é‡\")\n",
    "axes[2].set_ylabel(\"å‡ºç°æ¬¡æ•°\")\n",
    "axes[2].set_title(\"è¿ç»­ Bull/Bear Bar åˆ†å¸ƒ\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 19 å®Œæˆ: å¤šç©º Bar ç»“æ„ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1765492571138,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "UVh1bZMceX1Y",
    "outputId": "9af1a3d5-f584-4d7c-a9d2-1cf5cf44682a"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 20: å®ä½“/å½±çº¿ç»“æ„ (Body & Wick Ratios) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ 1.2(b) Brooks é£æ ¼çš„å®ä½“/å½±çº¿åˆ†æï¼ˆä¸åšæ—¥å¼å½¢æ€åï¼‰\n",
    "   å¯¹æ¯æ ¹ bar:\n",
    "   - body_ratio = |close - open| / range  (å®ä½“å æ¯”)\n",
    "   - upper_wick_ratio = (high - max(open, close)) / range (ä¸Šå½±çº¿å æ¯”)\n",
    "   - lower_wick_ratio = (min(open, close) - low) / range (ä¸‹å½±çº¿å æ¯”)\n",
    "\n",
    "   çª—å£å‡å€¼è§£è¯»:\n",
    "   - avg_body_ratio ä½ + å¤šå½±çº¿ â‡’ å…¸å‹ trading range\n",
    "   - avg_body_ratio é«˜ + bull/bear æç«¯ â‡’ è¶‹åŠ¿æ®µ\n",
    "   - Brooks: \"lots of tails, especially both sides â‡’ trading range\"\n",
    "\"\"\"\n",
    "print(\"è®¡ç®—å®ä½“/å½±çº¿ç»“æ„ç‰¹å¾...\")\n",
    "\n",
    "WICK_WINDOW = 10\n",
    "\n",
    "# ========== å• Bar çš„å®ä½“/å½±çº¿æ¯”ä¾‹ ==========\n",
    "df[\"body\"] = (df[\"close\"] - df[\"open\"]).abs()\n",
    "df[\"upper_wick\"] = df[\"high\"] - df[[\"open\", \"close\"]].max(axis=1)\n",
    "df[\"lower_wick\"] = df[[\"open\", \"close\"]].min(axis=1) - df[\"low\"]\n",
    "\n",
    "# æ¯”ä¾‹ (é¿å…é™¤ä»¥0)\n",
    "bar_range = df[\"bar_range\"].replace(0, np.nan)\n",
    "df[\"body_ratio\"] = df[\"body\"] / bar_range\n",
    "df[\"upper_wick_ratio\"] = df[\"upper_wick\"] / bar_range\n",
    "df[\"lower_wick_ratio\"] = df[\"lower_wick\"] / bar_range\n",
    "\n",
    "# åŒå½±çº¿æ¯”ä¾‹ (ä¸Šä¸‹å½±çº¿ä¹‹å’Œ)\n",
    "df[\"total_wick_ratio\"] = df[\"upper_wick_ratio\"] + df[\"lower_wick_ratio\"]\n",
    "\n",
    "# ========== çª—å£å‡å€¼ ==========\n",
    "df[\"avg_body_ratio\"] = df[\"body_ratio\"].rolling(WICK_WINDOW).mean()\n",
    "df[\"avg_upper_wick_ratio\"] = df[\"upper_wick_ratio\"].rolling(WICK_WINDOW).mean()\n",
    "df[\"avg_lower_wick_ratio\"] = df[\"lower_wick_ratio\"].rolling(WICK_WINDOW).mean()\n",
    "df[\"avg_total_wick_ratio\"] = df[\"total_wick_ratio\"].rolling(WICK_WINDOW).mean()\n",
    "\n",
    "# ========== å°å®ä½“/å¤§å½±çº¿çš„ bar æ•°é‡ (Brooks æ‰€è¯´çš„ trading range ç‰¹å¾) ==========\n",
    "# å®šä¹‰: body_ratio < 0.3 ä¸” total_wick_ratio > 0.5\n",
    "df[\"is_doji_like\"] = ((df[\"body_ratio\"] < 0.3) & (df[\"total_wick_ratio\"] > 0.5)).astype(int)\n",
    "df[\"doji_like_ratio\"] = df[\"is_doji_like\"].rolling(WICK_WINDOW).mean()\n",
    "\n",
    "# ========== ç»Ÿè®¡ ==========\n",
    "print(\"\\n=== å• Bar å®ä½“/å½±çº¿ç»Ÿè®¡ ===\")\n",
    "print(f\"body_ratio: mean={df['body_ratio'].mean():.4f}, median={df['body_ratio'].median():.4f}\")\n",
    "print(f\"upper_wick_ratio: mean={df['upper_wick_ratio'].mean():.4f}\")\n",
    "print(f\"lower_wick_ratio: mean={df['lower_wick_ratio'].mean():.4f}\")\n",
    "print(f\"total_wick_ratio: mean={df['total_wick_ratio'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\n=== çª—å£å‡å€¼ (N={WICK_WINDOW}) ===\")\n",
    "print(f\"avg_body_ratio: mean={df['avg_body_ratio'].mean():.4f}\")\n",
    "print(f\"avg_total_wick_ratio: mean={df['avg_total_wick_ratio'].mean():.4f}\")\n",
    "print(f\"doji_like_ratio: mean={df['doji_like_ratio'].mean():.4f} (å°å®ä½“å¤§å½±çº¿çš„æ¯”ä¾‹)\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# å• bar body_ratio åˆ†å¸ƒ\n",
    "axes[0, 0].hist(df[\"body_ratio\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[0, 0].axvline(x=0.3, color=\"red\", linestyle=\"--\", label=\"å°å®ä½“é˜ˆå€¼ 0.3\")\n",
    "axes[0, 0].axvline(x=0.7, color=\"green\", linestyle=\"--\", label=\"å¤§å®ä½“é˜ˆå€¼ 0.7\")\n",
    "axes[0, 0].set_xlabel(\"body_ratio\")\n",
    "axes[0, 0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0, 0].set_title(\"å• Bar å®ä½“æ¯”ä¾‹åˆ†å¸ƒ\")\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# å• bar å½±çº¿åˆ†å¸ƒ\n",
    "axes[0, 1].hist(df[\"upper_wick_ratio\"].dropna(), bins=50, alpha=0.6, label=\"ä¸Šå½±çº¿\", color=\"orange\")\n",
    "axes[0, 1].hist(df[\"lower_wick_ratio\"].dropna(), bins=50, alpha=0.6, label=\"ä¸‹å½±çº¿\", color=\"purple\")\n",
    "axes[0, 1].set_xlabel(\"wick_ratio\")\n",
    "axes[0, 1].set_ylabel(\"æ•°é‡\")\n",
    "axes[0, 1].set_title(\"ä¸Š/ä¸‹å½±çº¿æ¯”ä¾‹åˆ†å¸ƒ\")\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# çª—å£å‡å€¼ body vs wick\n",
    "axes[1, 0].scatter(df[\"avg_body_ratio\"].dropna().values[::100],\n",
    "                   df[\"avg_total_wick_ratio\"].dropna().values[::100],\n",
    "                   alpha=0.3, s=5)\n",
    "axes[1, 0].set_xlabel(\"avg_body_ratio\")\n",
    "axes[1, 0].set_ylabel(\"avg_total_wick_ratio\")\n",
    "axes[1, 0].set_title(f\"çª—å£å‡å€¼: å®ä½“ vs å½±çº¿ (N={WICK_WINDOW})\\n(é‡‡æ ·æ˜¾ç¤º)\")\n",
    "axes[1, 0].axhline(y=0.5, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "axes[1, 0].axvline(x=0.5, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# doji_like_ratio åˆ†å¸ƒ\n",
    "axes[1, 1].hist(df[\"doji_like_ratio\"].dropna(), bins=30, edgecolor=\"black\", alpha=0.7, color=\"gray\")\n",
    "axes[1, 1].set_xlabel(\"doji_like_ratio\")\n",
    "axes[1, 1].set_ylabel(\"æ•°é‡\")\n",
    "axes[1, 1].set_title(\"å°å®ä½“å¤§å½±çº¿ Bar æ¯”ä¾‹åˆ†å¸ƒ\\n(é«˜=å…¸å‹éœ‡è¡åŒºé—´)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 20 å®Œæˆ: å®ä½“/å½±çº¿ç»“æ„ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1765492572368,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "xQwcOBkeeX1Y",
    "outputId": "9038f3ff-0d89-4af2-e276-2914823bc914"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 21: ä¸‰é‡è…¿ç»“æ„ (Three-Type Leg Structure) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ 1.2(c) Leg Structure Metrics â€” Brooks é£æ ¼çš„è…¿ç»“æ„é‡åŒ–\n",
    "\n",
    "ä¸‰ç§è…¿çš„å®šä¹‰:\n",
    "1. Leg Type A (Major Legs): Spike Break Leg â€” ç»“æ„æ€§çªç ´è…¿\n",
    "   - ä¸Šæ¶¨ä¸­: æŸæ ¹ bar çš„ low è·Œç ´å‰ä¸€æ ¹ bar çš„ low â†’ æ–° major leg å¼€å§‹\n",
    "   - ä¸‹è·Œä¸­: æŸæ ¹ bar çš„ high çªç ´å‰ä¸€æ ¹ bar çš„ high â†’ æ–° major leg å¼€å§‹\n",
    "\n",
    "2. Leg Type B (Micro Legs): Opposite Close Leg â€” å¯¹å‘æ”¶ç›˜è…¿\n",
    "   - ä¸Šæ¶¨ä¸­: å‡ºç°ä¸€æ ¹é˜´çº¿ (close < open) â†’ æ–° micro leg\n",
    "   - ä¸‹è·Œä¸­: å‡ºç°ä¸€æ ¹é˜³çº¿ (close > open) â†’ æ–° micro leg\n",
    "\n",
    "3. Leg Type C (Fractal Legs): Implied Pullback Leg â€” éšå«å›è°ƒè…¿\n",
    "   - åŸºäºé‡å åº¦ã€å°å®ä½“ã€å½±çº¿ç­‰ç»“æ„ä¿¡å·åˆ¤å®š\n",
    "   - æ¨¡æ‹Ÿæ›´å°æ—¶é—´å‘¨æœŸä¸Šçš„ pullback ä¿¡æ¯\n",
    "\n",
    "è¾“å‡ºç‰¹å¾:\n",
    "- legA_id, legA_dir, legA_prev1_dir, legA_prev2_dir\n",
    "- legB_id, legB_dir, legB_prev1_dir, legB_prev2_dir\n",
    "- legC_id, legC_dir, legC_prev1_dir, legC_prev2_dir\n",
    "\"\"\"\n",
    "print(\"è®¡ç®—ä¸‰é‡è…¿ç»“æ„ç‰¹å¾ (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...\")\n",
    "\n",
    "@njit\n",
    "def calc_leg_type_A(high: np.ndarray, low: np.ndarray, close: np.ndarray, open_: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    è®¡ç®— Leg Type A: Spike Break Legs (Major Legs)\n",
    "\n",
    "    è§„åˆ™:\n",
    "    - ä¸Šæ¶¨è¶‹åŠ¿ä¸­: low è·Œç ´å‰ä¸€æ ¹ low â†’ æ–°è…¿å¼€å§‹\n",
    "    - ä¸‹è·Œè¶‹åŠ¿ä¸­: high çªç ´å‰ä¸€æ ¹ high â†’ æ–°è…¿å¼€å§‹\n",
    "    - åˆå§‹æ–¹å‘ç”±ç¬¬ä¸€æ ¹ bar çš„ close-open å†³å®š\n",
    "    \"\"\"\n",
    "    n = len(high)\n",
    "    leg_id = np.zeros(n, dtype=np.int32)\n",
    "    leg_dir = np.zeros(n, dtype=np.int32)\n",
    "\n",
    "    # åˆå§‹åŒ–\n",
    "    current_leg_id = 1\n",
    "    if close[0] >= open_[0]:\n",
    "        current_dir = 1  # ä¸Šæ¶¨\n",
    "    else:\n",
    "        current_dir = -1  # ä¸‹è·Œ\n",
    "\n",
    "    leg_id[0] = current_leg_id\n",
    "    leg_dir[0] = current_dir\n",
    "\n",
    "    for i in range(1, n):\n",
    "        new_leg = False\n",
    "\n",
    "        if current_dir == 1:  # å½“å‰ä¸Šæ¶¨è…¿\n",
    "            # å¦‚æœ low è·Œç ´å‰ä¸€æ ¹ low â†’ ç»“æ„æ€§ç ´å â†’ æ–°è…¿\n",
    "            if low[i] < low[i-1]:\n",
    "                new_leg = True\n",
    "                # æ–°è…¿æ–¹å‘ç”±å½“å‰ bar å†³å®š\n",
    "                if close[i] >= open_[i]:\n",
    "                    current_dir = 1\n",
    "                else:\n",
    "                    current_dir = -1\n",
    "        else:  # å½“å‰ä¸‹è·Œè…¿\n",
    "            # å¦‚æœ high çªç ´å‰ä¸€æ ¹ high â†’ ç»“æ„æ€§ç ´å â†’ æ–°è…¿\n",
    "            if high[i] > high[i-1]:\n",
    "                new_leg = True\n",
    "                if close[i] >= open_[i]:\n",
    "                    current_dir = 1\n",
    "                else:\n",
    "                    current_dir = -1\n",
    "\n",
    "        if new_leg:\n",
    "            current_leg_id += 1\n",
    "\n",
    "        leg_id[i] = current_leg_id\n",
    "        leg_dir[i] = current_dir\n",
    "\n",
    "    return leg_id, leg_dir\n",
    "\n",
    "\n",
    "@njit\n",
    "def calc_leg_type_B(close: np.ndarray, open_: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    è®¡ç®— Leg Type B: Opposite Close Legs (Micro Legs)\n",
    "\n",
    "    è§„åˆ™:\n",
    "    - å½“å‰ä¸Šæ¶¨è…¿ä¸­ï¼Œå‡ºç°é˜´çº¿ â†’ æ–°è…¿ï¼ˆæ–¹å‘ç¿»è½¬ï¼‰\n",
    "    - å½“å‰ä¸‹è·Œè…¿ä¸­ï¼Œå‡ºç°é˜³çº¿ â†’ æ–°è…¿ï¼ˆæ–¹å‘ç¿»è½¬ï¼‰\n",
    "    \"\"\"\n",
    "    n = len(close)\n",
    "    leg_id = np.zeros(n, dtype=np.int32)\n",
    "    leg_dir = np.zeros(n, dtype=np.int32)\n",
    "\n",
    "    current_leg_id = 1\n",
    "    if close[0] >= open_[0]:\n",
    "        current_dir = 1\n",
    "    else:\n",
    "        current_dir = -1\n",
    "\n",
    "    leg_id[0] = current_leg_id\n",
    "    leg_dir[0] = current_dir\n",
    "\n",
    "    for i in range(1, n):\n",
    "        bar_dir = 1 if close[i] >= open_[i] else -1\n",
    "\n",
    "        # å¦‚æœå½“å‰ bar æ–¹å‘ä¸è…¿æ–¹å‘ç›¸å â†’ æ–°è…¿\n",
    "        if bar_dir != current_dir:\n",
    "            current_leg_id += 1\n",
    "            current_dir = bar_dir\n",
    "\n",
    "        leg_id[i] = current_leg_id\n",
    "        leg_dir[i] = current_dir\n",
    "\n",
    "    return leg_id, leg_dir\n",
    "\n",
    "\n",
    "@njit\n",
    "def calc_leg_type_C(high: np.ndarray, low: np.ndarray, close: np.ndarray, open_: np.ndarray,\n",
    "                    overlap_ratio: np.ndarray, body_ratio: np.ndarray,\n",
    "                    upper_wick_ratio: np.ndarray, lower_wick_ratio: np.ndarray,\n",
    "                    atr: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    è®¡ç®— Leg Type C: Implied Pullback Legs (Fractal Legs)\n",
    "\n",
    "    è§„åˆ™ (ä¸Šæ¶¨ä¸­ï¼Œæ»¡è¶³2é¡¹æ¡ä»¶å³æ–°è…¿):\n",
    "    - overlap_ratio > 0.6\n",
    "    - body_ratio < 0.3\n",
    "    - upper_wick_ratio > 0.4 (ä¸Šæ¶¨ä¸­) æˆ– lower_wick_ratio > 0.4 (ä¸‹è·Œä¸­)\n",
    "    - æœ€è¿‘4æ ¹barçš„é«˜ç‚¹å¢å¹… < ATR * 0.3 (åŠ¨èƒ½åœæ»)\n",
    "    \"\"\"\n",
    "    n = len(high)\n",
    "    leg_id = np.zeros(n, dtype=np.int32)\n",
    "    leg_dir = np.zeros(n, dtype=np.int32)\n",
    "\n",
    "    current_leg_id = 1\n",
    "    if close[0] >= open_[0]:\n",
    "        current_dir = 1\n",
    "    else:\n",
    "        current_dir = -1\n",
    "\n",
    "    leg_id[0] = current_leg_id\n",
    "    leg_dir[0] = current_dir\n",
    "\n",
    "    for i in range(1, n):\n",
    "        conditions_met = 0\n",
    "\n",
    "        # æ£€æŸ¥å„é¡¹æ¡ä»¶\n",
    "        if not np.isnan(overlap_ratio[i]) and overlap_ratio[i] > 0.6:\n",
    "            conditions_met += 1\n",
    "\n",
    "        if not np.isnan(body_ratio[i]) and body_ratio[i] < 0.3:\n",
    "            conditions_met += 1\n",
    "\n",
    "        if current_dir == 1:  # ä¸Šæ¶¨è…¿\n",
    "            if not np.isnan(upper_wick_ratio[i]) and upper_wick_ratio[i] > 0.4:\n",
    "                conditions_met += 1\n",
    "        else:  # ä¸‹è·Œè…¿\n",
    "            if not np.isnan(lower_wick_ratio[i]) and lower_wick_ratio[i] > 0.4:\n",
    "                conditions_met += 1\n",
    "\n",
    "        # åŠ¨èƒ½åœæ»æ£€æŸ¥ (æœ€è¿‘4æ ¹bar)\n",
    "        if i >= 4 and not np.isnan(atr[i]) and atr[i] > 0:\n",
    "            if current_dir == 1:\n",
    "                high_gain = high[i] - high[i-4]\n",
    "            else:\n",
    "                high_gain = low[i-4] - low[i]\n",
    "\n",
    "            if high_gain < atr[i] * 0.3:\n",
    "                conditions_met += 1\n",
    "\n",
    "        # æ»¡è¶³ 2 é¡¹æ¡ä»¶ â†’ æ–°è…¿\n",
    "        if conditions_met >= 2:\n",
    "            current_leg_id += 1\n",
    "            # æ–¹å‘ç”±å½“å‰ bar å†³å®š\n",
    "            if close[i] >= open_[i]:\n",
    "                current_dir = 1\n",
    "            else:\n",
    "                current_dir = -1\n",
    "\n",
    "        leg_id[i] = current_leg_id\n",
    "        leg_dir[i] = current_dir\n",
    "\n",
    "    return leg_id, leg_dir\n",
    "\n",
    "\n",
    "# ========== è®¡ç®—ä¸‰ç§è…¿ ==========\n",
    "print(\"  è®¡ç®— Leg Type A (Major Legs)...\")\n",
    "legA_id, legA_dir = calc_leg_type_A(\n",
    "    df[\"high\"].values, df[\"low\"].values,\n",
    "    df[\"close\"].values, df[\"open\"].values\n",
    ")\n",
    "df[\"legA_id\"] = legA_id\n",
    "df[\"legA_dir\"] = legA_dir\n",
    "\n",
    "print(\"  è®¡ç®— Leg Type B (Micro Legs)...\")\n",
    "legB_id, legB_dir = calc_leg_type_B(df[\"close\"].values, df[\"open\"].values)\n",
    "df[\"legB_id\"] = legB_id\n",
    "df[\"legB_dir\"] = legB_dir\n",
    "\n",
    "print(\"  è®¡ç®— Leg Type C (Fractal Legs)...\")\n",
    "# å…ˆå¡«å…… NaN ä¸º 0ï¼Œé¿å… numba é”™è¯¯\n",
    "overlap_arr = df[\"overlap_ratio\"].fillna(0).values\n",
    "body_arr = df[\"body_ratio\"].fillna(0).values\n",
    "upper_wick_arr = df[\"upper_wick_ratio\"].fillna(0).values\n",
    "lower_wick_arr = df[\"lower_wick_ratio\"].fillna(0).values\n",
    "atr_arr = df[\"atr\"].fillna(0).values\n",
    "\n",
    "legC_id, legC_dir = calc_leg_type_C(\n",
    "    df[\"high\"].values, df[\"low\"].values,\n",
    "    df[\"close\"].values, df[\"open\"].values,\n",
    "    overlap_arr, body_arr, upper_wick_arr, lower_wick_arr, atr_arr\n",
    ")\n",
    "df[\"legC_id\"] = legC_id\n",
    "df[\"legC_dir\"] = legC_dir\n",
    "\n",
    "# ========== æ·»åŠ å‰å‡ è…¿æ–¹å‘ç‰¹å¾ ==========\n",
    "for leg_type in [\"A\", \"B\", \"C\"]:\n",
    "    dir_col = f\"leg{leg_type}_dir\"\n",
    "    df[f\"leg{leg_type}_prev1_dir\"] = df[dir_col].shift(1)\n",
    "    df[f\"leg{leg_type}_prev2_dir\"] = df[dir_col].shift(2)\n",
    "\n",
    "# ========== è®¡ç®—æ¯ç§è…¿çš„å˜åŒ–ç‡ (ç”¨äºæ£€æµ‹é¢‘ç‡) ==========\n",
    "for leg_type in [\"A\", \"B\", \"C\"]:\n",
    "    id_col = f\"leg{leg_type}_id\"\n",
    "    # è…¿å˜åŒ–æ ‡è®°\n",
    "    df[f\"leg{leg_type}_change\"] = (df[id_col] != df[id_col].shift(1)).astype(int)\n",
    "    # æœ€è¿‘ N æ ¹å†…çš„è…¿å˜åŒ–æ¬¡æ•°\n",
    "    df[f\"leg{leg_type}_changes_10\"] = df[f\"leg{leg_type}_change\"].rolling(10).sum()\n",
    "\n",
    "# ========== ç»Ÿè®¡ ==========\n",
    "print(\"\\n=== ä¸‰é‡è…¿ç»“æ„ç»Ÿè®¡ ===\")\n",
    "for leg_type, desc in [(\"A\", \"Major\"), (\"B\", \"Micro\"), (\"C\", \"Fractal\")]:\n",
    "    total_legs = df[f\"leg{leg_type}_id\"].max()\n",
    "    avg_changes = df[f\"leg{leg_type}_changes_10\"].mean()\n",
    "    print(f\"Leg {leg_type} ({desc}): æ€»è…¿æ•°={total_legs:,}, å¹³å‡æ¯10barå˜åŒ–={avg_changes:.2f}æ¬¡\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, (leg_type, desc, color) in enumerate([(\"A\", \"Major\", \"blue\"),\n",
    "                                               (\"B\", \"Micro\", \"green\"),\n",
    "                                               (\"C\", \"Fractal\", \"orange\")]):\n",
    "    changes_col = f\"leg{leg_type}_changes_10\"\n",
    "    axes[i].hist(df[changes_col].dropna(), bins=20, edgecolor=\"black\", alpha=0.7, color=color)\n",
    "    axes[i].set_xlabel(f\"æ¯10barçš„Leg{leg_type}å˜åŒ–æ¬¡æ•°\")\n",
    "    axes[i].set_ylabel(\"æ•°é‡\")\n",
    "    axes[i].set_title(f\"Leg {leg_type} ({desc}) å˜åŒ–é¢‘ç‡\\n(é«˜=æ›´å¤šè…¿åˆ‡æ¢)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 21 å®Œæˆ: ä¸‰é‡è…¿ç»“æ„ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5258,
     "status": "ok",
     "timestamp": 1765492577630,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "ihleI39beX1Y",
    "outputId": "bb0d78eb-04d0-4e21-b741-639872b2034a"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 22: Spike & Channel è¯„åˆ† (Phase Detection) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ ä½¿ç”¨ä¸‰å¥—è…¿ç»“æ„æ¥è¯†åˆ« Spike (è¶‹åŠ¿çˆ†å‘æœŸ) å’Œ Channel (è¶‹åŠ¿æˆç†ŸæœŸ)\n",
    "\n",
    "Spike (è¶‹åŠ¿çˆ†å‘) ç‰¹ç‚¹:\n",
    "- åªæœ‰ 1 æ¡ major legï¼ˆæˆ–åªåˆ° legA=2ï¼‰\n",
    "- micro legsï¼ˆB å‹ï¼‰æå°‘\n",
    "- implied legsï¼ˆC å‹ï¼‰æå°‘\n",
    "- æ–œç‡å¼ºã€é‡å å°‘ã€range_z é«˜ã€er é«˜ã€chop ä½\n",
    "\n",
    "Channel (è¶‹åŠ¿æˆç†Ÿ/è¡°ç«­) ç‰¹ç‚¹:\n",
    "- major legA â‰¥ 2 ä¸”è¶‹åŠ¿ä»å»¶ç»­\n",
    "- micro legsï¼ˆB å‹ï¼‰æ•°é‡ä¸Šå‡\n",
    "- implied legsï¼ˆC å‹ï¼‰å¯†åº¦ä¸Šå‡\n",
    "- slope ä¸‹é™ä½†æ–¹å‘ä»ç¨³å®š\n",
    "- é«˜é‡å åº¦\n",
    "\n",
    "è¾“å‡º:\n",
    "- spike_score: 0-1 åˆ†æ•°ï¼Œè¶Šé«˜è¶Šåƒ Spike\n",
    "- channel_score: 0-1 åˆ†æ•°ï¼Œè¶Šé«˜è¶Šåƒ Channel\n",
    "- phase: 0=normal, 1=spike, 2=channel\n",
    "\"\"\"\n",
    "print(\"è®¡ç®— Spike & Channel è¯„åˆ†...\")\n",
    "\n",
    "PHASE_WINDOW = 10\n",
    "\n",
    "# ========== Spike Score ==========\n",
    "def calc_spike_score(df: pd.DataFrame, window: int = 10) -> pd.Series:\n",
    "    \"\"\"\n",
    "    è®¡ç®— Spike Score (è¶‹åŠ¿çˆ†å‘åˆ†æ•°)\n",
    "\n",
    "    ç»„æˆ:\n",
    "    1. Major leg å°‘ (legA_changes ä½)\n",
    "    2. Micro leg å°‘ (legB_changes ä½)\n",
    "    3. Fractal leg å°‘ (legC_changes ä½)\n",
    "    4. ER é«˜\n",
    "    5. chop ä½\n",
    "    6. range_z é«˜\n",
    "    7. å¤šå°ºåº¦ä¸€è‡´æ€§é«˜ (|trend_alignment| == 3)\n",
    "    \"\"\"\n",
    "    scores = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # 1. Major leg å˜åŒ–å°‘ (spike ä¸­é€šå¸¸åªæœ‰ 1-2 æ¡å¤§è…¿)\n",
    "    legA_changes = df[\"legA_changes_10\"]\n",
    "    scores[\"legA_score\"] = 1 - (legA_changes / 10).clip(0, 1)  # å˜åŒ–å°‘ â†’ é«˜åˆ†\n",
    "\n",
    "    # 2. Micro leg å˜åŒ–å°‘\n",
    "    legB_changes = df[\"legB_changes_10\"]\n",
    "    scores[\"legB_score\"] = 1 - (legB_changes / 10).clip(0, 1)\n",
    "\n",
    "    # 3. Fractal leg å˜åŒ–å°‘\n",
    "    legC_changes = df[\"legC_changes_10\"]\n",
    "    scores[\"legC_score\"] = 1 - (legC_changes / 10).clip(0, 1)\n",
    "\n",
    "    # 4. ER é«˜ (> 0.4 å¼€å§‹åŠ åˆ†)\n",
    "    scores[\"er_score\"] = ((df[\"er\"] - 0.2) / 0.6).clip(0, 1)\n",
    "\n",
    "    # 5. chop ä½ (< 0.5 å¼€å§‹åŠ åˆ†)\n",
    "    scores[\"chop_score\"] = ((0.7 - df[\"chop\"]) / 0.5).clip(0, 1)\n",
    "\n",
    "    # 6. range_z é«˜ (æ‰©å¼ )\n",
    "    scores[\"range_z_score\"] = (df[\"range_z\"] / 3).clip(0, 1)\n",
    "\n",
    "    # 7. å¤šå°ºåº¦ä¸€è‡´æ€§\n",
    "    scores[\"alignment_score\"] = (df[\"trend_alignment\"].abs() / 3).clip(0, 1)\n",
    "\n",
    "    # åŠ æƒå¹³å‡\n",
    "    weights = {\n",
    "        \"legA_score\": 0.15,\n",
    "        \"legB_score\": 0.15,\n",
    "        \"legC_score\": 0.10,\n",
    "        \"er_score\": 0.20,\n",
    "        \"chop_score\": 0.15,\n",
    "        \"range_z_score\": 0.10,\n",
    "        \"alignment_score\": 0.15,\n",
    "    }\n",
    "\n",
    "    spike_score = sum(scores[col] * w for col, w in weights.items())\n",
    "    return spike_score.clip(0, 1)\n",
    "\n",
    "\n",
    "# ========== Channel Score ==========\n",
    "def calc_channel_score(df: pd.DataFrame, window: int = 10) -> pd.Series:\n",
    "    \"\"\"\n",
    "    è®¡ç®— Channel Score (è¶‹åŠ¿æˆç†Ÿ/è¡°ç«­åˆ†æ•°)\n",
    "\n",
    "    ç»„æˆ:\n",
    "    1. Major leg >= 2\n",
    "    2. Micro leg å¢å¤š (legB_changes é«˜)\n",
    "    3. Fractal leg å¢å¤š (legC_changes é«˜)\n",
    "    4. é‡å åº¦é«˜\n",
    "    5. æ–œç‡è¡°å‡ (ä½†æ–¹å‘ä»ä¸€è‡´)\n",
    "    6. ER ä¸­ç­‰ (0.3-0.5)\n",
    "    \"\"\"\n",
    "    scores = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # 1. Micro leg å˜åŒ–å¤š (channel å†…éƒ¨æœ‰å¾ˆå¤šå°å›è°ƒ)\n",
    "    legB_changes = df[\"legB_changes_10\"]\n",
    "    scores[\"legB_score\"] = (legB_changes / 8).clip(0, 1)\n",
    "\n",
    "    # 2. Fractal leg å˜åŒ–å¤š\n",
    "    legC_changes = df[\"legC_changes_10\"]\n",
    "    scores[\"legC_score\"] = (legC_changes / 6).clip(0, 1)\n",
    "\n",
    "    # 3. é‡å åº¦é«˜\n",
    "    scores[\"overlap_score\"] = ((df[\"overlap_ratio\"] - 0.3) / 0.5).clip(0, 1)\n",
    "\n",
    "    # 4. ER ä¸­ç­‰ (ä¸å¤ªé«˜ä¹Ÿä¸å¤ªä½)\n",
    "    er = df[\"er\"]\n",
    "    scores[\"er_score\"] = 1 - 2 * (er - 0.35).abs()  # 0.35 é™„è¿‘æœ€é«˜\n",
    "    scores[\"er_score\"] = scores[\"er_score\"].clip(0, 1)\n",
    "\n",
    "    # 5. æ–œç‡ä»æœ‰ä½†åœ¨è¡°å‡ (slope_norm æ­£/è´Ÿä½†ç»å¯¹å€¼ < 0.05)\n",
    "    slope_abs = df[\"slope_norm\"].abs()\n",
    "    scores[\"slope_score\"] = ((0.1 - slope_abs) / 0.1 + 0.5).clip(0, 1)\n",
    "\n",
    "    # 6. å°å®ä½“æ¯”ä¾‹é«˜ (channel å†…éƒ¨å¸¸è§)\n",
    "    scores[\"body_score\"] = ((0.6 - df[\"avg_body_ratio\"]) / 0.4).clip(0, 1)\n",
    "\n",
    "    # åŠ æƒå¹³å‡\n",
    "    weights = {\n",
    "        \"legB_score\": 0.20,\n",
    "        \"legC_score\": 0.15,\n",
    "        \"overlap_score\": 0.20,\n",
    "        \"er_score\": 0.15,\n",
    "        \"slope_score\": 0.15,\n",
    "        \"body_score\": 0.15,\n",
    "    }\n",
    "\n",
    "    channel_score = sum(scores[col] * w for col, w in weights.items())\n",
    "    return channel_score.clip(0, 1)\n",
    "\n",
    "\n",
    "# è®¡ç®—åˆ†æ•°\n",
    "df[\"spike_score\"] = calc_spike_score(df, PHASE_WINDOW)\n",
    "df[\"channel_score\"] = calc_channel_score(df, PHASE_WINDOW)\n",
    "\n",
    "# ========== Phase åˆ¤å®š ==========\n",
    "# phase: 0=normal, 1=spike, 2=channel\n",
    "SPIKE_THRESHOLD = 0.55\n",
    "CHANNEL_THRESHOLD = 0.50\n",
    "\n",
    "def determine_phase(spike: float, channel: float, regime: int) -> int:\n",
    "    \"\"\"\n",
    "    åˆ¤å®šå½“å‰é˜¶æ®µ\n",
    "    - å¦‚æœ regime == 0 (éœ‡è¡åŒºé—´)ï¼Œåˆ™ phase = 0\n",
    "    - å¦‚æœ spike_score é«˜ä¸”åœ¨è¶‹åŠ¿ä¸­ï¼Œåˆ™ phase = 1 (spike)\n",
    "    - å¦‚æœ channel_score é«˜ä¸”åœ¨è¶‹åŠ¿ä¸­ï¼Œåˆ™ phase = 2 (channel)\n",
    "    \"\"\"\n",
    "    if pd.isna(regime) or regime == 0:\n",
    "        return 0\n",
    "\n",
    "    if spike > SPIKE_THRESHOLD and spike > channel:\n",
    "        return 1  # Spike\n",
    "    elif channel > CHANNEL_THRESHOLD:\n",
    "        return 2  # Channel\n",
    "    else:\n",
    "        return 0  # Normal trend\n",
    "\n",
    "\n",
    "df[\"phase\"] = df.apply(\n",
    "    lambda row: determine_phase(row[\"spike_score\"], row[\"channel_score\"], row[\"regime\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ========== ç»Ÿè®¡ ==========\n",
    "print(\"\\n=== Spike & Channel è¯„åˆ†ç»Ÿè®¡ ===\")\n",
    "print(f\"spike_score: mean={df['spike_score'].mean():.4f}, max={df['spike_score'].max():.4f}\")\n",
    "print(f\"channel_score: mean={df['channel_score'].mean():.4f}, max={df['channel_score'].max():.4f}\")\n",
    "\n",
    "phase_counts = df[\"phase\"].value_counts().sort_index()\n",
    "print(f\"\\n=== Phase åˆ†å¸ƒ ===\")\n",
    "phase_names = {0: \"Normal/Range\", 1: \"Spike\", 2: \"Channel\"}\n",
    "for k, v in phase_counts.items():\n",
    "    print(f\"  {phase_names.get(k, k)}: {v:,} ({v/len(df)*100:.2f}%)\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Spike Score åˆ†å¸ƒ\n",
    "axes[0].hist(df[\"spike_score\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7, color=\"red\")\n",
    "axes[0].axvline(x=SPIKE_THRESHOLD, color=\"black\", linestyle=\"--\", label=f\"é˜ˆå€¼ {SPIKE_THRESHOLD}\")\n",
    "axes[0].set_xlabel(\"spike_score\")\n",
    "axes[0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0].set_title(\"Spike Score åˆ†å¸ƒ\\n(è¶‹åŠ¿çˆ†å‘åˆ†æ•°)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Channel Score åˆ†å¸ƒ\n",
    "axes[1].hist(df[\"channel_score\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7, color=\"purple\")\n",
    "axes[1].axvline(x=CHANNEL_THRESHOLD, color=\"black\", linestyle=\"--\", label=f\"é˜ˆå€¼ {CHANNEL_THRESHOLD}\")\n",
    "axes[1].set_xlabel(\"channel_score\")\n",
    "axes[1].set_ylabel(\"æ•°é‡\")\n",
    "axes[1].set_title(\"Channel Score åˆ†å¸ƒ\\n(è¶‹åŠ¿è¡°ç«­åˆ†æ•°)\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Phase åˆ†å¸ƒ\n",
    "phase_counts.plot(kind=\"bar\", ax=axes[2], color=[\"gray\", \"red\", \"purple\"], edgecolor=\"black\")\n",
    "axes[2].set_xlabel(\"Phase\")\n",
    "axes[2].set_ylabel(\"æ•°é‡\")\n",
    "axes[2].set_title(\"Phase åˆ†å¸ƒ\")\n",
    "axes[2].set_xticklabels([\"Normal/Range\", \"Spike\", \"Channel\"], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 22 å®Œæˆ: Spike & Channel è¯„åˆ† âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9736,
     "status": "ok",
     "timestamp": 1765492587381,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "43a7SrW2eX1Z",
    "outputId": "dbade2fb-f796-4d2b-ad79-f86a0641a212"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 23: å…³é”®ä»·ä½ç‰¹å¾ (Key Price Levels) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ 1.2(e) Brooks äº¤æ˜“å‘˜åœ¨ç›˜ä¸­éå¸¸çœ‹é‡çš„å…³é”®ä»·ä½:\n",
    "   - pos_in_day_range = (close - day_low) / (day_high - day_low)  âˆˆ [0,1]\n",
    "   - dist_to_open = (close - day_open) / ATR_day\n",
    "   - æ¥è¿‘å½“æ—¥é«˜/ä½ä¸”è¡Œæƒ…å·²ç»æ¶¨è·Œå¾ˆå¤š â‡’ æ›´å®¹æ˜“ trading range æˆ– climactic\n",
    "   - ä¸€ç›´è´´åœ¨ open è¿‘æ—ä¸Šä¸‹æ™ƒ â‡’ å…¸å‹\"å¼€ç›˜åŒºé—´\"çš„æ— æ–¹å‘éœ‡è¡\n",
    "\n",
    "æ³¨æ„: è¿™äº›ç‰¹å¾ä½¿ç”¨ cumulative çš„å½“æ—¥ä¿¡æ¯ï¼Œä¸æ³„éœ²æœªæ¥\n",
    "\"\"\"\n",
    "print(\"è®¡ç®—å…³é”®ä»·ä½ç‰¹å¾...\")\n",
    "\n",
    "# é¦–å…ˆéœ€è¦è¯†åˆ«æ¯ä¸ªäº¤æ˜“æ—¥\n",
    "df_temp = df.copy()\n",
    "df_temp = df_temp.reset_index()\n",
    "df_temp[\"timestamp_dt\"] = pd.to_datetime(df_temp[\"timestamp\"].astype(str).str.slice(0, 19))\n",
    "df_temp[\"date\"] = df_temp[\"timestamp_dt\"].dt.date\n",
    "df_temp = df_temp.set_index(\"timestamp\")\n",
    "\n",
    "# ========== è®¡ç®—æ¯æ—¥çš„å…³é”®ä»·ä½ (æ»šåŠ¨ç´¯ç§¯ï¼Œä¸æ³„éœ²æœªæ¥) ==========\n",
    "def calc_intraday_features(group):\n",
    "    \"\"\"\n",
    "    è®¡ç®—å•æ—¥å†…çš„å…³é”®ä»·ä½ç‰¹å¾ (ä½¿ç”¨ expanding ç¡®ä¿ä¸æ³„éœ²æœªæ¥)\n",
    "    \"\"\"\n",
    "    n = len(group)\n",
    "\n",
    "    # å½“æ—¥å¼€ç›˜ä»· (ç¬¬ä¸€æ ¹ bar çš„ open)\n",
    "    day_open = group[\"open\"].iloc[0]\n",
    "\n",
    "    # ç´¯ç§¯åˆ°å½“å‰çš„æœ€é«˜/æœ€ä½ä»· (expanding)\n",
    "    cum_high = group[\"high\"].expanding().max()\n",
    "    cum_low = group[\"low\"].expanding().min()\n",
    "    cum_range = cum_high - cum_low\n",
    "\n",
    "    # å½“å‰ä»·æ ¼åœ¨æ—¥å†…åŒºé—´çš„ä½ç½® [0, 1]\n",
    "    pos_in_day_range = (group[\"close\"] - cum_low) / cum_range.replace(0, np.nan)\n",
    "\n",
    "    # å½“å‰ä»·æ ¼ç›¸å¯¹å¼€ç›˜ä»·çš„è·ç¦» (æ ‡å‡†åŒ–)\n",
    "    # ä½¿ç”¨å½“æ—¥ç´¯ç§¯ ATR çš„å‡å€¼\n",
    "    cum_atr_mean = group[\"atr\"].expanding().mean()\n",
    "    dist_to_open = (group[\"close\"] - day_open) / cum_atr_mean.replace(0, np.nan)\n",
    "\n",
    "    # å½“æ—¥ç´¯ç§¯æ”¶ç›Š (ç›¸å¯¹å¼€ç›˜)\n",
    "    day_return = (group[\"close\"] - day_open) / day_open\n",
    "\n",
    "    # å½“æ—¥ç´¯ç§¯æ³¢åŠ¨ (ATR æ€»å’Œ / æ ¹æ•°)\n",
    "    day_volatility = group[\"atr\"].expanding().mean()\n",
    "\n",
    "    # å½“æ—¥ bar åºå· (ä» 0 å¼€å§‹)\n",
    "    bar_of_day = np.arange(n)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"day_open\": day_open,\n",
    "        \"cum_high\": cum_high,\n",
    "        \"cum_low\": cum_low,\n",
    "        \"cum_range\": cum_range,\n",
    "        \"pos_in_day_range\": pos_in_day_range,\n",
    "        \"dist_to_open\": dist_to_open,\n",
    "        \"day_return\": day_return,\n",
    "        \"day_volatility\": day_volatility,\n",
    "        \"bar_of_day\": bar_of_day,\n",
    "    }, index=group.index)\n",
    "\n",
    "\n",
    "# æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—\n",
    "print(\"  æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—æ—¥å†…ç‰¹å¾...\")\n",
    "intraday_features = df_temp.groupby(\"date\").apply(calc_intraday_features)\n",
    "\n",
    "# å¤„ç† MultiIndex\n",
    "if isinstance(intraday_features.index, pd.MultiIndex):\n",
    "    intraday_features = intraday_features.droplevel(0)\n",
    "\n",
    "# åˆå¹¶åˆ°ä¸» df\n",
    "for col in [\"pos_in_day_range\", \"dist_to_open\", \"day_return\", \"bar_of_day\"]:\n",
    "    df[col] = intraday_features[col]\n",
    "\n",
    "# ========== é¢å¤–çš„æ—¥å†…ä½ç½®ç‰¹å¾ ==========\n",
    "# æ˜¯å¦æ¥è¿‘å½“æ—¥é«˜ç‚¹ (top 10%)\n",
    "df[\"near_day_high\"] = (df[\"pos_in_day_range\"] > 0.9).astype(int)\n",
    "# æ˜¯å¦æ¥è¿‘å½“æ—¥ä½ç‚¹ (bottom 10%)\n",
    "df[\"near_day_low\"] = (df[\"pos_in_day_range\"] < 0.1).astype(int)\n",
    "# æ˜¯å¦åœ¨å¼€ç›˜åŒºé—´ (dist_to_open çš„ç»å¯¹å€¼ < 0.5 ATR)\n",
    "df[\"near_open\"] = (df[\"dist_to_open\"].abs() < 0.5).astype(int)\n",
    "\n",
    "# ========== æ—¶é—´ç‰¹å¾ (æ— æ³„éœ²) ==========\n",
    "# å°† bar_of_day æ ‡å‡†åŒ– (ä¸€å¤©çº¦ 79 æ ¹ 5min bar for RTH)\n",
    "df[\"time_of_day_norm\"] = df[\"bar_of_day\"] / 79  # 0=å¼€ç›˜, 1=æ”¶ç›˜\n",
    "\n",
    "# å¼€ç›˜/æ”¶ç›˜åŒºé—´æ ‡è®°\n",
    "df[\"is_open_range\"] = (df[\"bar_of_day\"] < 6).astype(int)   # å‰30åˆ†é’Ÿ\n",
    "df[\"is_close_range\"] = (df[\"bar_of_day\"] > 70).astype(int)  # æœ€å45åˆ†é’Ÿ\n",
    "\n",
    "# ========== ç»Ÿè®¡ ==========\n",
    "print(\"\\n=== å…³é”®ä»·ä½ç‰¹å¾ç»Ÿè®¡ ===\")\n",
    "print(f\"pos_in_day_range: mean={df['pos_in_day_range'].mean():.4f}, std={df['pos_in_day_range'].std():.4f}\")\n",
    "print(f\"dist_to_open: mean={df['dist_to_open'].mean():.4f}, std={df['dist_to_open'].std():.4f}\")\n",
    "print(f\"day_return: mean={df['day_return'].mean():.6f}, std={df['day_return'].std():.6f}\")\n",
    "\n",
    "print(f\"\\n=== ä½ç½®åˆ†å¸ƒ ===\")\n",
    "print(f\"near_day_high æ¯”ä¾‹: {df['near_day_high'].mean()*100:.2f}%\")\n",
    "print(f\"near_day_low æ¯”ä¾‹: {df['near_day_low'].mean()*100:.2f}%\")\n",
    "print(f\"near_open æ¯”ä¾‹: {df['near_open'].mean()*100:.2f}%\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# pos_in_day_range åˆ†å¸ƒ\n",
    "axes[0].hist(df[\"pos_in_day_range\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].axvline(x=0.5, color=\"red\", linestyle=\"--\", label=\"ä¸­é—´ä½ç½®\")\n",
    "axes[0].set_xlabel(\"pos_in_day_range\")\n",
    "axes[0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0].set_title(\"æ—¥å†…ä½ç½®åˆ†å¸ƒ\\n(0=æ—¥ä½, 1=æ—¥é«˜)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# dist_to_open åˆ†å¸ƒ\n",
    "axes[1].hist(df[\"dist_to_open\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7, color=\"orange\")\n",
    "axes[1].axvline(x=0, color=\"red\", linestyle=\"--\", label=\"å¼€ç›˜ä»·\")\n",
    "axes[1].set_xlabel(\"dist_to_open (ATR å•ä½)\")\n",
    "axes[1].set_ylabel(\"æ•°é‡\")\n",
    "axes[1].set_title(\"ç›¸å¯¹å¼€ç›˜ä»·è·ç¦»\\n(æ­£=é«˜äºå¼€ç›˜)\")\n",
    "axes[1].legend()\n",
    "axes[1].set_xlim(-5, 5)\n",
    "\n",
    "# bar_of_day åˆ†å¸ƒ (åº”è¯¥æ˜¯å‡åŒ€çš„)\n",
    "axes[2].hist(df[\"bar_of_day\"].dropna(), bins=79, edgecolor=\"black\", alpha=0.7, color=\"green\")\n",
    "axes[2].set_xlabel(\"bar_of_day\")\n",
    "axes[2].set_ylabel(\"æ•°é‡\")\n",
    "axes[2].set_title(\"æ—¥å†… Bar åºå·åˆ†å¸ƒ\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 23 å®Œæˆ: å…³é”®ä»·ä½ç‰¹å¾ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4757,
     "status": "ok",
     "timestamp": 1765492592152,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "HhnyGBOleX1Z",
    "outputId": "442c68de-34de-46fb-cac5-e620e1b33d3c"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 24: å¤šæ—¶é—´å‘¨æœŸç‰¹å¾ (Multi-Timeframe Features) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ Section 2: æŠŠ 15min / 1h çš„ä¿¡æ¯ä¹ŸåŠ å…¥è®­ç»ƒé›†\n",
    "\n",
    "æ€è·¯:\n",
    "1. å°† 5min æ•°æ® resample åˆ° 15min å’Œ 60min\n",
    "2. åœ¨é«˜å‘¨æœŸä¸Šè®¡ç®—ç›¸åŒçš„æŒ‡æ ‡ (KAMA, ER, ATR, slope, chop ç­‰)\n",
    "3. ä½¿ç”¨ floor å¯¹é½ï¼Œç¡®ä¿ä¸æ³„éœ²æœªæ¥ä¿¡æ¯\n",
    "4. åˆå¹¶å› 5min æ•°æ®\n",
    "\n",
    "è¿™æ ·æ¨¡å‹å¯ä»¥å­¦åˆ°:\n",
    "- \"å½“ 1h åœ¨ä¸Šå‡è¶‹åŠ¿ã€15min åœ¨éœ‡è¡æ—¶ï¼Œ5min çš„å‘ä¸‹æ³¢åŠ¨å¤šåŠæ˜¯ pullback\"\n",
    "\"\"\"\n",
    "print(\"è®¡ç®—å¤šæ—¶é—´å‘¨æœŸç‰¹å¾...\")\n",
    "\n",
    "# ========== 1. Resample to 15min and 60min ==========\n",
    "print(\"  Resampling åˆ° 15min å’Œ 60min...\")\n",
    "\n",
    "# ä¿å­˜åŸå§‹ 5min df\n",
    "df_5 = df.copy()\n",
    "\n",
    "# éœ€è¦å…ˆ reset index æ¥å¤„ç†\n",
    "df_5_reset = df_5.reset_index()\n",
    "df_5_reset[\"timestamp_dt\"] = pd.to_datetime(df_5_reset[\"timestamp\"].astype(str).str.slice(0, 19))\n",
    "df_5_reset = df_5_reset.set_index(\"timestamp_dt\")\n",
    "\n",
    "# Resample å‡½æ•°\n",
    "def resample_ohlcv(df_src: pd.DataFrame, freq: str) -> pd.DataFrame:\n",
    "    \"\"\"å°† OHLCV æ•°æ® resample åˆ°æŒ‡å®šé¢‘ç‡\"\"\"\n",
    "    df_resampled = df_src.resample(freq).agg({\n",
    "        \"open\": \"first\",\n",
    "        \"high\": \"max\",\n",
    "        \"low\": \"min\",\n",
    "        \"close\": \"last\",\n",
    "        \"volume\": \"sum\",\n",
    "    }).dropna()\n",
    "    return df_resampled\n",
    "\n",
    "df_15 = resample_ohlcv(df_5_reset, \"15T\")\n",
    "df_60 = resample_ohlcv(df_5_reset, \"60T\")\n",
    "\n",
    "print(f\"  15min bars: {len(df_15):,}\")\n",
    "print(f\"  60min bars: {len(df_60):,}\")\n",
    "\n",
    "# ========== 2. åœ¨é«˜å‘¨æœŸä¸Šè®¡ç®—æŒ‡æ ‡ ==========\n",
    "def calc_htf_features(df_htf: pd.DataFrame, suffix: str,\n",
    "                      n_atr: int = 14, n_er: int = 14, l_back: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    åœ¨é«˜å‘¨æœŸæ•°æ®ä¸Šè®¡ç®—æ ¸å¿ƒæŒ‡æ ‡\n",
    "    \"\"\"\n",
    "    df_htf = df_htf.copy()\n",
    "\n",
    "    # Log close\n",
    "    df_htf[\"log_close\"] = np.log(df_htf[\"close\"])\n",
    "\n",
    "    # ATR\n",
    "    prev_close = df_htf[\"close\"].shift(1)\n",
    "    tr1 = df_htf[\"high\"] - df_htf[\"low\"]\n",
    "    tr2 = (df_htf[\"high\"] - prev_close).abs()\n",
    "    tr3 = (df_htf[\"low\"] - prev_close).abs()\n",
    "    df_htf[\"tr\"] = np.maximum(np.maximum(tr1, tr2), tr3)\n",
    "    df_htf[f\"atr_{suffix}\"] = df_htf[\"tr\"].ewm(span=n_atr, adjust=False).mean()\n",
    "\n",
    "    # ER\n",
    "    change = (df_htf[\"close\"] - df_htf[\"close\"].shift(n_er)).abs()\n",
    "    volatility = df_htf[\"close\"].diff().abs().rolling(window=n_er).sum()\n",
    "    df_htf[f\"er_{suffix}\"] = (change / volatility.replace(0, np.nan)).clip(0, 1)\n",
    "\n",
    "    # Slope (ç®€åŒ–ç‰ˆ)\n",
    "    df_htf[f\"slope_{suffix}\"] = df_htf[\"log_close\"].diff(5) / 5\n",
    "    df_htf[f\"slope_{suffix}_norm\"] = df_htf[f\"slope_{suffix}\"] / df_htf[f\"atr_{suffix}\"].replace(0, np.nan) * 100\n",
    "\n",
    "    # Chop (ç®€åŒ–ç‰ˆ)\n",
    "    chop_window = min(14, l_back)\n",
    "    atr_sum = df_htf[\"tr\"].rolling(window=chop_window).sum()\n",
    "    high_max = df_htf[\"high\"].rolling(window=chop_window).max()\n",
    "    low_min = df_htf[\"low\"].rolling(window=chop_window).min()\n",
    "    hl_range = high_max - low_min\n",
    "    df_htf[f\"chop_{suffix}\"] = (np.log10(atr_sum / hl_range.replace(0, np.nan)) / np.log10(chop_window)).clip(0, 1)\n",
    "\n",
    "    # è¶‹åŠ¿æ–¹å‘ (åŸºäº slope)\n",
    "    df_htf[f\"trend_dir_{suffix}\"] = np.sign(df_htf[f\"slope_{suffix}\"])\n",
    "\n",
    "    # åªè¿”å›éœ€è¦çš„åˆ—\n",
    "    result_cols = [f\"atr_{suffix}\", f\"er_{suffix}\", f\"slope_{suffix}_norm\",\n",
    "                   f\"chop_{suffix}\", f\"trend_dir_{suffix}\"]\n",
    "\n",
    "    return df_htf[result_cols]\n",
    "\n",
    "\n",
    "print(\"  è®¡ç®— 15min æŒ‡æ ‡...\")\n",
    "df_15_features = calc_htf_features(df_15, \"15\", n_atr=14, n_er=14, l_back=14)\n",
    "\n",
    "print(\"  è®¡ç®— 60min æŒ‡æ ‡...\")\n",
    "df_60_features = calc_htf_features(df_60, \"60\", n_atr=14, n_er=14, l_back=14)\n",
    "\n",
    "# ========== 3. Floor å¯¹é½å¹¶ merge å› 5min ==========\n",
    "print(\"  å¯¹é½å¹¶åˆå¹¶åˆ° 5min æ•°æ®...\")\n",
    "\n",
    "# âš ï¸ é‡è¦ï¼šä½¿ç”¨å‰ä¸€ä¸ªå·²å®Œæˆçš„é«˜å‘¨æœŸ barï¼Œé¿å…æœªæ¥ä¿¡æ¯æ³„éœ²\n",
    "# ä¾‹å¦‚ï¼šåœ¨ 9:35 æ—¶ï¼Œfloor(\"15T\") = 9:30ï¼Œä½† 9:30-9:45 çš„ 15min bar åŒ…å« 9:40 çš„æœªæ¥ä¿¡æ¯\n",
    "# æ­£ç¡®åšæ³•ï¼šå‡å»ä¸€ä¸ªå‘¨æœŸï¼Œä½¿ç”¨å‰ä¸€ä¸ªå·²å®Œæˆçš„ bar\n",
    "df_5_reset[\"t_15\"] = df_5_reset.index.floor(\"15T\") - pd.Timedelta(\"15min\")\n",
    "df_5_reset[\"t_60\"] = df_5_reset.index.floor(\"60T\") - pd.Timedelta(\"60min\")\n",
    "\n",
    "# Merge 15min features\n",
    "df_15_features = df_15_features.reset_index()\n",
    "df_15_features = df_15_features.rename(columns={\"timestamp_dt\": \"t_15\"})\n",
    "df_5_merged = df_5_reset.reset_index().merge(\n",
    "    df_15_features, on=\"t_15\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Merge 60min features\n",
    "df_60_features = df_60_features.reset_index()\n",
    "df_60_features = df_60_features.rename(columns={\"timestamp_dt\": \"t_60\"})\n",
    "df_5_merged = df_5_merged.merge(\n",
    "    df_60_features, on=\"t_60\", how=\"left\"\n",
    ")\n",
    "\n",
    "# å°†ç‰¹å¾æ·»åŠ å›åŸå§‹ df\n",
    "df_5_merged = df_5_merged.set_index(\"timestamp\")\n",
    "\n",
    "for col in [\"atr_15\", \"er_15\", \"slope_15_norm\", \"chop_15\", \"trend_dir_15\",\n",
    "            \"atr_60\", \"er_60\", \"slope_60_norm\", \"chop_60\", \"trend_dir_60\"]:\n",
    "    if col in df_5_merged.columns:\n",
    "        df[col] = df_5_merged[col]\n",
    "\n",
    "# ========== 4. å¤šå‘¨æœŸæ¯”ç‡ç‰¹å¾ ==========\n",
    "# ATR æ¯”ç‡ (æ³¢åŠ¨ç‡è·¨å‘¨æœŸæ¯”)\n",
    "df[\"atr_ratio_15_5\"] = df[\"atr_15\"] / df[\"atr\"].replace(0, np.nan)\n",
    "df[\"atr_ratio_60_5\"] = df[\"atr_60\"] / df[\"atr\"].replace(0, np.nan)\n",
    "\n",
    "# å¤šå‘¨æœŸè¶‹åŠ¿ä¸€è‡´æ€§\n",
    "df[\"mtf_trend_alignment\"] = (\n",
    "    np.sign(df[\"slope_norm\"]) +\n",
    "    df[\"trend_dir_15\"].fillna(0) +\n",
    "    df[\"trend_dir_60\"].fillna(0)\n",
    ")\n",
    "\n",
    "# ========== ç»Ÿè®¡ ==========\n",
    "print(\"\\n=== å¤šå‘¨æœŸç‰¹å¾ç»Ÿè®¡ ===\")\n",
    "print(f\"15min ER: mean={df['er_15'].mean():.4f}\")\n",
    "print(f\"60min ER: mean={df['er_60'].mean():.4f}\")\n",
    "print(f\"ATR ratio (15/5): mean={df['atr_ratio_15_5'].mean():.4f}\")\n",
    "print(f\"ATR ratio (60/5): mean={df['atr_ratio_60_5'].mean():.4f}\")\n",
    "\n",
    "mtf_counts = df[\"mtf_trend_alignment\"].value_counts().sort_index()\n",
    "print(f\"\\nå¤šå‘¨æœŸè¶‹åŠ¿ä¸€è‡´æ€§åˆ†å¸ƒ:\")\n",
    "for k, v in mtf_counts.items():\n",
    "    print(f\"  {int(k):+d}: {v:,} ({v/len(df)*100:.1f}%)\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# ER æ¯”è¾ƒ: 5min vs 15min vs 60min\n",
    "axes[0].hist(df[\"er\"].dropna(), bins=50, alpha=0.5, label=\"5min ER\")\n",
    "axes[0].hist(df[\"er_15\"].dropna(), bins=50, alpha=0.5, label=\"15min ER\")\n",
    "axes[0].hist(df[\"er_60\"].dropna(), bins=50, alpha=0.5, label=\"60min ER\")\n",
    "axes[0].set_xlabel(\"ER\")\n",
    "axes[0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0].set_title(\"å¤šå‘¨æœŸ ER åˆ†å¸ƒæ¯”è¾ƒ\")\n",
    "axes[0].legend()\n",
    "\n",
    "# ATR æ¯”ç‡åˆ†å¸ƒ\n",
    "axes[1].hist(df[\"atr_ratio_15_5\"].dropna(), bins=50, alpha=0.7, label=\"15/5\")\n",
    "axes[1].hist(df[\"atr_ratio_60_5\"].dropna(), bins=50, alpha=0.5, label=\"60/5\")\n",
    "axes[1].set_xlabel(\"ATR æ¯”ç‡\")\n",
    "axes[1].set_ylabel(\"æ•°é‡\")\n",
    "axes[1].set_title(\"å¤šå‘¨æœŸ ATR æ¯”ç‡åˆ†å¸ƒ\")\n",
    "axes[1].legend()\n",
    "axes[1].set_xlim(0, 5)\n",
    "\n",
    "# å¤šå‘¨æœŸè¶‹åŠ¿ä¸€è‡´æ€§\n",
    "mtf_counts.plot(kind=\"bar\", ax=axes[2], color=\"steelblue\", edgecolor=\"black\")\n",
    "axes[2].set_xlabel(\"MTF Trend Alignment\")\n",
    "axes[2].set_ylabel(\"æ•°é‡\")\n",
    "axes[2].set_title(\"å¤šå‘¨æœŸè¶‹åŠ¿ä¸€è‡´æ€§\\n(Â±3=å…¨å‘¨æœŸåŒå‘)\")\n",
    "axes[2].set_xticklabels([f\"{int(x)}\" for x in mtf_counts.index], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 24 å®Œæˆ: å¤šæ—¶é—´å‘¨æœŸç‰¹å¾ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1345,
     "status": "ok",
     "timestamp": 1765492593500,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "9kRhz9RFeX1Z",
    "outputId": "a85a82c7-7feb-4e32-f12e-a16f084b0c4f"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 25: æ»åç‰¹å¾ (Lagged Features) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ Section 3: åŠ å…¥å‰å‡ ä¸ª K çº¿çš„æ ‡ç­¾å’Œæ»åç‰¹å¾\n",
    "\n",
    "æ·»åŠ :\n",
    "1. å†å² regime æ ‡ç­¾: regime_lag1, regime_lag2, regime_lag3\n",
    "2. å†å²æ ¸å¿ƒç‰¹å¾çš„æ»åç‰ˆæœ¬\n",
    "3. çª—å£ç»Ÿè®¡ç‰¹å¾ (å¦‚: æœ€è¿‘ 10 æ ¹ä¸­ regime=Â±1 çš„æ¯”ä¾‹)\n",
    "\n",
    "è¿™äº›ç›´æ¥æ¨¡æ‹Ÿ \"ç›˜æ„Ÿ\"ï¼š\n",
    "- æ¨¡å‹çœ‹åˆ°\"è¿ç»­ä¸‰æ ¹ regime=+1 ä¸” slope_norm éƒ½æ”¾å¤§\"ï¼Œè‡ªç„¶ä¼šæŠŠå½“å‰ä¹Ÿåˆ¤ä¸ºè¶‹åŠ¿æ®µ\n",
    "\"\"\"\n",
    "print(\"è®¡ç®—æ»åç‰¹å¾...\")\n",
    "\n",
    "# ========== é…ç½® ==========\n",
    "LAG_K = 3  # æ»åæœŸæ•°\n",
    "WINDOW_N = 10  # ç»Ÿè®¡çª—å£\n",
    "\n",
    "# ========== 1. å†å² regime æ ‡ç­¾ ==========\n",
    "print(\"  æ·»åŠ  regime æ»åç‰¹å¾...\")\n",
    "for lag in range(1, LAG_K + 1):\n",
    "    df[f\"regime_lag{lag}\"] = df[\"regime\"].shift(lag)\n",
    "\n",
    "# ========== 2. æ ¸å¿ƒç‰¹å¾çš„æ»åç‰ˆæœ¬ ==========\n",
    "print(\"  æ·»åŠ æ ¸å¿ƒç‰¹å¾æ»åç‰ˆæœ¬...\")\n",
    "\n",
    "# é€‰æ‹©éœ€è¦åšæ»åçš„æ ¸å¿ƒç‰¹å¾\n",
    "lag_features = [\n",
    "    \"er\",\n",
    "    \"slope_norm\",\n",
    "    \"dist_norm\",\n",
    "    \"chop\",\n",
    "    \"r2\",\n",
    "    \"range_z\",\n",
    "    \"dir_vol_ratio\",\n",
    "    \"bull_bear_diff\",\n",
    "    \"avg_body_ratio\",\n",
    "]\n",
    "\n",
    "for col in lag_features:\n",
    "    if col in df.columns:\n",
    "        for lag in range(1, LAG_K + 1):\n",
    "            df[f\"{col}_lag{lag}\"] = df[col].shift(lag)\n",
    "\n",
    "# ========== 3. çª—å£ç»Ÿè®¡ç‰¹å¾ ==========\n",
    "print(\"  æ·»åŠ çª—å£ç»Ÿè®¡ç‰¹å¾...\")\n",
    "\n",
    "# æœ€è¿‘ N æ ¹ä¸­ regime çš„ç»Ÿè®¡\n",
    "# è¶‹åŠ¿æ¯”ä¾‹ (regime = Â±1 çš„æ¯”ä¾‹)\n",
    "df[\"regime_trend_ratio\"] = df[\"regime\"].abs().rolling(WINDOW_N).mean()\n",
    "\n",
    "# ä¸Šæ¶¨è¶‹åŠ¿æ¯”ä¾‹ (regime = +1 çš„æ¯”ä¾‹)\n",
    "df[\"regime_up_ratio\"] = (df[\"regime\"] == 1).astype(int).rolling(WINDOW_N).mean()\n",
    "\n",
    "# ä¸‹è·Œè¶‹åŠ¿æ¯”ä¾‹ (regime = -1 çš„æ¯”ä¾‹)\n",
    "df[\"regime_down_ratio\"] = (df[\"regime\"] == -1).astype(int).rolling(WINDOW_N).mean()\n",
    "\n",
    "# regime å˜åŒ–æ¬¡æ•° (å¸‚åœºç»“æ„å˜åŒ–é¢‘ç‡)\n",
    "df[\"regime_change\"] = (df[\"regime\"] != df[\"regime\"].shift(1)).astype(int)\n",
    "df[\"regime_changes_N\"] = df[\"regime_change\"].rolling(WINDOW_N).sum()\n",
    "\n",
    "# è¿ç»­ regime æ ‡ç­¾æ•°é‡ (æ¨¡æ‹Ÿ\"è¶‹åŠ¿æŒç»­æ€§\")\n",
    "@njit\n",
    "def calc_consecutive_regime(regime: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"è®¡ç®—è¿ç»­ç›¸åŒ regime çš„é•¿åº¦\"\"\"\n",
    "    n = len(regime)\n",
    "    consec = np.zeros(n, dtype=np.int32)\n",
    "\n",
    "    for i in range(n):\n",
    "        if i == 0 or np.isnan(regime[i]) or np.isnan(regime[i-1]):\n",
    "            consec[i] = 1\n",
    "        elif regime[i] == regime[i-1]:\n",
    "            consec[i] = consec[i-1] + 1\n",
    "        else:\n",
    "            consec[i] = 1\n",
    "\n",
    "    return consec\n",
    "\n",
    "df[\"regime_consec\"] = calc_consecutive_regime(df[\"regime\"].values.astype(np.float64))\n",
    "\n",
    "# ========== 4. ç‰¹å¾å˜åŒ–ç‡ (momentum of features) ==========\n",
    "print(\"  æ·»åŠ ç‰¹å¾å˜åŒ–ç‡...\")\n",
    "\n",
    "# æ ¸å¿ƒç‰¹å¾çš„å˜åŒ–ç‡\n",
    "momentum_features = [\"er\", \"slope_norm\", \"chop\", \"range_z\"]\n",
    "\n",
    "for col in momentum_features:\n",
    "    if col in df.columns:\n",
    "        # 1 æœŸå˜åŒ–\n",
    "        df[f\"{col}_diff1\"] = df[col].diff(1)\n",
    "        # 3 æœŸå˜åŒ–\n",
    "        df[f\"{col}_diff3\"] = df[col].diff(3)\n",
    "\n",
    "# ========== 5. è¶‹åŠ¿åŠ é€Ÿ/å‡é€ŸæŒ‡æ ‡ ==========\n",
    "# slope_norm çš„å˜åŒ– (è¶‹åŠ¿åŠ é€Ÿ)\n",
    "df[\"slope_accel\"] = df[\"slope_norm\"].diff(1)\n",
    "df[\"slope_accel_ma3\"] = df[\"slope_accel\"].rolling(3).mean()\n",
    "\n",
    "# ========== ç»Ÿè®¡ ==========\n",
    "print(\"\\n=== æ»åç‰¹å¾ç»Ÿè®¡ ===\")\n",
    "print(f\"regime_trend_ratio: mean={df['regime_trend_ratio'].mean():.4f} (è¶‹åŠ¿å æ¯”)\")\n",
    "print(f\"regime_changes_N: mean={df['regime_changes_N'].mean():.2f} (æ¯{WINDOW_N}barå˜åŒ–æ¬¡æ•°)\")\n",
    "print(f\"regime_consec: max={df['regime_consec'].max()}, mean={df['regime_consec'].mean():.2f}\")\n",
    "\n",
    "# æ£€æŸ¥æ»åç‰¹å¾æ•°é‡\n",
    "lag_cols = [c for c in df.columns if \"_lag\" in c or \"_diff\" in c]\n",
    "print(f\"\\næ–°å¢æ»å/å˜åŒ–ç‰¹å¾æ•°é‡: {len(lag_cols)}\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# regime_trend_ratio åˆ†å¸ƒ\n",
    "axes[0].hist(df[\"regime_trend_ratio\"].dropna(), bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].set_xlabel(\"regime_trend_ratio\")\n",
    "axes[0].set_ylabel(\"æ•°é‡\")\n",
    "axes[0].set_title(f\"è¶‹åŠ¿å æ¯”åˆ†å¸ƒ (çª—å£={WINDOW_N})\\n(é«˜=æ›´å¤šè¶‹åŠ¿)\")\n",
    "\n",
    "# regime_consec åˆ†å¸ƒ\n",
    "consec_counts = df[\"regime_consec\"].value_counts().sort_index()\n",
    "consec_counts_plot = consec_counts[consec_counts.index <= 30]  # é™åˆ¶æ˜¾ç¤ºèŒƒå›´\n",
    "axes[1].bar(consec_counts_plot.index, consec_counts_plot.values, edgecolor=\"black\", alpha=0.7)\n",
    "axes[1].set_xlabel(\"regime_consec\")\n",
    "axes[1].set_ylabel(\"æ•°é‡\")\n",
    "axes[1].set_title(\"è¿ç»­ç›¸åŒ Regime é•¿åº¦åˆ†å¸ƒ\")\n",
    "\n",
    "# slope_accel åˆ†å¸ƒ\n",
    "axes[2].hist(df[\"slope_accel\"].dropna(), bins=50, edgecolor=\"black\", alpha=0.7, color=\"purple\")\n",
    "axes[2].axvline(x=0, color=\"red\", linestyle=\"--\")\n",
    "axes[2].set_xlabel(\"slope_accel\")\n",
    "axes[2].set_ylabel(\"æ•°é‡\")\n",
    "axes[2].set_title(\"æ–œç‡åŠ é€Ÿåº¦åˆ†å¸ƒ\\n(æ­£=è¶‹åŠ¿åŠ é€Ÿ)\")\n",
    "axes[2].set_xlim(-0.02, 0.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCell 25 å®Œæˆ: æ»åç‰¹å¾ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2696,
     "status": "ok",
     "timestamp": 1765492596201,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "gaPiF5_reX1Z",
    "outputId": "f19cce1e-7488-4d5d-f907-0c397af4bb1e"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 11: å¤šæ—¶é—´å‘¨æœŸè¾…åŠ© Regime æ ‡æ³¨ (MTF-Assisted Labeling) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ ç›®æ ‡: åœ¨æ‰“æ ‡ç­¾æ—¶è®©é«˜å‘¨æœŸç»“æ„æˆä¸º\"é¢å¤–çš„è£åˆ¤\"\n",
    "  - 5m è¶‹åŠ¿å¦‚æœå’Œ 60m å®Œå…¨åå‘ â†’ é™æƒæˆ–æ‰“å› 0 (å¯èƒ½æ˜¯ pullback)\n",
    "  - 5m éœ‡è¡å¦‚æœåœ¨å¼º 60m è¶‹åŠ¿ä¸­ â†’ æ ‡è®°ä¸º \"range_inside_trend\"\n",
    "\n",
    "ğŸ“Œ è®¾è®¡åŸåˆ™:\n",
    "  - 5min ç‰¹å¾å  ~80% å†³ç­–æƒé‡\n",
    "  - 15min/60min å  ~20%ï¼Œä»…èµ·è¾…åŠ©ä½œç”¨\n",
    "  - å¤šå‘¨æœŸåŒå‘æ—¶å¢åŠ ç½®ä¿¡åº¦\n",
    "  - é«˜å‘¨æœŸå¼ºåå‘æ—¶é™ä½è¶‹åŠ¿æ¦‚ç‡\n",
    "\"\"\"\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”„ å¤šæ—¶é—´å‘¨æœŸè¾…åŠ© Regime æ ‡æ³¨\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ========== 1. å®šä¹‰é«˜å‘¨æœŸå¼ºè¶‹åŠ¿æ¡ä»¶ ==========\n",
    "# 15min å¼ºè¶‹åŠ¿\n",
    "STRONG_15_SLOPE_THR = 0.02\n",
    "STRONG_15_ER_THR = 0.4\n",
    "STRONG_15_CHOP_THR = 0.6\n",
    "\n",
    "# 60min å¼ºè¶‹åŠ¿\n",
    "STRONG_60_SLOPE_THR = 0.02\n",
    "STRONG_60_ER_THR = 0.4\n",
    "STRONG_60_CHOP_THR = 0.6\n",
    "\n",
    "# MTF æƒé‡\n",
    "W_15 = 0.15  # 15min æƒé‡\n",
    "W_60 = 0.15  # 60min æƒé‡\n",
    "THR_TREND_SCORE = 1.0  # è¶‹åŠ¿å¾—åˆ†é˜ˆå€¼\n",
    "\n",
    "# è®¡ç®—é«˜å‘¨æœŸå¼ºè¶‹åŠ¿æ ‡è®°\n",
    "df[\"strong_15\"] = (\n",
    "    (df[\"slope_15_norm\"].abs() > STRONG_15_SLOPE_THR) &\n",
    "    (df[\"er_15\"] > STRONG_15_ER_THR) &\n",
    "    (df[\"chop_15\"] < STRONG_15_CHOP_THR)\n",
    ").astype(int)\n",
    "\n",
    "df[\"strong_60\"] = (\n",
    "    (df[\"slope_60_norm\"].abs() > STRONG_60_SLOPE_THR) &\n",
    "    (df[\"er_60\"] > STRONG_60_ER_THR) &\n",
    "    (df[\"chop_60\"] < STRONG_60_CHOP_THR)\n",
    ").astype(int)\n",
    "\n",
    "print(f\"\\nå¼º 15min è¶‹åŠ¿ bar æ¯”ä¾‹: {df['strong_15'].mean()*100:.1f}%\")\n",
    "print(f\"å¼º 60min è¶‹åŠ¿ bar æ¯”ä¾‹: {df['strong_60'].mean()*100:.1f}%\")\n",
    "\n",
    "# ========== 2. å¸¦ MTF è¾…åŠ©çš„è¶‹åŠ¿è¯†åˆ« ==========\n",
    "def identify_trend_with_mtf(df: pd.DataFrame, is_range: np.ndarray,\n",
    "                             w_15: float = 0.15, w_60: float = 0.15,\n",
    "                             thr_score: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    å¸¦å¤šæ—¶é—´å‘¨æœŸè¾…åŠ©çš„è¶‹åŠ¿è¯†åˆ«\n",
    "\n",
    "    è¶‹åŠ¿å¾—åˆ† = base_score + mtf_bonus - mtf_penalty\n",
    "    - base_score: åŸºäº 5min çš„åŸå§‹æ¡ä»¶ (0-1)\n",
    "    - mtf_bonus: é«˜å‘¨æœŸåŒå‘åŠ åˆ†\n",
    "    - mtf_penalty: é«˜å‘¨æœŸåå‘å‡åˆ†\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    regime = np.zeros(n, dtype=np.int32)\n",
    "    trend_scores = np.zeros(n, dtype=np.float64)\n",
    "\n",
    "    # é¢„æå–æ•°ç»„ (åŠ é€Ÿ)\n",
    "    er = df[\"er\"].values\n",
    "    chop = df[\"chop\"].values\n",
    "    slope_norm = df[\"slope_norm\"].values\n",
    "    dist_norm = df[\"dist_norm\"].values\n",
    "    d_barrier = df[\"d_barrier\"].values\n",
    "    close = df[\"close\"].values\n",
    "\n",
    "    # é«˜å‘¨æœŸä¿¡æ¯\n",
    "    trend_dir_15 = df[\"trend_dir_15\"].fillna(0).values\n",
    "    trend_dir_60 = df[\"trend_dir_60\"].fillna(0).values\n",
    "    strong_15 = df[\"strong_15\"].fillna(0).values\n",
    "    strong_60 = df[\"strong_60\"].fillna(0).values\n",
    "    er_15 = df[\"er_15\"].fillna(0).values\n",
    "    er_60 = df[\"er_60\"].fillna(0).values\n",
    "\n",
    "    for t in range(n):\n",
    "        if is_range[t]:\n",
    "            regime[t] = 0\n",
    "            continue\n",
    "\n",
    "        if np.isnan(slope_norm[t]) or np.isnan(er[t]):\n",
    "            continue\n",
    "\n",
    "        # ========== 5min åŸºç¡€å¾—åˆ† ==========\n",
    "        dir_5 = np.sign(slope_norm[t])\n",
    "        if dir_5 == 0:\n",
    "            continue\n",
    "\n",
    "        # æ–¹å‘ä¸€è‡´æ€§ (ä½¿ç”¨æœªæ¥ L_FWD çš„æ”¶ç›Š)\n",
    "        future_idx = min(t + L_FWD, n - 1)\n",
    "        future_direction = np.sign(close[future_idx] - close[t])\n",
    "        direction_consistent = (dir_5 == future_direction) and (dir_5 != 0)\n",
    "\n",
    "        # æ„å»º base_score (0-1 åŒºé—´)\n",
    "        base_score = 0.0\n",
    "\n",
    "        # æ–¹å‘ä¸€è‡´ +0.3\n",
    "        if direction_consistent:\n",
    "            base_score += 0.3\n",
    "\n",
    "        # æ–œç‡å¼ºåº¦ +0.2\n",
    "        if abs(slope_norm[t]) > THR_SLOPE_NORM:\n",
    "            base_score += 0.2\n",
    "\n",
    "        # è¶‹åŠ¿è´¨é‡ (ER é«˜æˆ– chop ä½) +0.25\n",
    "        if er[t] > THR_ER_HIGH or chop[t] < THR_CHOP_LOW:\n",
    "            base_score += 0.25\n",
    "\n",
    "        # ä»·æ ¼åç¦» +0.15\n",
    "        if abs(dist_norm[t]) > THR_DIST_NORM:\n",
    "            base_score += 0.15\n",
    "\n",
    "        # Triple barrier ç¡®è®¤ +0.1\n",
    "        if d_barrier[t] == dir_5:\n",
    "            base_score += 0.1\n",
    "\n",
    "        # ========== MTF åŠ å‡åˆ† ==========\n",
    "        mtf_adjustment = 0.0\n",
    "\n",
    "        # 15min åŒå‘åŠ åˆ†\n",
    "        if trend_dir_15[t] == dir_5 and trend_dir_15[t] != 0:\n",
    "            mtf_adjustment += w_15\n",
    "\n",
    "        # 60min åŒå‘åŠ åˆ†\n",
    "        if trend_dir_60[t] == dir_5 and trend_dir_60[t] != 0:\n",
    "            mtf_adjustment += w_60\n",
    "\n",
    "        # é«˜å‘¨æœŸå¼ºåå‘ â†’ å¤§å¹…å‡åˆ† (å¯èƒ½æ˜¯ counter-trend pullback)\n",
    "        if strong_60[t] and trend_dir_60[t] == -dir_5:\n",
    "            base_score *= 0.5\n",
    "\n",
    "        # å¤šå‘¨æœŸå®Œå…¨æ··ä¹± â†’ å°å¹…é™æƒ\n",
    "        mtf_align = dir_5 + trend_dir_15[t] + trend_dir_60[t]\n",
    "        if abs(mtf_align) <= 1:\n",
    "            base_score *= 0.85\n",
    "\n",
    "        # æœ€ç»ˆå¾—åˆ†\n",
    "        final_score = base_score + mtf_adjustment\n",
    "        trend_scores[t] = final_score\n",
    "\n",
    "        # åˆ¤å®š\n",
    "        if final_score >= thr_score:\n",
    "            regime[t] = int(dir_5)\n",
    "\n",
    "    return regime, trend_scores\n",
    "\n",
    "\n",
    "# ========== 3. å¸¦ MTF è¿‡æ»¤çš„éœ‡è¡è¯†åˆ« ==========\n",
    "def identify_range_with_mtf_filter(df: pd.DataFrame, is_range_5m: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    åœ¨ 5min éœ‡è¡åŸºç¡€ä¸Šï¼Œæ ‡è®°\"å¼ºè¶‹åŠ¿ä¸­çš„éœ‡è¡\"\n",
    "\n",
    "    è¿”å›:\n",
    "        is_range_final: æœ€ç»ˆéœ‡è¡æ ‡è®°\n",
    "        is_range_in_trend: å¼ºè¶‹åŠ¿ä¸­çš„éœ‡è¡æ ‡è®° (ä»è®­ç»ƒé›†å‰”é™¤)\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    is_range_final = is_range_5m.copy()\n",
    "    is_range_in_trend = np.zeros(n, dtype=bool)\n",
    "\n",
    "    strong_60 = df[\"strong_60\"].fillna(0).values\n",
    "    er_60 = df[\"er_60\"].fillna(0.5).values\n",
    "    chop_60 = df[\"chop_60\"].fillna(0.5).values\n",
    "\n",
    "    for t in range(n):\n",
    "        if is_range_5m[t]:\n",
    "            # å¦‚æœ 60min æ˜¯å¼ºè¶‹åŠ¿ï¼Œæ ‡è®°ä¸º \"range_inside_trend\"\n",
    "            if strong_60[t] and er_60[t] > 0.45 and chop_60[t] < 0.55:\n",
    "                is_range_in_trend[t] = True\n",
    "                # å¯é€‰: ä¿æŒ is_range_final[t] = True (ä»ç„¶æ˜¯éœ‡è¡ï¼Œä½†è®­ç»ƒæ—¶å‰”é™¤)\n",
    "\n",
    "    return is_range_final, is_range_in_trend\n",
    "\n",
    "\n",
    "# ========== 4. æ‰§è¡Œ MTF è¾…åŠ©æ ‡æ³¨ ==========\n",
    "print(\"\\næ‰§è¡Œ MTF è¾…åŠ©æ ‡æ³¨...\")\n",
    "\n",
    "# ä½¿ç”¨åŸå§‹çš„ 5m éœ‡è¡åˆ¤å®š\n",
    "is_range_5m = df[\"is_range_extended\"].values if \"is_range_extended\" in df.columns else df[\"is_range\"].values\n",
    "\n",
    "# MTF è¿‡æ»¤éœ‡è¡\n",
    "is_range_mtf, is_range_in_trend = identify_range_with_mtf_filter(df, is_range_5m)\n",
    "\n",
    "# MTF è¾…åŠ©è¶‹åŠ¿è¯†åˆ«\n",
    "regime_mtf_raw, trend_scores = identify_trend_with_mtf(\n",
    "    df, is_range_mtf,\n",
    "    w_15=W_15, w_60=W_60, thr_score=THR_TREND_SCORE\n",
    ")\n",
    "\n",
    "# åº”ç”¨å¹³æ»‘ (ä¸åŸæ–¹æ³•ç›¸åŒ)\n",
    "regime_mtf = smooth_regime_labels(regime_mtf_raw, MIN_TREND_LEN, SMOOTH_WINDOW)\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "df[\"regime_mtf\"] = regime_mtf\n",
    "df[\"trend_score_mtf\"] = trend_scores\n",
    "df[\"is_range_in_trend\"] = is_range_in_trend\n",
    "\n",
    "# ========== 5. ç»Ÿè®¡å¯¹æ¯” ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ“Š åŸå§‹ vs MTF è¾…åŠ© Regime åˆ†å¸ƒå¯¹æ¯”\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# åŸå§‹åˆ†å¸ƒ\n",
    "orig_counts = df[\"regime\"].value_counts().sort_index()\n",
    "mtf_counts = df[\"regime_mtf\"].value_counts().sort_index()\n",
    "\n",
    "print(\"\\nåŸå§‹æ–¹æ³•:\")\n",
    "for k, v in orig_counts.items():\n",
    "    label = {-1: \"DOWN\", 0: \"RANGE\", 1: \"UP\"}.get(k, str(k))\n",
    "    print(f\"  {label}: {v:,} ({v/len(df)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nMTF è¾…åŠ©æ–¹æ³•:\")\n",
    "for k, v in mtf_counts.items():\n",
    "    label = {-1: \"DOWN\", 0: \"RANGE\", 1: \"UP\"}.get(k, str(k))\n",
    "    print(f\"  {label}: {v:,} ({v/len(df)*100:.2f}%)\")\n",
    "\n",
    "# æ ‡ç­¾å˜åŒ–ç»Ÿè®¡\n",
    "changed = (df[\"regime\"] != df[\"regime_mtf\"]).sum()\n",
    "print(f\"\\næ ‡ç­¾å˜åŒ–æ•°é‡: {changed:,} ({changed/len(df)*100:.2f}%)\")\n",
    "\n",
    "# å¼ºè¶‹åŠ¿ä¸­çš„éœ‡è¡æ•°é‡\n",
    "range_in_trend_count = df[\"is_range_in_trend\"].sum()\n",
    "print(f\"å¼ºè¶‹åŠ¿ä¸­çš„éœ‡è¡ bar: {range_in_trend_count:,} ({range_in_trend_count/len(df)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nCell 11 å®Œæˆ: MTF è¾…åŠ©æ ‡æ³¨ âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zKFeWd2i-2h"
   },
   "source": [
    "## Cell 12: åŸå§‹ vs MTF è¾…åŠ©æ ‡æ³¨ å¹¶æ’å¯è§†åŒ–å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4678,
     "status": "ok",
     "timestamp": 1765492600882,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "Ft8Okwx4eX1a",
    "outputId": "17a729f3-b442-452e-cf8c-52dc8732f247"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 12: åŸå§‹ vs MTF è¾…åŠ©æ ‡æ³¨ å¹¶æ’å¯è§†åŒ–å¯¹æ¯” ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ Side-by-side å¯¹æ¯”åŸå§‹æ–¹æ³•å’Œ MTF è¾…åŠ©æ–¹æ³•çš„ regime æ ‡æ³¨ç»“æœ\n",
    "   ç”¨äºå†³å®šæœ€ç»ˆé‡‡ç”¨å“ªç§æ–¹æ³•\n",
    "\"\"\"\n",
    "from bokeh.layouts import row as bokeh_row\n",
    "\n",
    "print(\"ç”ŸæˆåŸå§‹ vs MTF å¯¹æ¯”å›¾è¡¨...\")\n",
    "\n",
    "# ========== 1. ä¿®æ”¹ç»˜å›¾å‡½æ•°ä»¥æ”¯æŒä¸åŒ regime åˆ— ==========\n",
    "def plot_kline_comparison(df_day: pd.DataFrame, regime_col: str, title: str, width: int = 600) -> figure:\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶å•æ—¥ K çº¿å›¾ï¼Œæ”¯æŒæŒ‡å®š regime åˆ—\n",
    "    \"\"\"\n",
    "    df_day = df_day.copy().reset_index(drop=True)\n",
    "    df_day[\"idx\"] = range(len(df_day))\n",
    "\n",
    "    # åˆ›å»ºå›¾è¡¨\n",
    "    p = figure(\n",
    "        width=width, height=350,\n",
    "        title=title,\n",
    "        x_axis_label=\"Bar Index\",\n",
    "        y_axis_label=\"Price\",\n",
    "        tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
    "    )\n",
    "\n",
    "    # æ·»åŠ  regime èƒŒæ™¯è‰²\n",
    "    regime_colors = {-1: \"#FFCCCC\", 0: \"#FFFFCC\", 1: \"#CCFFCC\"}\n",
    "\n",
    "    # æŒ‰ regime åˆ†æ®µæ·»åŠ èƒŒæ™¯\n",
    "    current_regime = None\n",
    "    start_idx = 0\n",
    "\n",
    "    for i in range(len(df_day)):\n",
    "        r = df_day[regime_col].iloc[i] if not pd.isna(df_day[regime_col].iloc[i]) else 0\n",
    "        r = int(r)\n",
    "\n",
    "        if current_regime is None:\n",
    "            current_regime = r\n",
    "            start_idx = i\n",
    "        elif r != current_regime or i == len(df_day) - 1:\n",
    "            # æ·»åŠ å‰ä¸€æ®µçš„èƒŒæ™¯\n",
    "            end_idx = i if r != current_regime else i + 1\n",
    "            y_min = df_day[\"low\"].iloc[start_idx:end_idx].min() - 1\n",
    "            y_max = df_day[\"high\"].iloc[start_idx:end_idx].max() + 1\n",
    "\n",
    "            box = BoxAnnotation(\n",
    "                left=start_idx - 0.5, right=end_idx - 0.5,\n",
    "                fill_color=regime_colors.get(current_regime, \"#FFFFFF\"),\n",
    "                fill_alpha=0.3, level=\"underlay\"\n",
    "            )\n",
    "            p.add_layout(box)\n",
    "\n",
    "            current_regime = r\n",
    "            start_idx = i\n",
    "\n",
    "    # ç»˜åˆ¶ K çº¿\n",
    "    # é˜³çº¿ (ä¸Šæ¶¨)\n",
    "    bull_mask = df_day[\"close\"] >= df_day[\"open\"]\n",
    "    bear_mask = ~bull_mask\n",
    "\n",
    "    # é˜³çº¿å®ä½“\n",
    "    bull_idx = df_day[bull_mask][\"idx\"]\n",
    "    if len(bull_idx) > 0:\n",
    "        p.segment(x0=bull_idx, y0=df_day[bull_mask][\"low\"],\n",
    "                  x1=bull_idx, y1=df_day[bull_mask][\"high\"], color=\"green\", line_width=1)\n",
    "        p.vbar(x=bull_idx, width=0.6, top=df_day[bull_mask][\"close\"],\n",
    "               bottom=df_day[bull_mask][\"open\"], fill_color=\"green\", line_color=\"green\")\n",
    "\n",
    "    # é˜´çº¿å®ä½“\n",
    "    bear_idx = df_day[bear_mask][\"idx\"]\n",
    "    if len(bear_idx) > 0:\n",
    "        p.segment(x0=bear_idx, y0=df_day[bear_mask][\"low\"],\n",
    "                  x1=bear_idx, y1=df_day[bear_mask][\"high\"], color=\"red\", line_width=1)\n",
    "        p.vbar(x=bear_idx, width=0.6, top=df_day[bear_mask][\"open\"],\n",
    "               bottom=df_day[bear_mask][\"close\"], fill_color=\"red\", line_color=\"red\")\n",
    "\n",
    "    p.xaxis.visible = False\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "# ========== 2. é€‰æ‹©æ—¥æœŸè¿›è¡Œå¯¹æ¯” ==========\n",
    "# å‡†å¤‡ç»˜å›¾æ•°æ®\n",
    "df_plot = df.reset_index()\n",
    "df_plot[\"timestamp_dt\"] = pd.to_datetime(df_plot[\"timestamp\"].astype(str).str.slice(0, 19))\n",
    "df_plot[\"date\"] = df_plot[\"timestamp_dt\"].dt.date\n",
    "\n",
    "valid_dates = df_plot.groupby(\"date\").size()\n",
    "valid_dates = valid_dates[valid_dates >= 50].index.tolist()\n",
    "\n",
    "# éšæœºé€‰æ‹© 5 ä¸ªæ—¥æœŸè¿›è¡Œå¯¹æ¯”\n",
    "np.random.seed(42)\n",
    "sample_dates = np.random.choice(valid_dates, size=min(5, len(valid_dates)), replace=False)\n",
    "\n",
    "print(f\"é€‰æ‹© {len(sample_dates)} ä¸ªæ—¥æœŸè¿›è¡Œå¯¹æ¯”:\")\n",
    "for d in sample_dates:\n",
    "    print(f\"  - {d}\")\n",
    "\n",
    "# ========== 3. ç”Ÿæˆå¹¶æ’å¯¹æ¯”å›¾ ==========\n",
    "comparison_plots = []\n",
    "\n",
    "for date in sample_dates:\n",
    "    df_day = df_plot[df_plot[\"date\"] == date].copy()\n",
    "\n",
    "    if len(df_day) < 30:\n",
    "        continue\n",
    "\n",
    "    # ç»Ÿè®¡è¯¥æ—¥çš„æ ‡ç­¾å˜åŒ–\n",
    "    orig_counts = df_day[\"regime\"].value_counts().to_dict()\n",
    "    mtf_counts = df_day[\"regime_mtf\"].value_counts().to_dict()\n",
    "    changes = (df_day[\"regime\"] != df_day[\"regime_mtf\"]).sum()\n",
    "\n",
    "    # åŸå§‹æ–¹æ³•å›¾\n",
    "    title_orig = f\"{date} - åŸå§‹æ–¹æ³• | D:{orig_counts.get(-1,0)} R:{orig_counts.get(0,0)} U:{orig_counts.get(1,0)}\"\n",
    "    p_orig = plot_kline_comparison(df_day, \"regime\", title_orig, width=550)\n",
    "\n",
    "    # MTF è¾…åŠ©æ–¹æ³•å›¾\n",
    "    title_mtf = f\"{date} - MTFè¾…åŠ© | D:{mtf_counts.get(-1,0)} R:{mtf_counts.get(0,0)} U:{mtf_counts.get(1,0)} | å˜åŒ–:{changes}\"\n",
    "    p_mtf = plot_kline_comparison(df_day, \"regime_mtf\", title_mtf, width=550)\n",
    "\n",
    "    # å¹¶æ’å¸ƒå±€\n",
    "    comparison_plots.append(bokeh_row(p_orig, p_mtf))\n",
    "\n",
    "if comparison_plots:\n",
    "    comparison_layout = column(*comparison_plots)\n",
    "    show(comparison_layout)\n",
    "\n",
    "    # ä¿å­˜å¯¹æ¯”å›¾\n",
    "    chart_path = OUTPUT_DIR_CHARTS / \"regime_comparison_orig_vs_mtf.html\"\n",
    "    output_file(str(chart_path))\n",
    "    save(comparison_layout, filename=str(chart_path), title=\"Regime Comparison: Original vs MTF\")\n",
    "    print(f\"\\nå¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {chart_path}\")\n",
    "\n",
    "# ========== 4. æ±‡æ€»ç»Ÿè®¡ ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ“Š æ–¹æ³•å¯¹æ¯”æ±‡æ€»\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# è®¡ç®—å˜åŒ–çŸ©é˜µ\n",
    "print(\"\\næ ‡ç­¾å˜åŒ–çŸ©é˜µ (è¡Œ=åŸå§‹, åˆ—=MTF):\")\n",
    "change_matrix = pd.crosstab(df[\"regime\"], df[\"regime_mtf\"], margins=True, margins_name=\"Total\")\n",
    "print(change_matrix)\n",
    "\n",
    "# è¶‹åŠ¿è¯†åˆ«ç‡å¯¹æ¯”\n",
    "orig_trend_rate = (df[\"regime\"] != 0).mean() * 100\n",
    "mtf_trend_rate = (df[\"regime_mtf\"] != 0).mean() * 100\n",
    "print(f\"\\nè¶‹åŠ¿è¯†åˆ«ç‡:\")\n",
    "print(f\"  åŸå§‹æ–¹æ³•: {orig_trend_rate:.2f}%\")\n",
    "print(f\"  MTF è¾…åŠ©: {mtf_trend_rate:.2f}%\")\n",
    "\n",
    "# å¤šå‘¨æœŸä¸€è‡´æ€§åˆ†æ\n",
    "mtf_align = df[\"mtf_trend_alignment\"].dropna()\n",
    "print(f\"\\nå¤šå‘¨æœŸä¸€è‡´æ€§åˆ†å¸ƒ (åŸå§‹è¶‹åŠ¿æ ·æœ¬):\")\n",
    "trend_samples = df[df[\"regime\"] != 0][\"mtf_trend_alignment\"].dropna()\n",
    "for v in sorted(trend_samples.unique()):\n",
    "    count = (trend_samples == v).sum()\n",
    "    print(f\"  alignment={int(v)}: {count:,} ({count/len(trend_samples)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nCell 12 å®Œæˆ: å¯¹æ¯”å¯è§†åŒ– âœ…\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âš ï¸ è¯·æŸ¥çœ‹ä¸Šæ–¹å¯¹æ¯”å›¾ï¼Œå†³å®šæ˜¯å¦é‡‡ç”¨ MTF è¾…åŠ©æ–¹æ³•\")\n",
    "print(\"   å¦‚æœæ»¡æ„ï¼Œåç»­å°†ä½¿ç”¨ regime_mtf ä½œä¸ºæœ€ç»ˆæ ‡ç­¾\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71472,
     "status": "ok",
     "timestamp": 1765492672368,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "h7e7TM2ceX1a",
    "outputId": "d7b4018a-602c-4663-fe3a-7cc3e9f1c3a5"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 26: æœ€ç»ˆç‰¹å¾çŸ©é˜µ & æ•°æ®å¯¼å‡º (Final Feature Matrix) ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ æœ€ç»ˆå‡†å¤‡æœºå™¨å­¦ä¹ è®­ç»ƒæ•°æ®\n",
    "\n",
    "å…³é”®æ›´æ–°:\n",
    "1. ä½¿ç”¨ regime_mtf (å¤šå‘¨æœŸè¾…åŠ©æ ‡æ³¨) ä½œä¸ºæ ‡ç­¾ (å¯åˆ‡æ¢ä¸ºåŸå§‹ regime)\n",
    "2. æ’é™¤åŸå§‹å°ºåº¦ç‰¹å¾ (kama, atr, tr, bar_range)ï¼Œä½¿ç”¨å½’ä¸€åŒ–ç‰ˆæœ¬ (*_z)\n",
    "3. d_barrier åªç”¨äºæ ‡æ³¨ï¼Œä¸è¾“å…¥æ¨¡å‹è®­ç»ƒ (å®ƒä½¿ç”¨äº†æœªæ¥ä¿¡æ¯)\n",
    "\n",
    "æ³„éœ²æ£€æŸ¥æ¸…å•:\n",
    "âœ… æ— æ³„éœ²: ä½¿ç”¨ shift/rolling çš„è¿‡å»çª—å£ç‰¹å¾\n",
    "âœ… æ— æ³„éœ²: ä½¿ç”¨ expanding (ç´¯ç§¯åˆ°å½“å‰) çš„ç‰¹å¾\n",
    "âœ… æ— æ³„éœ²: å¤šå‘¨æœŸç‰¹å¾ä½¿ç”¨ floor - 1 å‘¨æœŸå¯¹é½\n",
    "âŒ æ³„éœ²: d_barrier (ä½¿ç”¨äº†æœªæ¥è·¯å¾„) â†’ æ’é™¤\n",
    "\"\"\"\n",
    "print(\"å‡†å¤‡æœ€ç»ˆç‰¹å¾çŸ©é˜µ...\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âš ï¸ é€‰æ‹©ä½¿ç”¨å“ªä¸ª regime ä½œä¸ºæ ‡ç­¾\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "USE_MTF_REGIME = True  # True: ä½¿ç”¨ MTF è¾…åŠ©æ ‡ç­¾, False: ä½¿ç”¨åŸå§‹æ ‡ç­¾\n",
    "\n",
    "LABEL_COL = \"regime_mtf\" if USE_MTF_REGIME else \"regime\"\n",
    "print(f\"\\nä½¿ç”¨æ ‡ç­¾åˆ—: {LABEL_COL}\")\n",
    "\n",
    "# ========== 1. å®šä¹‰ç‰¹å¾åˆ—è¡¨ (å·²æ’é™¤åŸå§‹å°ºåº¦ç‰¹å¾) ==========\n",
    "\n",
    "# åŸºç¡€æ³¢åŠ¨ç‰¹å¾ (å·²å½’ä¸€åŒ–)\n",
    "volatility_features = [\n",
    "    \"log_return\",       # å½“å‰æ”¶ç›Š (æ— é‡çº²)\n",
    "    \"range_atr\",        # åŒºé—´/ATR (æ¯”ä¾‹)\n",
    "    \"range_z\",          # Range z-score\n",
    "    \"range_z_ma5\",      # Range z-score å‡å€¼\n",
    "    \"atr_z\",            # ATR å½’ä¸€åŒ–\n",
    "    \"tr_z\",             # TR å½’ä¸€åŒ– (å¦‚æœå­˜åœ¨)\n",
    "    \"bar_range_z\",      # Bar range å½’ä¸€åŒ– (å¦‚æœå­˜åœ¨)\n",
    "]\n",
    "\n",
    "# è¶‹åŠ¿ç‰¹å¾ (æ— æ³„éœ² - å…¨éƒ¨ä½¿ç”¨è¿‡å»çª—å£)\n",
    "trend_features = [\n",
    "    \"er\",               # æ•ˆç‡å› å­ [0,1]\n",
    "    \"slope_norm\",       # KAMA æ–œç‡æ ‡å‡†åŒ– (ç›¸å¯¹ ATR)\n",
    "    \"dist_norm\",        # ä»·æ ¼åç¦»åº¦ (ç›¸å¯¹ ATR)\n",
    "    \"kama_z\",           # KAMA å½’ä¸€åŒ– (å¦‚æœå­˜åœ¨)\n",
    "    \"beta\",             # å›å½’æ–œç‡\n",
    "    \"r2\",               # RÂ² [0,1]\n",
    "    \"slope_10_norm\",    # 10-bar æ–œç‡\n",
    "    \"slope_30_norm\",    # 30-bar æ–œç‡\n",
    "    \"slope_60_norm\",    # 60-bar æ–œç‡\n",
    "    \"trend_alignment\",  # å¤šå°ºåº¦ä¸€è‡´æ€§ [-3, +3]\n",
    "]\n",
    "\n",
    "# éœ‡è¡ç‰¹å¾ (æ— æ³„éœ²)\n",
    "range_features = [\n",
    "    \"chop\",             # Choppiness Index [0,1]\n",
    "    \"overlap_ratio\",    # é‡å åº¦ [0,1]\n",
    "    \"dir_vol_ratio\",    # æ–¹å‘æ€§æ³¢åŠ¨ [0,1]\n",
    "    \"vol_up_ratio\",     # ä¸Šæ¶¨æ³¢åŠ¨å æ¯” [0,1]\n",
    "]\n",
    "\n",
    "# Bar ç»“æ„ç‰¹å¾ (æ— æ³„éœ²)\n",
    "bar_structure_features = [\n",
    "    \"is_bull\",          # é˜³çº¿ {0,1}\n",
    "    \"is_bear\",          # é˜´çº¿ {0,1}\n",
    "    \"bull_ratio\",       # é˜³çº¿æ¯”ä¾‹ [0,1]\n",
    "    \"bear_ratio\",       # é˜´çº¿æ¯”ä¾‹ [0,1]\n",
    "    \"bull_bear_diff\",   # å¤šç©ºå·® [-1,1]\n",
    "    \"consec_bull\",      # è¿ç»­é˜³çº¿\n",
    "    \"consec_bear\",      # è¿ç»­é˜´çº¿\n",
    "    \"body_ratio\",       # å®ä½“æ¯”ä¾‹ [0,1]\n",
    "    \"upper_wick_ratio\", # ä¸Šå½±çº¿æ¯”ä¾‹ [0,1]\n",
    "    \"lower_wick_ratio\", # ä¸‹å½±çº¿æ¯”ä¾‹ [0,1]\n",
    "    \"total_wick_ratio\", # æ€»å½±çº¿æ¯”ä¾‹ [0,1]\n",
    "    \"avg_body_ratio\",   # çª—å£å¹³å‡å®ä½“æ¯”ä¾‹\n",
    "    \"avg_total_wick_ratio\",  # çª—å£å¹³å‡å½±çº¿æ¯”ä¾‹\n",
    "    \"doji_like_ratio\",  # å°å®ä½“å¤§å½±çº¿æ¯”ä¾‹ [0,1]\n",
    "]\n",
    "\n",
    "# è…¿ç»“æ„ç‰¹å¾ (æ— æ³„éœ² - å…¨éƒ¨åŸºäºè¿‡å»)\n",
    "leg_features = [\n",
    "    \"legA_dir\", \"legA_prev1_dir\", \"legA_prev2_dir\", \"legA_changes_10\",\n",
    "    \"legB_dir\", \"legB_prev1_dir\", \"legB_prev2_dir\", \"legB_changes_10\",\n",
    "    \"legC_dir\", \"legC_prev1_dir\", \"legC_prev2_dir\", \"legC_changes_10\",\n",
    "]\n",
    "\n",
    "# Phase ç‰¹å¾ (æ— æ³„éœ²)\n",
    "phase_features = [\n",
    "    \"spike_score\",      # Spike åˆ†æ•° [0,1]\n",
    "    \"channel_score\",    # Channel åˆ†æ•° [0,1]\n",
    "    \"phase\",            # Phase {0,1,2}\n",
    "]\n",
    "\n",
    "# æ—¥å†…ç‰¹å¾ (æ— æ³„éœ² - expanding)\n",
    "intraday_features = [\n",
    "    \"pos_in_day_range\", # æ—¥å†…ä½ç½® [0,1]\n",
    "    \"dist_to_open\",     # è·å¼€ç›˜ä»·\n",
    "    \"day_return\",       # æ—¥å†…æ”¶ç›Š\n",
    "    \"bar_of_day\",       # å½“æ—¥ç¬¬å‡ æ ¹ bar\n",
    "    \"time_of_day_norm\", # æ—¶é—´å½’ä¸€åŒ– [0,1]\n",
    "    \"near_day_high\",    # æ¥è¿‘æ—¥é«˜ {0,1}\n",
    "    \"near_day_low\",     # æ¥è¿‘æ—¥ä½ {0,1}\n",
    "    \"near_open\",        # æ¥è¿‘å¼€ç›˜ {0,1}\n",
    "    \"is_open_range\",    # å¼€ç›˜é˜¶æ®µ {0,1}\n",
    "    \"is_close_range\",   # æ”¶ç›˜é˜¶æ®µ {0,1}\n",
    "]\n",
    "\n",
    "# å¤šå‘¨æœŸç‰¹å¾ (æ— æ³„éœ² - ä½¿ç”¨ floor-1 å¯¹é½)\n",
    "mtf_features = [\n",
    "    \"er_15\", \"slope_15_norm\", \"chop_15\", \"trend_dir_15\",\n",
    "    \"er_60\", \"slope_60_norm\", \"chop_60\", \"trend_dir_60\",\n",
    "    \"atr_ratio_15_5\", \"atr_ratio_60_5\", \"mtf_trend_alignment\",\n",
    "]\n",
    "\n",
    "# æ»åç‰¹å¾ (æ— æ³„éœ² - shift)\n",
    "lag_features = []\n",
    "for lag in range(1, 4):\n",
    "    lag_features.extend([\n",
    "        f\"er_lag{lag}\", f\"slope_norm_lag{lag}\", f\"dist_norm_lag{lag}\",\n",
    "        f\"chop_lag{lag}\", f\"r2_lag{lag}\", f\"range_z_lag{lag}\",\n",
    "        f\"dir_vol_ratio_lag{lag}\", f\"bull_bear_diff_lag{lag}\",\n",
    "        f\"avg_body_ratio_lag{lag}\",\n",
    "    ])\n",
    "\n",
    "# ç»Ÿè®¡ç‰¹å¾ (æ— æ³„éœ²)\n",
    "stat_features = [\n",
    "    \"regime_trend_ratio\", \"regime_up_ratio\", \"regime_down_ratio\",\n",
    "    \"regime_changes_N\", \"regime_consec\",\n",
    "    \"er_diff1\", \"er_diff3\", \"slope_norm_diff1\", \"slope_norm_diff3\",\n",
    "    \"chop_diff1\", \"chop_diff3\", \"range_z_diff1\", \"range_z_diff3\",\n",
    "    \"slope_accel\", \"slope_accel_ma3\",\n",
    "]\n",
    "\n",
    "# Volume ç‰¹å¾ (å¦‚æœå­˜åœ¨)\n",
    "volume_features = [\"volume_z\", \"log_volume_z\"]\n",
    "\n",
    "# ========== 2. åˆå¹¶æ‰€æœ‰ç‰¹å¾å¹¶è¿‡æ»¤å­˜åœ¨çš„åˆ— ==========\n",
    "all_features = (\n",
    "    volatility_features + trend_features + range_features +\n",
    "    bar_structure_features + leg_features + phase_features +\n",
    "    intraday_features + mtf_features + lag_features + stat_features +\n",
    "    volume_features\n",
    ")\n",
    "\n",
    "# æ˜ç¡®æ’é™¤çš„ç‰¹å¾ (åŸå§‹å°ºåº¦æˆ–æ³„éœ²)\n",
    "EXCLUDED_FEATURES = [\n",
    "    \"kama\", \"atr\", \"tr\", \"bar_range\", \"volume\",  # åŸå§‹å°ºåº¦\n",
    "    \"d_barrier\", \"regime_raw\", \"is_range\", \"is_range_extended\",  # æ³„éœ²æˆ–è¾…åŠ©æ ‡è®°\n",
    "    \"is_range_in_trend\", \"strong_15\", \"strong_60\", \"trend_score_mtf\",  # è¾…åŠ©å˜é‡\n",
    "]\n",
    "\n",
    "# è¿‡æ»¤: åªä¿ç•™å­˜åœ¨ä¸”æœªæ’é™¤çš„ç‰¹å¾\n",
    "training_features = [\n",
    "    col for col in all_features\n",
    "    if col in df.columns and col not in EXCLUDED_FEATURES\n",
    "]\n",
    "\n",
    "print(f\"\\nå¯ç”¨ç‰¹å¾æ•°é‡: {len(training_features)}\")\n",
    "\n",
    "# ========== 3. æ„å»ºè®­ç»ƒæ•°æ® ==========\n",
    "# è¿‡æ»¤æœ‰æ•ˆæ ·æœ¬ (é NaN)\n",
    "df_train = df.dropna(subset=[LABEL_COL]).copy()\n",
    "\n",
    "# æ„å»º X å’Œ y\n",
    "X = df_train[training_features].copy()\n",
    "y = df_train[LABEL_COL].astype(int).copy()\n",
    "\n",
    "# è¿‡æ»¤æ‰ç‰¹å¾ä¸­æœ‰ NaN çš„è¡Œ\n",
    "valid_mask = X.notna().all(axis=1)\n",
    "X = X[valid_mask]\n",
    "y = y[valid_mask]\n",
    "df_train = df_train[valid_mask]\n",
    "\n",
    "print(f\"æœ‰æ•ˆæ ·æœ¬æ•°: {len(X):,} / {len(df):,} ({len(X)/len(df)*100:.1f}%)\")\n",
    "print(f\"ç‰¹å¾æ•°: {X.shape[1]}\")\n",
    "\n",
    "# ========== 4. ç‰¹å¾ç»Ÿè®¡ ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ“Š ç‰¹å¾ç»Ÿè®¡\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# æŒ‰ç±»åˆ«ç»Ÿè®¡\n",
    "feature_categories = {\n",
    "    \"æ³¢åŠ¨\": volatility_features,\n",
    "    \"è¶‹åŠ¿\": trend_features,\n",
    "    \"éœ‡è¡\": range_features,\n",
    "    \"Barç»“æ„\": bar_structure_features,\n",
    "    \"è…¿ç»“æ„\": leg_features,\n",
    "    \"Phase\": phase_features,\n",
    "    \"æ—¥å†…\": intraday_features,\n",
    "    \"å¤šå‘¨æœŸ\": mtf_features,\n",
    "    \"æ»å\": lag_features,\n",
    "    \"ç»Ÿè®¡\": stat_features,\n",
    "}\n",
    "\n",
    "for cat, feats in feature_categories.items():\n",
    "    available = [f for f in feats if f in training_features]\n",
    "    print(f\"  {cat}: {len(available)} ä¸ªç‰¹å¾\")\n",
    "\n",
    "# ========== 5. æ ‡ç­¾åˆ†å¸ƒ ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"ğŸ“Š æ ‡ç­¾åˆ†å¸ƒ ({LABEL_COL})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "label_counts = y.value_counts().sort_index()\n",
    "for k, v in label_counts.items():\n",
    "    label_name = {-1: \"DOWN (-1)\", 0: \"RANGE (0)\", 1: \"UP (+1)\"}.get(k, str(k))\n",
    "    print(f\"  {label_name}: {v:,} ({v/len(y)*100:.2f}%)\")\n",
    "\n",
    "# ========== 6. å¯¼å‡ºè®­ç»ƒæ•°æ® ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ’¾ å¯¼å‡ºè®­ç»ƒæ•°æ®\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# å‡†å¤‡å¯¼å‡ºæ•°æ®\n",
    "df_train = df_train.reset_index()\n",
    "df_train[\"timestamp_str\"] = df_train[\"timestamp\"].astype(str)\n",
    "df_train[\"year\"] = pd.to_datetime(df_train[\"timestamp_str\"].str[:10]).dt.year\n",
    "df_train[\"month\"] = pd.to_datetime(df_train[\"timestamp_str\"].str[:10]).dt.month\n",
    "df_train[\"date\"] = df_train[\"timestamp_str\"].str[:10]\n",
    "\n",
    "# é€‰æ‹©è¦å¯¼å‡ºçš„åˆ—\n",
    "export_meta = [\"timestamp_str\", \"year\", \"month\", \"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "export_cols = export_meta + training_features + [LABEL_COL]\n",
    "export_cols = [c for c in export_cols if c in df_train.columns]\n",
    "\n",
    "# å»é‡\n",
    "export_cols = list(dict.fromkeys(export_cols))\n",
    "\n",
    "df_export = df_train[export_cols].copy()\n",
    "df_export = df_export.rename(columns={\"timestamp_str\": \"timestamp\", LABEL_COL: \"regime\"})\n",
    "\n",
    "# å¯¼å‡º\n",
    "OUTPUT_TRAIN_CSV = OUTPUT_DIR_FEATURES / \"market_cycle_train_data.csv\"\n",
    "OUTPUT_TRAIN_PARQUET = OUTPUT_DIR_FEATURES / \"market_cycle_train_data.parquet\"\n",
    "\n",
    "df_export.to_csv(OUTPUT_TRAIN_CSV, index=False)\n",
    "df_export.to_parquet(OUTPUT_TRAIN_PARQUET, index=False)\n",
    "\n",
    "print(f\"\\nğŸ“ è®­ç»ƒæ•°æ®å·²å¯¼å‡º:\")\n",
    "print(f\"   - CSV: {OUTPUT_TRAIN_CSV}\")\n",
    "print(f\"   - Parquet: {OUTPUT_TRAIN_PARQUET}\")\n",
    "print(f\"   - æ ·æœ¬æ•°: {len(df_export):,}\")\n",
    "print(f\"   - ç‰¹å¾æ•°: {len(training_features)}\")\n",
    "\n",
    "# ========== 7. æ•°æ®æ³„éœ²æœ€ç»ˆæ£€æŸ¥ ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ” æ•°æ®æ³„éœ²æ£€æŸ¥\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦æœ‰æœªæ¥ä¿¡æ¯ç‰¹å¾\n",
    "future_keywords = [\"_fwd\", \"future\", \"barrier\"]\n",
    "potential_leak = [c for c in training_features if any(k in c.lower() for k in future_keywords)]\n",
    "if potential_leak:\n",
    "    print(f\"âš ï¸ å‘ç°å¯èƒ½æ³„éœ²çš„ç‰¹å¾: {potential_leak}\")\n",
    "else:\n",
    "    print(\"âœ… æœªå‘ç°æ˜æ˜¾çš„æ•°æ®æ³„éœ²\")\n",
    "\n",
    "# æ£€æŸ¥åŸå§‹å°ºåº¦ç‰¹å¾\n",
    "raw_scale_in_train = [c for c in [\"kama\", \"atr\", \"tr\", \"bar_range\"] if c in training_features]\n",
    "if raw_scale_in_train:\n",
    "    print(f\"âš ï¸ è®­ç»ƒé›†ä¸­åŒ…å«åŸå§‹å°ºåº¦ç‰¹å¾: {raw_scale_in_train}\")\n",
    "else:\n",
    "    print(\"âœ… åŸå§‹å°ºåº¦ç‰¹å¾å·²æ’é™¤\")\n",
    "\n",
    "print(\"\\nCell 26 å®Œæˆ: æœ€ç»ˆç‰¹å¾çŸ©é˜µå‡†å¤‡å®Œæ¯• âœ…\")\n",
    "print(\"\\nğŸ‰ æ•°æ®å‡†å¤‡å®Œæˆï¼å¯ä»¥å¼€å§‹æœºå™¨å­¦ä¹ è®­ç»ƒäº†ï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48206,
     "status": "ok",
     "timestamp": 1765492720580,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "u3_S9Ea2eX1a",
    "outputId": "368fc56f-2dd1-435b-da6c-14d8178209df"
   },
   "outputs": [],
   "source": [
    "# ========== Save Sequence Data for Deep Learning ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ Save preprocessed sequence data for Notebook 3 (Deep Learning)\n",
    "This allows Notebook 3 to load pre-computed sequences instantly\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ’¾ Saving Sequence Data for Deep Learning\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load the training data\n",
    "df_seq = pd.read_parquet(OUTPUT_DIR_FEATURES / \"market_cycle_train_data.parquet\")\n",
    "\n",
    "# Define feature columns\n",
    "meta_cols = [\"timestamp\", \"year\", \"month\", \"date\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"regime\"]\n",
    "feature_cols = [c for c in df_seq.columns if c not in meta_cols]\n",
    "\n",
    "# Known future features (time-based, can be known in advance)\n",
    "known_future_features = [\"time_of_day_norm\", \"bar_of_day\", \"is_open_range\", \"is_close_range\"]\n",
    "known_future_features = [f for f in known_future_features if f in feature_cols]\n",
    "observed_features = [f for f in feature_cols if f not in known_future_features]\n",
    "\n",
    "# Label mapping\n",
    "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
    "df_seq[\"label\"] = df_seq[\"regime\"].map(label_mapping)\n",
    "\n",
    "# Standardize features\n",
    "X_raw = df_seq[feature_cols].values.astype(np.float32)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "\n",
    "# Create date arrays\n",
    "df_seq[\"date_str\"] = df_seq[\"date\"].astype(str)\n",
    "dates = df_seq[\"date_str\"].values\n",
    "\n",
    "# Sequence generation parameters\n",
    "SEQ_LEN = 30\n",
    "\n",
    "def create_sequences(X, y, dates, seq_len=30):\n",
    "    \"\"\"Create sliding window sequences, handling day boundaries\"\"\"\n",
    "    N = len(X)\n",
    "    sequences_X, sequences_y, indices = [], [], []\n",
    "\n",
    "    for i in range(seq_len - 1, N):\n",
    "        start_idx = i - seq_len + 1\n",
    "        seq_dates = dates[start_idx:i+1]\n",
    "\n",
    "        # Skip if sequence crosses day boundary\n",
    "        if len(set(seq_dates)) > 1:\n",
    "            continue\n",
    "\n",
    "        seq_X = X[start_idx:i+1]\n",
    "        if np.isnan(seq_X).any():\n",
    "            continue\n",
    "\n",
    "        sequences_X.append(seq_X)\n",
    "        sequences_y.append(y[i])\n",
    "        indices.append(i)\n",
    "\n",
    "    return np.array(sequences_X, dtype=np.float32), np.array(sequences_y, dtype=np.int64), np.array(indices)\n",
    "\n",
    "print(\"Creating sequences...\")\n",
    "y_raw = df_seq[\"label\"].values\n",
    "X_seq, y_seq, seq_indices = create_sequences(X_scaled, y_raw, dates, seq_len=SEQ_LEN)\n",
    "\n",
    "# Feature indices for TFT\n",
    "known_indices = [feature_cols.index(f) for f in known_future_features if f in feature_cols]\n",
    "observed_indices = [feature_cols.index(f) for f in observed_features if f in feature_cols]\n",
    "\n",
    "# Save everything\n",
    "output_path = OUTPUT_DIR_FEATURES / \"sequence_data.npz\"\n",
    "np.savez_compressed(\n",
    "    output_path,\n",
    "    X_seq=X_seq,\n",
    "    y_seq=y_seq,\n",
    "    seq_indices=seq_indices,\n",
    "    known_indices=np.array(known_indices),\n",
    "    observed_indices=np.array(observed_indices),\n",
    "    seq_dates=dates[seq_indices],\n",
    "    scaler_mean=scaler.mean_,\n",
    "    scaler_scale=scaler.scale_,\n",
    "    feature_cols=np.array(feature_cols),\n",
    "    known_features=np.array(known_future_features),\n",
    "    observed_features=np.array(observed_features),\n",
    "    label_names=np.array([\"DOWN\", \"RANGE\", \"UP\"])\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Sequence data saved to: {output_path}\")\n",
    "print(f\"   Sequences: {X_seq.shape}\")\n",
    "print(f\"   Features: {len(feature_cols)}\")\n",
    "print(f\"   Known features: {len(known_indices)}\")\n",
    "print(f\"   Observed features: {len(observed_indices)}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ‰ Notebook 1 å®Œæˆ! è¯·ç»§ç»­è¿è¡Œ Notebook 2 æˆ– 3\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42dHfkpMoHRN"
   },
   "source": [
    "## HMM æ ‡æ³¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1765493749627,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "XCSQGH9PoKio",
    "outputId": "eb6345c9-8b60-45e3-ae68-b1987d246366"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8985,
     "status": "ok",
     "timestamp": 1765493816846,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "Lc76j9_6oX_-",
    "outputId": "c2da0413-158d-46c3-a823-5a920ad9c666"
   },
   "outputs": [],
   "source": [
    "!pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1765496270522,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "_OQy5y_lxxMF",
    "outputId": "e4cc9171-7677-4692-e6d5-2aa35fefc649"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VR5bxaPboTpS"
   },
   "outputs": [],
   "source": [
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# 1. å–å‡ºç‰¹å¾ï¼Œå¹¶å¤„ç† NaN / inf\n",
    "# feat_cols = [\"log_return\", \"atr\", \"slope_norm\"]\n",
    "# feat_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "# feat_cols = [\"regime\", 'regime_mtf']\n",
    "feat_cols = [\"log_return\", \"ret_vol\"]\n",
    "df[\"ret_vol\"] = df[\"log_return\"].rolling(20).std()\n",
    "\n",
    "# å…ˆæ›¿æ¢ infï¼Œå† dropna\n",
    "features = df[feat_cols].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# è®°ä½å®ƒçš„ç´¢å¼•ï¼Œåé¢è¦è´´å›å»\n",
    "valid_idx = features.index\n",
    "\n",
    "# 2. ç‰¹å¾ç¼©æ”¾ï¼ˆHMM å¯¹å°ºåº¦æ¯”è¾ƒæ•æ„Ÿï¼Œå»ºè®®æ ‡å‡†åŒ–ï¼‰\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(features.values)\n",
    "\n",
    "# 3. è®­ç»ƒ HMM\n",
    "hmm = GaussianHMM(\n",
    "    n_components=3,          # æƒ³åˆ†å‡ ç§ regime\n",
    "    covariance_type=\"full\",\n",
    "    n_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "hmm.fit(X)\n",
    "\n",
    "# 4. é¢„æµ‹éšè—çŠ¶æ€\n",
    "hidden_states = hmm.predict(X)   # è¿™é‡Œä¸ä¼šå†æœ‰ NaN æŠ¥é”™\n",
    "\n",
    "# 5. æŠŠçŠ¶æ€è´´å›åŸ dfï¼ˆå…¶ä»–ä½ç½®ä¿æŒ NaNï¼‰\n",
    "df[\"regime_hmm_raw\"] = np.nan\n",
    "df.loc[valid_idx, \"regime_hmm_raw\"] = hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1765496886627,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "qv5UyIy9q279",
    "outputId": "720bbdd3-c6ad-405c-cc4c-4b7fb452544e"
   },
   "outputs": [],
   "source": [
    "df[\"regime_hmm_raw\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1765496953254,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "UqoL1C8V0WpJ",
    "outputId": "9516d64b-fae3-4d35-dc76-5636264a9ee2"
   },
   "outputs": [],
   "source": [
    "df[\"regime_mtf\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXvAeHejrT3R"
   },
   "outputs": [],
   "source": [
    "state_returns = (\n",
    "    # features[\"log_return\"]\n",
    "    # features[\"open\"]\n",
    "    features[\"regime\"]\n",
    "    .groupby(hidden_states)\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "# ä»ä½åˆ°é«˜ï¼šæœ€å·® = ä¸‹è·Œï¼Œä¸­é—´ = éœ‡è¡ï¼Œæœ€å¥½ = ä¸Šæ¶¨\n",
    "state_to_regime = {}\n",
    "state_to_regime[state_returns.index[0]] = -1   # æœ€å·®\n",
    "state_to_regime[state_returns.index[1]] = 1    # ä¸­\n",
    "state_to_regime[state_returns.index[2]] = 0    # æœ€å¥½\n",
    "\n",
    "df[\"regime_hmm\"] = df[\"regime_hmm_raw\"].map(state_to_regime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVwF0wce5dgF"
   },
   "source": [
    "### åŸå§‹ vs MTF vs HMM è¾…åŠ©æ ‡æ³¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8380,
     "status": "ok",
     "timestamp": 1765496676229,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "U_7qx_LjpDVO",
    "outputId": "30e60cb5-2838-4b23-b84b-3f269926a5f6"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 12: åŸå§‹ vs MTF vs HMM è¾…åŠ©æ ‡æ³¨ å¹¶æ’å¯è§†åŒ–å¯¹æ¯” ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ Side-by-side å¯¹æ¯”ä¸‰ç§æ–¹æ³•çš„ regime æ ‡æ³¨ç»“æœï¼š\n",
    "   1. åŸå§‹æ–¹æ³•  (regime)\n",
    "   2. MTF è¾…åŠ© (regime_mtf)\n",
    "   3. HMM æ–¹æ³• (regime_hmm)\n",
    "\"\"\"\n",
    "\n",
    "from bokeh.layouts import row as bokeh_row\n",
    "\n",
    "print(\"ç”Ÿæˆ åŸå§‹ vs MTF vs HMM å¯¹æ¯”å›¾è¡¨...\")\n",
    "\n",
    "# ========== 1. ç»˜å›¾å‡½æ•°ï¼ˆä¸éœ€è¦æ”¹åŠ¨å¤ªå¤šï¼Œåªæ˜¯é€šç”¨ regime åˆ—ï¼‰ ==========\n",
    "def plot_kline_comparison(\n",
    "    df_day: pd.DataFrame,\n",
    "    regime_col: str,\n",
    "    title: str,\n",
    "    width: int = 400\n",
    ") -> figure:\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶å•æ—¥ K çº¿å›¾ï¼Œæ”¯æŒæŒ‡å®š regime åˆ—\n",
    "    \"\"\"\n",
    "    df_day = df_day.copy().reset_index(drop=True)\n",
    "    df_day[\"idx\"] = range(len(df_day))\n",
    "\n",
    "    # åˆ›å»ºå›¾è¡¨\n",
    "    p = figure(\n",
    "        width=width, height=350,\n",
    "        title=title,\n",
    "        x_axis_label=\"Bar Index\",\n",
    "        y_axis_label=\"Price\",\n",
    "        tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
    "    )\n",
    "\n",
    "    # regime èƒŒæ™¯è‰²\n",
    "    regime_colors = {-1: \"#FFCCCC\", 0: \"#FFFFCC\", 1: \"#CCFFCC\"}\n",
    "\n",
    "    # æŒ‰ regime åˆ†æ®µæ·»åŠ èƒŒæ™¯\n",
    "    current_regime = None\n",
    "    start_idx = 0\n",
    "\n",
    "    for i in range(len(df_day)):\n",
    "        r_val = df_day[regime_col].iloc[i]\n",
    "        r = int(r_val) if not pd.isna(r_val) else 0\n",
    "\n",
    "        if current_regime is None:\n",
    "            current_regime = r\n",
    "            start_idx = i\n",
    "        elif r != current_regime or i == len(df_day) - 1:\n",
    "            # ç»“æŸä¸Šä¸€æ®µ\n",
    "            end_idx = i if r != current_regime else i + 1\n",
    "            y_min = df_day[\"low\"].iloc[start_idx:end_idx].min() - 1\n",
    "            y_max = df_day[\"high\"].iloc[start_idx:end_idx].max() + 1\n",
    "\n",
    "            box = BoxAnnotation(\n",
    "                left=start_idx - 0.5, right=end_idx - 0.5,\n",
    "                fill_color=regime_colors.get(current_regime, \"#FFFFFF\"),\n",
    "                fill_alpha=0.3, level=\"underlay\"\n",
    "            )\n",
    "            p.add_layout(box)\n",
    "\n",
    "            current_regime = r\n",
    "            start_idx = i\n",
    "\n",
    "    # ç»˜åˆ¶ K çº¿\n",
    "    bull_mask = df_day[\"close\"] >= df_day[\"open\"]\n",
    "    bear_mask = ~bull_mask\n",
    "\n",
    "    bull_idx = df_day[bull_mask][\"idx\"]\n",
    "    if len(bull_idx) > 0:\n",
    "        p.segment(\n",
    "            x0=bull_idx, y0=df_day[bull_mask][\"low\"],\n",
    "            x1=bull_idx, y1=df_day[bull_mask][\"high\"],\n",
    "            color=\"green\", line_width=1\n",
    "        )\n",
    "        p.vbar(\n",
    "            x=bull_idx, width=0.6,\n",
    "            top=df_day[bull_mask][\"close\"],\n",
    "            bottom=df_day[bull_mask][\"open\"],\n",
    "            fill_color=\"green\", line_color=\"green\"\n",
    "        )\n",
    "\n",
    "    bear_idx = df_day[bear_mask][\"idx\"]\n",
    "    if len(bear_idx) > 0:\n",
    "        p.segment(\n",
    "            x0=bear_idx, y0=df_day[bear_mask][\"low\"],\n",
    "            x1=bear_idx, y1=df_day[bear_mask][\"high\"],\n",
    "            color=\"red\", line_width=1\n",
    "        )\n",
    "        p.vbar(\n",
    "            x=bear_idx, width=0.6,\n",
    "            top=df_day[bear_mask][\"open\"],\n",
    "            bottom=df_day[bear_mask][\"close\"],\n",
    "            fill_color=\"red\", line_color=\"red\"\n",
    "        )\n",
    "\n",
    "    p.xaxis.visible = False\n",
    "    return p\n",
    "\n",
    "\n",
    "# ========== 2. é€‰æ‹©æ—¥æœŸè¿›è¡Œå¯¹æ¯” ==========\n",
    "df_plot = df.reset_index()\n",
    "df_plot[\"timestamp_dt\"] = pd.to_datetime(df_plot[\"timestamp\"].astype(str).str.slice(0, 19))\n",
    "df_plot[\"date\"] = df_plot[\"timestamp_dt\"].dt.date\n",
    "\n",
    "valid_dates = df_plot.groupby(\"date\").size()\n",
    "valid_dates = valid_dates[valid_dates >= 50].index.tolist()\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_dates = np.random.choice(valid_dates, size=min(5, len(valid_dates)), replace=False)\n",
    "\n",
    "print(f\"é€‰æ‹© {len(sample_dates)} ä¸ªæ—¥æœŸè¿›è¡Œå¯¹æ¯”:\")\n",
    "for d in sample_dates:\n",
    "    print(f\"  - {d}\")\n",
    "\n",
    "\n",
    "# ========== 3. ç”Ÿæˆâ€œä¸‰å›¾å¹¶æ’â€å¯¹æ¯” ==========\n",
    "comparison_plots = []\n",
    "\n",
    "for date in sample_dates:\n",
    "    df_day = df_plot[df_plot[\"date\"] == date].copy()\n",
    "    if len(df_day) < 30:\n",
    "        continue\n",
    "\n",
    "    # å„æ–¹æ³•è¯¥æ—¥æ ‡ç­¾ç»Ÿè®¡\n",
    "    orig_counts = df_day[\"regime\"].value_counts().to_dict()\n",
    "    mtf_counts = df_day[\"regime_mtf\"].value_counts().to_dict()\n",
    "    hmm_counts = df_day[\"regime_hmm\"].value_counts().to_dict()\n",
    "\n",
    "    changes_mtf = (df_day[\"regime\"] != df_day[\"regime_mtf\"]).sum()\n",
    "    changes_hmm = (df_day[\"regime\"] != df_day[\"regime_hmm\"]).sum()\n",
    "\n",
    "    title_orig = (\n",
    "        f\"{date} - åŸå§‹ | \"\n",
    "        f\"D:{orig_counts.get(-1,0)} R:{orig_counts.get(0,0)} U:{orig_counts.get(1,0)}\"\n",
    "    )\n",
    "    title_mtf = (\n",
    "        f\"{date} - MTF | \"\n",
    "        f\"D:{mtf_counts.get(-1,0)} R:{mtf_counts.get(0,0)} U:{mtf_counts.get(1,0)} \"\n",
    "        f\"| å˜æ›´(å¯¹åŸå§‹):{changes_mtf}\"\n",
    "    )\n",
    "    title_hmm = (\n",
    "        f\"{date} - HMM | \"\n",
    "        f\"D:{hmm_counts.get(-1,0)} R:{hmm_counts.get(0,0)} U:{hmm_counts.get(1,0)} \"\n",
    "        f\"| å˜æ›´(å¯¹åŸå§‹):{changes_hmm}\"\n",
    "    )\n",
    "\n",
    "    p_orig = plot_kline_comparison(df_day, \"regime\",      title_orig, width=400)\n",
    "    p_mtf  = plot_kline_comparison(df_day, \"regime_mtf\",  title_mtf,  width=400)\n",
    "    p_hmm  = plot_kline_comparison(df_day, \"regime_hmm\",  title_hmm,  width=400)\n",
    "\n",
    "    comparison_plots.append(bokeh_row(p_orig, p_mtf, p_hmm))\n",
    "\n",
    "if comparison_plots:\n",
    "    comparison_layout = column(*comparison_plots)\n",
    "    show(comparison_layout)\n",
    "\n",
    "    chart_path = OUTPUT_DIR_CHARTS / \"regime_comparison_orig_vs_mtf_vs_hmm.html\"\n",
    "    output_file(str(chart_path))\n",
    "    save(comparison_layout, filename=str(chart_path),\n",
    "         title=\"Regime Comparison: Original vs MTF vs HMM\")\n",
    "    print(f\"\\nå¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {chart_path}\")\n",
    "\n",
    "\n",
    "# ========== 4. æ±‡æ€»ç»Ÿè®¡ ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ“Š ä¸‰ç§æ–¹æ³•å¯¹æ¯”æ±‡æ€»\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\næ ‡ç­¾å˜åŒ–çŸ©é˜µ (è¡Œ=åŸå§‹, åˆ—=MTF):\")\n",
    "change_matrix_mtf = pd.crosstab(df[\"regime\"], df[\"regime_mtf\"],\n",
    "                                margins=True, margins_name=\"Total\")\n",
    "print(change_matrix_mtf)\n",
    "\n",
    "print(\"\\næ ‡ç­¾å˜åŒ–çŸ©é˜µ (è¡Œ=åŸå§‹, åˆ—=HMM):\")\n",
    "change_matrix_hmm = pd.crosstab(df[\"regime\"], df[\"regime_hmm\"],\n",
    "                                margins=True, margins_name=\"Total\")\n",
    "print(change_matrix_hmm)\n",
    "\n",
    "# è¶‹åŠ¿è¯†åˆ«ç‡å¯¹æ¯”\n",
    "orig_trend_rate = (df[\"regime\"] != 0).mean() * 100\n",
    "mtf_trend_rate  = (df[\"regime_mtf\"] != 0).mean() * 100\n",
    "hmm_trend_rate  = (df[\"regime_hmm\"] != 0).mean() * 100\n",
    "\n",
    "print(f\"\\nè¶‹åŠ¿è¯†åˆ«ç‡:\")\n",
    "print(f\"  åŸå§‹æ–¹æ³•: {orig_trend_rate:.2f}%\")\n",
    "print(f\"  MTF è¾…åŠ©: {mtf_trend_rate:.2f}%\")\n",
    "print(f\"  HMM æ–¹æ³•: {hmm_trend_rate:.2f}%\")\n",
    "\n",
    "# å¤šå‘¨æœŸä¸€è‡´æ€§åˆ†æè¿˜æ˜¯é’ˆå¯¹ MTF çš„ï¼Œä¸éœ€è¦æ”¹\n",
    "mtf_align = df[\"mtf_trend_alignment\"].dropna()\n",
    "print(f\"\\nå¤šå‘¨æœŸä¸€è‡´æ€§åˆ†å¸ƒ (åŸå§‹è¶‹åŠ¿æ ·æœ¬):\")\n",
    "trend_samples = df[df[\"regime\"] != 0][\"mtf_trend_alignment\"].dropna()\n",
    "for v in sorted(trend_samples.unique()):\n",
    "    count = (trend_samples == v).sum()\n",
    "    print(f\"  alignment={int(v)}: {count:,} ({count/len(trend_samples)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nCell 12 å®Œæˆ: ä¸‰æ–¹æ³•å¯¹æ¯”å¯è§†åŒ– âœ…\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âš ï¸ è¯·æŸ¥çœ‹ä¸Šæ–¹ä¸‰å›¾å¯¹æ¯”ï¼Œå†³å®šæ˜¯å¦é‡‡ç”¨ MTF / HMM ä½œä¸ºæœ€ç»ˆæ ‡ç­¾\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSPEYDtp26Hp"
   },
   "source": [
    "## 10+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UjolDTT27dV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_10p2_scores(\n",
    "    df: pd.DataFrame,\n",
    "    tick_size: float = 0.01,\n",
    "    max_shadow_ratio: float = 0.3,\n",
    "    body_balance_tol: float = 0.5,\n",
    "    min_body_range_ratio: float = 0.3,\n",
    "    min_move_atr: float = 1.0,\n",
    "    atr_col: str | None = None,\n",
    "    htf_trend_col: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æ ¹æ®â€œ10+2â€æ ‡å‡†ï¼Œå¯¹ã€ä¸‰æ ¹è¿ç»­Kçº¿ã€‘çš„å¤šå¤´/ç©ºå¤´è¶‹åŠ¿è´¨é‡è¿›è¡Œæ‰“åˆ†ã€‚\n",
    "    åœ¨ç¬¬ t æ ¹Kçº¿ä¸Šå¾—åˆ°ï¼š\n",
    "        - score_10p2_long  : (t-2,t-1,t) ä¸‰æ ¹ä½œä¸ºå¤šå¤´ç»„åˆçš„è´¨é‡è¯„åˆ† âˆˆ [0,1]\n",
    "        - score_10p2_short : (t-2,t-1,t) ä¸‰æ ¹ä½œä¸ºç©ºå¤´ç»„åˆçš„è´¨é‡è¯„åˆ† âˆˆ [0,1]\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    o, h, l, c = df[\"open\"], df[\"high\"], df[\"low\"], df[\"close\"]\n",
    "\n",
    "    # å•æ ¹Kçº¿åŸºç¡€é‡\n",
    "    # å®ä½“é•¿\n",
    "    body = (c - o).abs()\n",
    "    # ä¸Šå½±çº¿é•¿\n",
    "    upper = h - np.maximum(o, c)\n",
    "    # ä¸‹å½±çº¿é•¿\n",
    "    lower = np.minimum(o, c) - l\n",
    "    # å…¨é•¿\n",
    "    true_range = h - l + 1e-9\n",
    "\n",
    "    # ä¸ºæ–¹ä¾¿ä¸‰æ ¹ç»„åˆï¼Œç”¨ shift å¯¹é½åˆ°â€œå½“å‰bar = ç¬¬3æ ¹Kçº¿â€\n",
    "    body1, body2, body3 = body.shift(2), body.shift(1), body\n",
    "    upper1, upper2, upper3 = upper.shift(2), upper.shift(1), upper\n",
    "    lower1, lower2, lower3 = lower.shift(2), lower.shift(1), lower\n",
    "    o1, o2, o3 = o.shift(2), o.shift(1), o\n",
    "    h1, h2, h3 = h.shift(2), h.shift(1), h\n",
    "    l1, l2, l3 = l.shift(2), l.shift(1), l\n",
    "    c1, c2, c3 = c.shift(2), c.shift(1), c\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # A. åé¡¹åŸºç¡€æŒ‡æ ‡ï¼ˆæ–¹å‘æ— å…³éƒ¨åˆ†ï¼‰\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    base_conds = {}\n",
    "\n",
    "    # 1. Kçº¿ä½“ç§¯å‡è¡¡ï¼šä¸‰æ ¹å®ä½“å¤§å°æ¥è¿‘\n",
    "    # body_balance_tol = 0.5\n",
    "    # bar1 (1M) : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
    "    # bar2 (2M) : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
    "    # bar3 (3M) : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
    "    # bar1 (1M) : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
    "    # bar2 (1M) : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
    "    # bar3 (3M) : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
    "    mean_body = (body1 + body2 + body3) / 3\n",
    "    ratio1 = body1 / mean_body\n",
    "    ratio2 = body2 / mean_body\n",
    "    ratio3 = body3 / mean_body\n",
    "    base_conds[\"k_body_balance\"] = (\n",
    "        (ratio1.between(1 - body_balance_tol, 1 + body_balance_tol)) &\n",
    "        (ratio2.between(1 - body_balance_tol, 1 + body_balance_tol)) &\n",
    "        (ratio3.between(1 - body_balance_tol, 1 + body_balance_tol))\n",
    "    )\n",
    "\n",
    "\n",
    "    # # 8. æ— ä¸‹å½±çº¿ï¼ˆå½±çº¿ç›¸å¯¹å®ä½“è¾ƒçŸ­ï¼‰\n",
    "    # no_lower1 = (lower1 / (body1 + 1e-9)) <= max_shadow_ratio\n",
    "    # no_lower2 = (lower2 / (body2 + 1e-9)) <= max_shadow_ratio\n",
    "    # no_lower3 = (lower3 / (body3 + 1e-9)) <= max_shadow_ratio\n",
    "    # base_conds[\"k_no_lower_shadow\"] = (\n",
    "    #     (no_lower1.astype(int) +\n",
    "    #      no_lower2.astype(int) +\n",
    "    #      no_lower3.astype(int)) >= 2\n",
    "    # )\n",
    "\n",
    "    # # 9. æ— ä¸Šå½±çº¿\n",
    "    # no_upper1 = (upper1 / (body1 + 1e-9)) <= max_shadow_ratio\n",
    "    # no_upper2 = (upper2 / (body2 + 1e-9)) <= max_shadow_ratio\n",
    "    # no_upper3 = (upper3 / (body3 + 1e-9)) <= max_shadow_ratio\n",
    "    # base_conds[\"k_no_upper_shadow\"] = (\n",
    "    #     (no_upper1.astype(int) +\n",
    "    #      no_upper2.astype(int) +\n",
    "    #      no_upper3.astype(int)) >= 2\n",
    "    # )\n",
    "\n",
    "    # # 10. çº¯ç²¹æŸ±ï¼šä¸‰æ ¹éƒ½ä¸æ˜¯åå­—æ˜Ÿ\n",
    "    # body_ratio1 = body1 / (h1 - l1 + 1e-9)\n",
    "    # body_ratio2 = body2 / (h2 - l2 + 1e-9)\n",
    "    # body_ratio3 = body3 / (h3 - l3 + 1e-9)\n",
    "    # no_doji = (body_ratio1 > min_body_range_ratio) & \\\n",
    "    #           (body_ratio2 > min_body_range_ratio) & \\\n",
    "    #           (body_ratio3 > min_body_range_ratio)\n",
    "    no_doji = True\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # B. æ–¹å‘ç›¸å…³éƒ¨åˆ†ï¼šå¤šå¤´ & ç©ºå¤´ å„è‡ªä¸€å¥—\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "    # ===== å¤šå¤´ï¼ˆlongï¼‰ =====\n",
    "    long_conds = {}\n",
    "\n",
    "    # 2L. æ”¶ç›˜å¼ºåŠ¿ï¼šæ”¶ç›˜é è¿‘é«˜ä½ï¼ˆä¸Šå½±çº¿çŸ­ï¼‰ï¼Œ3æ ¹è‡³å°‘2æ ¹æ»¡è¶³\n",
    "    strong_close1_long = (upper1 / (h1 - l1 + 1e-9)) <= max_shadow_ratio\n",
    "    strong_close2_long = (upper2 / (h2 - l2 + 1e-9)) <= max_shadow_ratio\n",
    "    strong_close3_long = (upper3 / (h3 - l3 + 1e-9)) <= max_shadow_ratio\n",
    "    long_conds[\"k_close_strong\"] = (\n",
    "        (strong_close1_long.astype(int) +\n",
    "         strong_close2_long.astype(int) +\n",
    "         strong_close3_long.astype(int)) >= 2\n",
    "    )\n",
    "\n",
    "    # 3L. Micro gapsï¼ˆå¤šå¤´ï¼‰ï¼šå®ä½“ä¹‹é—´å­˜åœ¨æœªå›è¡¥çš„å‘ä¸Šé—´éš™ï¼ˆgap upï¼‰\n",
    "    # å®ä½“åŒºé—´\n",
    "    body_low1,  body_high1  = np.minimum(o1, c1), np.maximum(o1, c1)\n",
    "    body_low2,  body_high2  = np.minimum(o2, c2), np.maximum(o2, c2)\n",
    "    body_low3,  body_high3  = np.minimum(o3, c3), np.maximum(o3, c3)\n",
    "    t = tick_size\n",
    "\n",
    "    # a) 1-2 gap upï¼šbar2 å®ä½“æ•´ä½“è·³åˆ° bar1 ä¸Šæ–¹\n",
    "    gap_up_12 = body_low2 > body_high1 + t\n",
    "\n",
    "    # b) æœªå›è¡¥ï¼ˆä¸¥æ ¼ç‰ˆï¼‰ï¼šbar3 å®ä½“ä»åœ¨ gap ä¸Šæ–¹ï¼ˆä¸è¿›å…¥ gap åŒºé—´ï¼‰\n",
    "    # gap_up åŒºé—´ï¼š(body_high1, body_low2)ï¼Œè¦æ±‚ bar3 å®ä½“ä¸‹æ²¿ >= body_low2\n",
    "    unfilled_up_12 = gap_up_12 & (body_low3 >= body_low2)\n",
    "\n",
    "    # c) 2-3 gap upï¼šæˆªè‡³ bar3 æ”¶ç›˜ä»å­˜åœ¨ï¼ˆæœªæ¥æ˜¯å¦å›è¡¥ä¸å¯çŸ¥ï¼‰\n",
    "    gap_up_23 = body_low3 > body_high2 + t\n",
    "\n",
    "    long_conds[\"k_micro_gap\"] = unfilled_up_12 | gap_up_23\n",
    "\n",
    "    # 4L. Kçº¿é—´ç¼ºå£ï¼ˆå‘ä¸Šï¼‰ï¼šå‰ä¸€æ ¹æœ€é«˜ < åä¸€æ ¹æœ€ä½\n",
    "    gap_12_long = h1 < l2 - tick_size\n",
    "    gap_23_long = h2 < l3 - tick_size\n",
    "    long_conds[\"k_bar_gap\"] = gap_12_long | gap_23_long\n",
    "\n",
    "    # 5L. æ”¶ç›˜ä»·é€’å¢ï¼šæ¯æ ¹æ”¶ç›˜ > å‰ä¸€æ ¹æœ€é«˜\n",
    "    long_conds[\"k_close_trend\"] = (c2 > h1) & (c3 > h2)\n",
    "\n",
    "    # 6L. ä½ç‚¹é€’å¢\n",
    "    long_conds[\"k_low_trend\"] = (l2 > l1) & (l3 > l2)\n",
    "\n",
    "    # # 7L. Close/Open Gap å‘ä¸Š\n",
    "    # gap_co_12_long = o2 > c1 + tick_size\n",
    "    # gap_co_23_long = o3 > c2 + tick_size\n",
    "    # long_conds[\"k_close_open_gap\"] = gap_co_12_long & gap_co_23_long\n",
    "\n",
    "    # 10L. çº¯é˜³çº¿\n",
    "    all_bull = (c1 > o1) & (c2 > o2) & (c3 > o3)\n",
    "    long_conds[\"k_pure_bars\"] = all_bull & no_doji\n",
    "\n",
    "    # ===== ç©ºå¤´ï¼ˆshortï¼‰ =====\n",
    "    short_conds = {}\n",
    "\n",
    "    # 2S. æ”¶ç›˜å¼ºåŠ¿ï¼ˆç©ºå¤´ï¼‰ï¼šæ”¶ç›˜é è¿‘ä½ä½ï¼ˆä¸‹å½±çº¿çŸ­ï¼‰\n",
    "    strong_close1_short = (lower1 / (h1 - l1 + 1e-9)) >= -max_shadow_ratio  # å®é™…=è´Ÿæ•°ï¼Œç®€å•ç”¨ä¸‹å½±çº¿å æ¯”\n",
    "    strong_close1_short = (lower1.abs() / (h1 - l1 + 1e-9)) <= max_shadow_ratio\n",
    "    strong_close2_short = (lower2.abs() / (h2 - l2 + 1e-9)) <= max_shadow_ratio\n",
    "    strong_close3_short = (lower3.abs() / (h3 - l3 + 1e-9)) <= max_shadow_ratio\n",
    "    short_conds[\"k_close_strong\"] = (\n",
    "        (strong_close1_short.astype(int) +\n",
    "         strong_close2_short.astype(int) +\n",
    "         strong_close3_short.astype(int)) >= 2\n",
    "    )\n",
    "\n",
    "    # 3S. Micro gapsï¼ˆç©ºå¤´ï¼‰ï¼šå®ä½“ä¹‹é—´å­˜åœ¨æœªå›è¡¥çš„å‘ä¸‹é—´éš™ï¼ˆgap downï¼‰\n",
    "    # a) 1-2 gap downï¼šbar2 å®ä½“æ•´ä½“è·³åˆ° bar1 ä¸‹æ–¹\n",
    "    gap_down_12 = body_low1 > body_high2 + t\n",
    "\n",
    "    # b) æœªå›è¡¥ï¼ˆä¸¥æ ¼ç‰ˆï¼‰ï¼šbar3 å®ä½“ä»åœ¨ gap ä¸‹æ–¹ï¼ˆä¸è¿›å…¥ gap åŒºé—´ï¼‰\n",
    "    # gap_down åŒºé—´ï¼š(body_high2, body_low1)ï¼Œè¦æ±‚ bar3 å®ä½“ä¸Šæ²¿ <= body_high2\n",
    "    unfilled_down_12 = gap_down_12 & (body_high3 <= body_high2)\n",
    "\n",
    "    # c) 2-3 gap downï¼šæˆªè‡³ bar3 æ”¶ç›˜ä»å­˜åœ¨ï¼ˆæœªæ¥æ˜¯å¦å›è¡¥ä¸å¯çŸ¥ï¼‰\n",
    "    gap_down_23 = body_low2 > body_high3 + t\n",
    "\n",
    "    short_conds[\"k_micro_gap\"] = unfilled_down_12 | gap_down_23\n",
    "\n",
    "    # 4S. Kçº¿é—´ç¼ºå£ï¼ˆå‘ä¸‹ï¼‰ï¼šå‰ä¸€æ ¹æœ€ä½ > åä¸€æ ¹æœ€é«˜\n",
    "    gap_12_short = l1 > h2 + tick_size\n",
    "    gap_23_short = l2 > h3 + tick_size\n",
    "    short_conds[\"k_bar_gap\"] = gap_12_short | gap_23_short\n",
    "\n",
    "    # 5S. æ”¶ç›˜ä»·é€’å‡ï¼šæ¯æ ¹æ”¶ç›˜ < å‰ä¸€æ ¹æœ€ä½\n",
    "    short_conds[\"k_close_trend\"] = (c2 < l1) & (c3 < l2)\n",
    "\n",
    "    # 6S. é«˜ç‚¹é€’å‡\n",
    "    short_conds[\"k_high_trend\"] = (h2 < h1) & (h3 < h2)\n",
    "\n",
    "    # # 7S. Close/Open Gap å‘ä¸‹\n",
    "    # gap_co_12_short = o2 < c1 - tick_size\n",
    "    # gap_co_23_short = o3 < c2 - tick_size\n",
    "    # short_conds[\"k_close_open_gap\"] = gap_co_12_short & gap_co_23_short\n",
    "\n",
    "    # 10S. çº¯é˜´çº¿\n",
    "    all_bear = (c1 < o1) & (c2 < o2) & (c3 < o3)\n",
    "    short_conds[\"k_pure_bars\"] = all_bear & no_doji\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # C. æ±‡æ€»å¤šå¤´/ç©ºå¤´ 10 é¡¹åŸºç¡€æ¡ä»¶\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    #   åŸºç¡€æ¡ä»¶ = æ–¹å‘æ— å…³ + å¯¹åº”æ–¹å‘çš„æ¡ä»¶\n",
    "    long_base_cols  = list(base_conds.keys())  + list(long_conds.keys())\n",
    "    short_base_cols = list(base_conds.keys())  + list(short_conds.keys())\n",
    "\n",
    "    for k, v in base_conds.items():\n",
    "        df[f\"cond_base_{k}\"] = v.astype(int)\n",
    "\n",
    "    for k, v in long_conds.items():\n",
    "        df[f\"cond_long_{k}\"] = v.astype(int)\n",
    "\n",
    "    for k, v in short_conds.items():\n",
    "        df[f\"cond_short_{k}\"] = v.astype(int)\n",
    "\n",
    "    df[\"num_base_long_ok\"] = df[[f\"cond_base_{k}\" for k in base_conds.keys()] +\n",
    "                                [f\"cond_long_{k}\" for k in long_conds.keys()]].sum(axis=1)\n",
    "    df[\"num_base_short_ok\"] = df[[f\"cond_base_{k}\" for k in base_conds.keys()] +\n",
    "                                 [f\"cond_short_{k}\" for k in short_conds.keys()]].sum(axis=1)\n",
    "\n",
    "    df[\"score_base_long\"]  = (1.0 - (7 - df[\"num_base_long_ok\"])  * 0.05).clip(0.0, 1.0)\n",
    "    df[\"score_base_short\"] = (1.0 - (7 - df[\"num_base_short_ok\"]) * 0.05).clip(0.0, 1.0)\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # D. ä¸¤é¡¹é¢å¤–å¦å†³æŒ‡æ ‡ï¼šé¡ºåŠ¿ & ä½ç§»å……è¶³\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # # 11. é¡ºåŠ¿åŸåˆ™\n",
    "    # if htf_trend_col is not None and htf_trend_col in df.columns:\n",
    "    #     # å¤šå¤´ï¼šå¤§çº§åˆ«è¶‹åŠ¿ >= 0\n",
    "    #     cond_follow_trend_long  = df[htf_trend_col] >= 0\n",
    "    #     # ç©ºå¤´ï¼šå¤§çº§åˆ«è¶‹åŠ¿ <= 0\n",
    "    #     cond_follow_trend_short = df[htf_trend_col] <= 0\n",
    "    # else:\n",
    "    #     cond_follow_trend_long  = pd.Series(True, index=df.index)\n",
    "    #     cond_follow_trend_short = pd.Series(True, index=df.index)\n",
    "\n",
    "    # df[\"cond_follow_trend_long\"]  = cond_follow_trend_long.astype(int)\n",
    "    # df[\"cond_follow_trend_short\"] = cond_follow_trend_short.astype(int)\n",
    "\n",
    "    # 12. ä½ç§»å……è¶³\n",
    "    total_move_long  = c3 - o1      # å¤šå¤´ï¼šå‘ä¸Šä½ç§»\n",
    "    total_move_short = o1 - c3      # ç©ºå¤´ï¼šå‘ä¸‹ä½ç§»\n",
    "\n",
    "    if atr_col is not None and atr_col in df.columns:\n",
    "        atr = df[atr_col]\n",
    "        cond_enough_move_long  = total_move_long  > (min_move_atr * atr)\n",
    "        cond_enough_move_short = total_move_short > (min_move_atr * atr)\n",
    "    else:\n",
    "        avg_range = (true_range.rolling(50).mean()).shift(1)\n",
    "        cond_enough_move_long  = total_move_long  > (min_move_atr * avg_range)\n",
    "        cond_enough_move_short = total_move_short > (min_move_atr * avg_range)\n",
    "\n",
    "    df[\"cond_enough_move_long\"]  = cond_enough_move_long.astype(int)\n",
    "    df[\"cond_enough_move_short\"] = cond_enough_move_short.astype(int)\n",
    "\n",
    "    # df[\"num_extra_long_ok\"]  = df[\"cond_follow_trend_long\"]  + df[\"cond_enough_move_long\"]\n",
    "    # df[\"num_extra_short_ok\"] = df[\"cond_follow_trend_short\"] + df[\"cond_enough_move_short\"]\n",
    "\n",
    "    df[\"score_extra_long\"]  = (1.0 - (1 - df[\"cond_enough_move_long\"])  * 0.10).clip(0.0, 1.0)\n",
    "    df[\"score_extra_short\"] = (1.0 - (1 - df[\"cond_enough_move_long\"]) * 0.10).clip(0.0, 1.0)\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # E. ç»¼åˆ 10+2 å¾—åˆ†\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    df[\"score_10p2_long\"]  = (df[\"score_base_long\"]  * df[\"score_extra_long\"]).clip(0.0, 1.0)\n",
    "    df[\"score_10p2_short\"] = (df[\"score_base_short\"] * df[\"score_extra_short\"]).clip(0.0, 1.0)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8GKjspV2-tl"
   },
   "outputs": [],
   "source": [
    "def label_regime_by_10p2(\n",
    "    df: pd.DataFrame,\n",
    "    lookback: int = 20,\n",
    "    high_score: float = 0.8,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æ ¹æ® 10+2 å¤šç©ºå¾—åˆ†ï¼Œç»™å‡ºä¸€ä¸ªç®€å•çš„å¸‚åœºå‘¨æœŸæ ‡ç­¾ï¼š\n",
    "    +1: å¤šå¤´è¶‹åŠ¿ä¸»å¯¼\n",
    "    -1: ç©ºå¤´è¶‹åŠ¿ä¸»å¯¼\n",
    "     0: éœ‡è¡ / æ— æ˜æ˜¾è¶‹åŠ¿\n",
    "\n",
    "    è§„åˆ™ï¼š\n",
    "    - long_trend_strength = æœ€è¿‘ lookback å†…æœ€é«˜çš„ score_10p2_long\n",
    "    - short_trend_strength = æœ€è¿‘ lookback å†…æœ€é«˜çš„ score_10p2_short\n",
    "    - è‹¥ä¸¤è€…éƒ½ä½äº high_score â†’ 0\n",
    "    - è‹¥è‡³å°‘ä¸€æ–¹ >= high_score â†’ å–åˆ†æ•°æ›´é«˜çš„ä¸€æ–¹çš„æ–¹å‘\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"long_trend_strength\"]  = df[\"score_10p2_long\"].rolling(lookback).max()\n",
    "    df[\"short_trend_strength\"] = df[\"score_10p2_short\"].rolling(lookback).max()\n",
    "\n",
    "    long_str  = df[\"long_trend_strength\"]\n",
    "    short_str = df[\"short_trend_strength\"]\n",
    "\n",
    "    regime = np.zeros(len(df), dtype=int)\n",
    "\n",
    "    cond_long  = long_str  >= high_score\n",
    "    cond_short = short_str >= high_score\n",
    "\n",
    "    # åªå¤šå¤´å¼º\n",
    "    regime[cond_long & ~cond_short] = 1\n",
    "    # åªç©ºå¤´å¼º\n",
    "    regime[cond_short & ~cond_long] = -1\n",
    "    # ä¸¤è¾¹éƒ½å¼º â†’ é€‰æ›´å¼ºçš„é‚£è¾¹\n",
    "    both = cond_long & cond_short\n",
    "    regime[both & (long_str >= short_str)] = 1\n",
    "    regime[both & (short_str > long_str)] = -1\n",
    "\n",
    "    df[\"regime_10p2\"] = regime\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mlrs25vB3A7d"
   },
   "outputs": [],
   "source": [
    "# from three_bar_10p2 import compute_10p2_scores, label_regime_by_10p2\n",
    "\n",
    "df = compute_10p2_scores(\n",
    "    df,\n",
    "    tick_size=0.01,\n",
    "    atr_col=\"atr\",          # å¦‚æœæ²¡æœ‰ATRï¼Œå°±å…ˆä¼  None\n",
    "    htf_trend_col=\"htf_trend\"  # å¦‚æœæ²¡æœ‰å¤§çº§åˆ«è¶‹åŠ¿ï¼Œå°±å…ˆä¼  None\n",
    ")\n",
    "\n",
    "df = label_regime_by_10p2(df, lookback=20, high_score=0.8)\n",
    "\n",
    "# ä¹‹åç”¨ df_scored[\"regime_10p2\"] ä½œä¸ºæ–°çš„å¸‚åœºå‘¨æœŸæ ‡ç­¾ç”»å›¾å³å¯\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1765498575513,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "0hqcDeQv3pTB",
    "outputId": "9d50b524-ce1d-4a87-dd83-e1d6e3e76018"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1765498579074,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "xUuYxYGZ3qgT",
    "outputId": "594d2cfe-db60-4b6f-f231-cdecad3bac69"
   },
   "outputs": [],
   "source": [
    "df[\"regime_10p2\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cTagLXe5hW6"
   },
   "source": [
    "### åŸå§‹ vs MTF vs 10+2 è¾…åŠ©æ ‡æ³¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8390,
     "status": "ok",
     "timestamp": 1765498591920,
     "user": {
      "displayName": "Haipei Xu",
      "userId": "12284641341061669545"
     },
     "user_tz": 300
    },
    "id": "iruuRKPj37Xt",
    "outputId": "7b0980a8-9886-477a-a1ca-c6df7c8b985a"
   },
   "outputs": [],
   "source": [
    "# ========== Cell 12: åŸå§‹ vs MTF vs 10+2 è¾…åŠ©æ ‡æ³¨ å¹¶æ’å¯è§†åŒ–å¯¹æ¯” ==========\n",
    "\"\"\"\n",
    "ğŸ“Œ Side-by-side å¯¹æ¯”ä¸‰ç§æ–¹æ³•çš„ regime æ ‡æ³¨ç»“æœï¼š\n",
    "   1. åŸå§‹æ–¹æ³•  (regime)\n",
    "   2. MTF è¾…åŠ© (regime_mtf)\n",
    "   3. 10+2 æ–¹æ³• (regime_10p2)\n",
    "\"\"\"\n",
    "\n",
    "from bokeh.layouts import row as bokeh_row\n",
    "\n",
    "print(\"ç”Ÿæˆ åŸå§‹ vs MTF vs 10+2 å¯¹æ¯”å›¾è¡¨...\")\n",
    "\n",
    "# ========== 1. ç»˜å›¾å‡½æ•°ï¼ˆä¸éœ€è¦æ”¹åŠ¨å¤ªå¤šï¼Œåªæ˜¯é€šç”¨ regime åˆ—ï¼‰ ==========\n",
    "def plot_kline_comparison(\n",
    "    df_day: pd.DataFrame,\n",
    "    regime_col: str,\n",
    "    title: str,\n",
    "    width: int = 400\n",
    ") -> figure:\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶å•æ—¥ K çº¿å›¾ï¼Œæ”¯æŒæŒ‡å®š regime åˆ—\n",
    "    \"\"\"\n",
    "    df_day = df_day.copy().reset_index(drop=True)\n",
    "    df_day[\"idx\"] = range(len(df_day))\n",
    "\n",
    "    # åˆ›å»ºå›¾è¡¨\n",
    "    p = figure(\n",
    "        width=width, height=350,\n",
    "        title=title,\n",
    "        x_axis_label=\"Bar Index\",\n",
    "        y_axis_label=\"Price\",\n",
    "        tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
    "    )\n",
    "\n",
    "    # regime èƒŒæ™¯è‰²\n",
    "    regime_colors = {-1: \"#FFCCCC\", 0: \"#FFFFCC\", 1: \"#CCFFCC\"}\n",
    "\n",
    "    # æŒ‰ regime åˆ†æ®µæ·»åŠ èƒŒæ™¯\n",
    "    current_regime = None\n",
    "    start_idx = 0\n",
    "\n",
    "    for i in range(len(df_day)):\n",
    "        r_val = df_day[regime_col].iloc[i]\n",
    "        r = int(r_val) if not pd.isna(r_val) else 0\n",
    "\n",
    "        if current_regime is None:\n",
    "            current_regime = r\n",
    "            start_idx = i\n",
    "        elif r != current_regime or i == len(df_day) - 1:\n",
    "            # ç»“æŸä¸Šä¸€æ®µ\n",
    "            end_idx = i if r != current_regime else i + 1\n",
    "            y_min = df_day[\"low\"].iloc[start_idx:end_idx].min() - 1\n",
    "            y_max = df_day[\"high\"].iloc[start_idx:end_idx].max() + 1\n",
    "\n",
    "            box = BoxAnnotation(\n",
    "                left=start_idx - 0.5, right=end_idx - 0.5,\n",
    "                fill_color=regime_colors.get(current_regime, \"#FFFFFF\"),\n",
    "                fill_alpha=0.3, level=\"underlay\"\n",
    "            )\n",
    "            p.add_layout(box)\n",
    "\n",
    "            current_regime = r\n",
    "            start_idx = i\n",
    "\n",
    "    # ç»˜åˆ¶ K çº¿\n",
    "    bull_mask = df_day[\"close\"] >= df_day[\"open\"]\n",
    "    bear_mask = ~bull_mask\n",
    "\n",
    "    bull_idx = df_day[bull_mask][\"idx\"]\n",
    "    if len(bull_idx) > 0:\n",
    "        p.segment(\n",
    "            x0=bull_idx, y0=df_day[bull_mask][\"low\"],\n",
    "            x1=bull_idx, y1=df_day[bull_mask][\"high\"],\n",
    "            color=\"green\", line_width=1\n",
    "        )\n",
    "        p.vbar(\n",
    "            x=bull_idx, width=0.6,\n",
    "            top=df_day[bull_mask][\"close\"],\n",
    "            bottom=df_day[bull_mask][\"open\"],\n",
    "            fill_color=\"green\", line_color=\"green\"\n",
    "        )\n",
    "\n",
    "    bear_idx = df_day[bear_mask][\"idx\"]\n",
    "    if len(bear_idx) > 0:\n",
    "        p.segment(\n",
    "            x0=bear_idx, y0=df_day[bear_mask][\"low\"],\n",
    "            x1=bear_idx, y1=df_day[bear_mask][\"high\"],\n",
    "            color=\"red\", line_width=1\n",
    "        )\n",
    "        p.vbar(\n",
    "            x=bear_idx, width=0.6,\n",
    "            top=df_day[bear_mask][\"open\"],\n",
    "            bottom=df_day[bear_mask][\"close\"],\n",
    "            fill_color=\"red\", line_color=\"red\"\n",
    "        )\n",
    "\n",
    "    p.xaxis.visible = False\n",
    "    return p\n",
    "\n",
    "\n",
    "# ========== 2. é€‰æ‹©æ—¥æœŸè¿›è¡Œå¯¹æ¯” ==========\n",
    "df_plot = df.reset_index()\n",
    "df_plot[\"timestamp_dt\"] = pd.to_datetime(df_plot[\"timestamp\"].astype(str).str.slice(0, 19))\n",
    "df_plot[\"date\"] = df_plot[\"timestamp_dt\"].dt.date\n",
    "\n",
    "valid_dates = df_plot.groupby(\"date\").size()\n",
    "valid_dates = valid_dates[valid_dates >= 50].index.tolist()\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_dates = np.random.choice(valid_dates, size=min(5, len(valid_dates)), replace=False)\n",
    "\n",
    "print(f\"é€‰æ‹© {len(sample_dates)} ä¸ªæ—¥æœŸè¿›è¡Œå¯¹æ¯”:\")\n",
    "for d in sample_dates:\n",
    "    print(f\"  - {d}\")\n",
    "\n",
    "\n",
    "# ========== 3. ç”Ÿæˆâ€œä¸‰å›¾å¹¶æ’â€å¯¹æ¯” ==========\n",
    "comparison_plots = []\n",
    "\n",
    "for date in sample_dates:\n",
    "    df_day = df_plot[df_plot[\"date\"] == date].copy()\n",
    "    if len(df_day) < 30:\n",
    "        continue\n",
    "\n",
    "    # å„æ–¹æ³•è¯¥æ—¥æ ‡ç­¾ç»Ÿè®¡\n",
    "    orig_counts = df_day[\"regime\"].value_counts().to_dict()\n",
    "    mtf_counts  = df_day[\"regime_mtf\"].value_counts().to_dict()\n",
    "    p10_counts  = df_day[\"regime_10p2\"].value_counts().to_dict()\n",
    "\n",
    "    changes_mtf = (df_day[\"regime\"] != df_day[\"regime_mtf\"]).sum()\n",
    "    changes_10p = (df_day[\"regime\"] != df_day[\"regime_10p2\"]).sum()\n",
    "\n",
    "    title_orig = (\n",
    "        f\"{date} - åŸå§‹ | \"\n",
    "        f\"D:{orig_counts.get(-1,0)} R:{orig_counts.get(0,0)} U:{orig_counts.get(1,0)}\"\n",
    "    )\n",
    "    title_mtf = (\n",
    "        f\"{date} - MTF | \"\n",
    "        f\"D:{mtf_counts.get(-1,0)} R:{mtf_counts.get(0,0)} U:{mtf_counts.get(1,0)} \"\n",
    "        f\"| å˜æ›´(å¯¹åŸå§‹):{changes_mtf}\"\n",
    "    )\n",
    "    title_10p = (\n",
    "        f\"{date} - 10+2 | \"\n",
    "        f\"D:{p10_counts.get(-1,0)} R:{p10_counts.get(0,0)} U:{p10_counts.get(1,0)} \"\n",
    "        f\"| å˜æ›´(å¯¹åŸå§‹):{changes_10p}\"\n",
    "    )\n",
    "\n",
    "    p_orig = plot_kline_comparison(df_day, \"regime\",      title_orig, width=400)\n",
    "    p_mtf  = plot_kline_comparison(df_day, \"regime_mtf\",  title_mtf,  width=400)\n",
    "    p_10p  = plot_kline_comparison(df_day, \"regime_10p2\", title_10p,  width=400)\n",
    "\n",
    "    comparison_plots.append(bokeh_row(p_orig, p_mtf, p_10p))\n",
    "\n",
    "if comparison_plots:\n",
    "    comparison_layout = column(*comparison_plots)\n",
    "    show(comparison_layout)\n",
    "\n",
    "    chart_path = OUTPUT_DIR_CHARTS / \"regime_comparison_orig_vs_mtf_vs_10p2.html\"\n",
    "    output_file(str(chart_path))\n",
    "    save(comparison_layout, filename=str(chart_path),\n",
    "         title=\"Regime Comparison: Original vs MTF vs 10+2\")\n",
    "    print(f\"\\nå¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {chart_path}\")\n",
    "\n",
    "\n",
    "# ========== 4. æ±‡æ€»ç»Ÿè®¡ ==========\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ“Š ä¸‰ç§æ–¹æ³•å¯¹æ¯”æ±‡æ€»\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\næ ‡ç­¾å˜åŒ–çŸ©é˜µ (è¡Œ=åŸå§‹, åˆ—=MTF):\")\n",
    "change_matrix_mtf = pd.crosstab(df[\"regime\"], df[\"regime_mtf\"],\n",
    "                                margins=True, margins_name=\"Total\")\n",
    "print(change_matrix_mtf)\n",
    "\n",
    "print(\"\\næ ‡ç­¾å˜åŒ–çŸ©é˜µ (è¡Œ=åŸå§‹, åˆ—=10+2):\")\n",
    "change_matrix_10p = pd.crosstab(df[\"regime\"], df[\"regime_10p2\"],\n",
    "                                margins=True, margins_name=\"Total\")\n",
    "print(change_matrix_10p)\n",
    "\n",
    "# è¶‹åŠ¿è¯†åˆ«ç‡å¯¹æ¯”\n",
    "orig_trend_rate = (df[\"regime\"] != 0).mean() * 100\n",
    "mtf_trend_rate  = (df[\"regime_mtf\"] != 0).mean() * 100\n",
    "p10_trend_rate  = (df[\"regime_10p2\"] != 0).mean() * 100\n",
    "\n",
    "print(f\"\\nè¶‹åŠ¿è¯†åˆ«ç‡:\")\n",
    "print(f\"  åŸå§‹æ–¹æ³•: {orig_trend_rate:.2f}%\")\n",
    "print(f\"  MTF è¾…åŠ©: {mtf_trend_rate:.2f}%\")\n",
    "print(f\"  10+2 æ–¹æ³•: {p10_trend_rate:.2f}%\")\n",
    "\n",
    "# å¤šå‘¨æœŸä¸€è‡´æ€§åˆ†æè¿˜æ˜¯é’ˆå¯¹ MTF çš„ï¼Œä¸éœ€è¦æ”¹\n",
    "mtf_align = df[\"mtf_trend_alignment\"].dropna()\n",
    "print(f\"\\nå¤šå‘¨æœŸä¸€è‡´æ€§åˆ†å¸ƒ (åŸå§‹è¶‹åŠ¿æ ·æœ¬):\")\n",
    "trend_samples = df[df[\"regime\"] != 0][\"mtf_trend_alignment\"].dropna()\n",
    "for v in sorted(trend_samples.unique()):\n",
    "    count = (trend_samples == v).sum()\n",
    "    print(f\"  alignment={int(v)}: {count:,} ({count/len(trend_samples)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nCell 12 å®Œæˆ: ä¸‰æ–¹æ³•å¯¹æ¯”å¯è§†åŒ– âœ…\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âš ï¸ è¯·æŸ¥çœ‹ä¸Šæ–¹ä¸‰å›¾å¯¹æ¯”ï¼Œå†³å®šæ˜¯å¦é‡‡ç”¨ MTF / 10+2 ä½œä¸ºæœ€ç»ˆæ ‡ç­¾\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtU9aMJR5xnc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
